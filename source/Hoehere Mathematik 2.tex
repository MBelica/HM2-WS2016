\documentclass[12pt]{extreport} % Schriftgröße: 8pt, 9pt, 10pt, 11pt, 12pt, 14pt, 17pt oder 20pt

%% Packages
\usepackage{scrextend}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{chngcntr}
\usepackage{cmap}
\usepackage{color}
\usepackage{enumitem}
\usepackage{float}
\usepackage{hyperref}
\usepackage{ulem}
\usepackage{lmodern}
\usepackage{makeidx}
\usepackage{mathtools}
\usepackage{xpatch}
\usepackage{pgfplots}
\pgfplotsset{compat=1.7}
\usetikzlibrary{calc}	
\usetikzlibrary{matrix}	

% Language Setup (Deutsch)
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 
\usepackage[ngerman]{babel}

\usepackage{csquotes}
% Options
\makeatletter%%  
  % Linkfarbe, {0,0.35,0.35} für Türkis, {0,0,0} für Schwarz, {1,0,0} für Rot, {0,0,0.85} für Blau
  \definecolor{linkcolor}{rgb}{0,0.35,0.35}
  % Zeilenabstand für bessere Leserlichkeit
  \def\mystretch{1.2} 
  % Publisher definieren
  \newcommand\publishers[1]{\newcommand\@publishers{#1}} 
  % Enumerate im 1. Level: \alph für a), b), ...
  \renewcommand{\labelenumi}{\alph{enumi})} 
  % Enumerate im 2. Level: \roman für (i), (ii), ...
  \renewcommand{\labelenumii}{(\roman{enumii})}
  % Zeileneinrückung am Anfang des Absatzes
  \setlength{\parindent}{0pt} 
  % Verweise auf Enumerate, z.B.: 3.2 a)
  \setlist[enumerate,1]{ref={\thesatz ~ \alph*)}}
  % Für das Proof-Environment: 'Beweis:' anstatt 'Beweis.'
  \xpatchcmd{\proof}{\@addpunct{.}}{\@addpunct{:}}{}{} 
  % Nummerierung der Bilder, z.B.: Abbildung 4.1
  \@ifundefined{thechapter}{}{\def\thefigure{\thechapter.\arabic{figure}}} 
  % Chapter-Nummerierung beginnen bei (-1):
  \setcounter{chapter}{14}
\makeatother%

% Meta Setup (Für Titelblatt und Metadaten im PDF)
\title{Höhere Mathematik II}
\author{G. Herzog, Ch. Schmoeger}
\date{Sommersemester 2017}
\publishers{Karlsruher Institut für Technologie}

%% Math. Definitionen
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

%% Theorems (unnamedtheorem = Theorem ohne Namen)
\newtheoremstyle{named}{}{}{\normalfont}{}{\bfseries}{:}{0.25em}{#2 \thmnote{#3}}
\newtheoremstyle{nnamed}{}{}{\normalfont}{}{\bfseries}{:}{0.25em}{\thmnote{#3}}
\newtheoremstyle{itshape}{}{}{\itshape}{}{\bfseries}{:}{ }{}
\newtheoremstyle{normal}{}{}{\normalfont}{}{\bfseries}{:}{ }{}
\renewcommand*{\qed}{\hfill\ensuremath{\square}}

\theoremstyle{named}
\newtheorem{unnamedtheorem}{Theorem} \counterwithin{unnamedtheorem}{chapter}
\theoremstyle{nnamed}
\newtheorem*{unnamedtheorem*}{Theorem} 

\theoremstyle{itshape}
\newtheorem{satz}[unnamedtheorem]{Satz} 
\newtheorem*{definition}{Definition}
\newtheorem{hilfssatz}[unnamedtheorem]{Hilfssatz}
\newtheorem*{hilfssatz*}{Hilfssatz}

\theoremstyle{normal}
\newtheorem{beispiel}[unnamedtheorem]{Beispiel}
\newtheorem{folgerung}[unnamedtheorem]{Folgerung}
%\newtheorem{hilfssatz}[unnamedtheorem]{Hilfssatz}
\newtheorem{anwendung}[unnamedtheorem]{Anwendung}
\newtheorem{anwendungen}[unnamedtheorem]{Anwendungen}
\newtheorem*{anwendung*}{Anwendung}
\newtheorem*{beispiel*}{Beispiel}
\newtheorem*{beispiele}{Beispiele}
\newtheorem*{bemerkung}{Bemerkung} 
\newtheorem*{bemerkungen}{Bemerkungen}
\newtheorem*{bezeichnung}{Bezeichnung}
\newtheorem*{eigenschaften}{Eigenschaften}
\newtheorem*{folgerung*}{Folgerung}
\newtheorem*{folgerungen}{Folgerungen}
%\newtheorem*{hilfssatz*}{Hilfssatz}
\newtheorem*{regeln}{Regeln}
\newtheorem*{motivation}{Motivation}
\newtheorem*{erinnerung}{Erinnerung}
\newtheorem*{schreibweise}{Schreibweise}
\newtheorem*{schreibweisen}{Schreibweisen}
\newtheorem*{uebung}{Übung}
\newtheorem*{vereinbarung}{Vereinbarung}

%% Template
\makeatletter%
\DeclareUnicodeCharacter{00A0}{ } \pgfplotsset{compat=1.7} \hypersetup{colorlinks,breaklinks, urlcolor=linkcolor, linkcolor=linkcolor, pdftitle=\@title, pdfauthor=\@author, pdfsubject=\@title, pdfcreator=\@publishers}\DeclareOption*{\PassOptionsToClass{\CurrentOption}{report}} \ProcessOptions \def\baselinestretch{\mystretch} \setlength{\oddsidemargin}{0.125in} \setlength{\evensidemargin}{0.125in} \setlength{\topmargin}{0.5in} \setlength{\textwidth}{6.25in} \setlength{\textheight}{8in} \addtolength{\topmargin}{-\headheight} \addtolength{\topmargin}{-\headsep} \def\pulldownheader{ \addtolength{\topmargin}{\headheight} \addtolength{\topmargin}{\headsep} \addtolength{\textheight}{-\headheight} \addtolength{\textheight}{-\headsep} } \def\pullupfooter{ \addtolength{\textheight}{-\footskip} } \def\ps@headings{\let\@mkboth\markboth \def\@oddfoot{} \def\@evenfoot{} \def\@oddhead{\hbox {}\sl \rightmark \hfil \rm\thepage} \def\chaptermark##1{\markright {\uppercase{\ifnum \c@secnumdepth >\m@ne \@chapapp\ \thechapter. \ \fi ##1}}} \pulldownheader } \def\ps@myheadings{\let\@mkboth\@gobbletwo \def\@oddfoot{} \def\@evenfoot{} \def\sectionmark##1{} \def\subsectionmark##1{}  \def\@evenhead{\rm \thepage\hfil\sl\leftmark\hbox {}} \def\@oddhead{\hbox{}\sl\rightmark \hfil \rm\thepage} \pulldownheader }	\def\chapter{\cleardoublepage  \thispagestyle{plain} \global\@topnum\z@ \@afterindentfalse \secdef\@chapter\@schapter} \def\@makeschapterhead#1{ {\parindent \z@ \raggedright \normalfont \interlinepenalty\@M \Huge \bfseries  #1\par\nobreak \vskip 40\p@ }} \newcommand{\indexsection}{chapter} \patchcmd{\@makechapterhead}{\vspace*{50\p@}}{}{}{}\def\Xint#1{\mathchoice
    {\XXint\displaystyle\textstyle{#1}} {\XXint\textstyle\scriptstyle{#1}} {\XXint\scriptstyle\scriptscriptstyle{#1}} {\XXint\scriptscriptstyle\scriptscriptstyle{#1}} \!\int} \def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$} \vcenter{\hbox{$#2#3$}}\kern-.5\wd0}} \def\dashint{\Xint-} \def\Yint#1{\mathchoice {\YYint\displaystyle\textstyle{#1}} {\YYYint\textstyle\scriptscriptstyle{#1}} {}{} \!\int} \def\YYint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$} \lower1ex\hbox{$#2#3$}\kern-.46\wd0}} \def\YYYint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$}  \lower0.35ex\hbox{$#2#3$}\kern-.48\wd0}} \def\lowdashint{\Yint-} \def\Zint#1{\mathchoice {\ZZint\displaystyle\textstyle{#1}}{\ZZZint\textstyle\scriptscriptstyle{#1}} {}{} \!\int} \def\ZZint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$}\raise1.15ex\hbox{$#2#3$}\kern-.57\wd0}} \def\ZZZint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$} \raise0.85ex\hbox{$#2#3$}\kern-.53\wd0}} \def\highdashint{\Zint-} \DeclareRobustCommand*{\onlyattoc}[1]{} \newcommand*{\activateonlyattoc}{ \DeclareRobustCommand*{\onlyattoc}[1]{##1} } \AtBeginDocument{\addtocontents{toc} {\protect\activateonlyattoc}} 
	% Titlepage
	\def\maketitle{ \begin{titlepage} 
			~\vspace{3cm} 
		\begin{center} {\Huge \@title} \end{center} 
	 		\vspace*{1cm} 
	 	\begin{center} {\large \@author} \end{center} 
	 	\begin{center} \@date \end{center} 
	 		\vspace*{7cm} 
	 	\begin{center} \@publishers \end{center} 
	 		\vfill 
	\end{titlepage} }
\makeatother%

% Indexdatei erstellen
\makeindex 

\begin{document}

\pagenumbering{Alph}
\begin{titlepage}
	\maketitle
	\thispagestyle{empty}
\end{titlepage}
\pagenumbering{arabic}
	
% Inhaltsverzeichnis
\tableofcontents
\thispagestyle{empty}
  
% Skript - Anfang 
\chapter{Konvergenz im \texorpdfstring{$\R^{n}$}{Rn}}
     
     
\index{Folge!beschränkte} \index{Folge!Teil-} \index{Häufungswert} \index{Folge!konvergente} \index{Grenzwert} \index{Limes} \index{Folge!divergente}
\begin{definition}
	Sei $\left(a^{(k)}\right)$ eine Folge im $\R^{n}$, also $\left( a^{(k)} \right) = \left( a^{(1)}, a^{(2)}, a^{(3)}, \dotsc \right)$ mit $a^{(k)} = \left(a_{1}^{(k)}, \dotsc, a_{n}^{(k)} \right) \in \R^{n}$.
	\begin{enumerate} 
		\item $\left( a^{(k)} \right)$ hei{\ss}t \textbf{beschränkt} $: \iff$ $\exists c \geq 0 ~\forall k : \left\| a^{(k)} \right\| \leq c$.
		\item Der Begriff \textbf{Teilfolge} (TF) wird wie in HMI definiert.
		\item $x_{0} \in \R^{n}$ hei{\ss}t ein \textbf{Häufungswert} (HW) von $\left( a^{(k)} \right) : \iff \forall \epsilon > 0: a^{(k)} \in U_{\epsilon}(x_{0})$ für endlich viele $k$.
		\item $\left( a^{(k)}\right)$ hei{\ss}t \textbf{konvergent} $: \iff$ $\exists a \in \R^{n}$:
			\[ \left\| a^{(k)} - a \right\| \longrightarrow 0 \quad (k \rightarrow \infty) \]
			In diesem Fall hei{\ss}t $a$ der \textbf{Grenzwert} (GW) oder \textbf{Limes} von $\left( a^{(k)} \right)$ und man schreibt 
			\[ a = \lim_{k \rightarrow \infty} a^{(k)} \quad \text{ oder } \quad a^{(k)} \longrightarrow a \quad (k \rightarrow \infty) \] 	
			Wie in HMI: der Grenzwert einer konvergenten Folge ist eindeutig bestimmt. 
		\item Ist $\left( a^{(k)} \right)$ nicht konvergent, so hei{\ss}t $\left( a^{(k)} \right)$ \textbf{divergent}
	\end{enumerate}
\end{definition}


Beachte: $a^{(k)} \longrightarrow a \iff \forall \epsilon > 0 ~\exists k_{0} \in \N \forall k \geq k_{0}: \left\| a^{(k)} - a \right\| < \epsilon$
	\[ \quad \iff \forall \epsilon > 0 \text{ gilt für fast alle } k \in \N : a^{(k)} \in U_{\epsilon}(a) \hspace{1.75cm} \]


\begin{beispiel*}[$n = 2$]
	$a^{(k)} \coloneqq \left( \frac{1}{k} , 1 + \frac{1}{k} \right)$, $a \coloneqq (0, 1)$	
	\[ \left\| a^{(k)} - a \right\| = \left\| \left( \frac{1}{k} , \frac{1}{k} \right) \right\| = \left( \frac{2}{k^{2}} \right)^{\frac{1}{2}} = \frac{\sqrt{2}}{k} \longrightarrow 0 \]
	Also: $a^{(k)} \longrightarrow (0, 1)$.
\end{beispiel*}

\index{Cauchykriterium} \index{Bolzano-Weierstra{\ss}}
\begin{satz} \label{15.1:satz}
	$\left( a^{(k)} \right)$ sei eine Folge im $\R^{n}$, $a^{(k)} = \left( a_{1}^{(k)}, \dotsc, a_{n}^{(k)}\right)$.
	
	\begin{enumerate}
		\item Ist $\left( a^{(k)} \right)$ konvergent, so ist $\left( a^{(k)} \right)$ beschränkt und jede Teilfolge von $\left( a^{(k)} \right)$ konvergiert gegen $\lim a^{(k)}$.
		\item Ist $a = \left( a_{1}, \dotsc, a_{n} \right) \in \R^{n}$, so gilt: $a^{(k)} \longrightarrow a \iff a_{j}^{(k)} \longrightarrow a_{j} \quad (j = 1, \dotsc, n)$.
		\item Sei $\left( b^{(k)}\right)$ eine weitere Folge im $\R^{n}$, $a, b \in \R^{n}$, $(\beta_{k})$ eine Folge in $\R$, $\beta \in \R$ und es gelte $a^{(k)} \longrightarrow a$, $b^{(k)} \longrightarrow b$ und $\beta_{k} \longrightarrow \beta$. Dann:
			\begin{enumerate}
				\item $a^{(k)} + b^{(k)} \longrightarrow a + b$,
				\item $\beta_{k} a^{(k)} \longrightarrow \beta a$,
				\item $a^{(k)} b^{(k)} \longrightarrow a b$ und
				\item $\left\| a^{(k)} \right\| \longrightarrow \| a \|$
			\end{enumerate}
		\item \textbf{Cauchykriterium}: $\left( a^{(k)}\right)$ ist konvergent 
			\[ \iff \forall \epsilon > 0 ~\exists k_{0} \in \N ~\forall k, l \geq k_{0}: \left\| a^{(k)} - a^{(l)} \right\| < \epsilon. \]
		\item \textbf{Bolzano-Weierstra{\ss}}: Ist $\left( a^{(k)} \right)$ beschränkt, so enthält $\left( a^{(k)} \right)$ eine konvergente Teilfolge.
	\end{enumerate}
	
	\begin{proof} ~\
		\begin{enumerate}
			\item Wie in HMI.
			\item Sei $j \in \{1, \dotsc, n\}$, dann
				\[ \left| a_{j}^{(k)} - a_{j} \right| \overset{14.1 h)}{\leq} \left\| a^{(k)} - a \right\| \overset{14.1 h)}{\leq} \sum_{i = 1}^{n} \left| a_{i}^{(k)} - a_{i} \right| \]
				$\Rightarrow$ Behauptung.
			\item Folgt aus b).
			\item \enquote{$\Rightarrow$} Wie in HMI \enquote{$\Leftarrow$} Übung (mit b) und 14.1 h)).
			\item Der Übersicht wegen sei $n = 2$. Also $a^{(k)} = (x_{k} , y_{k})$, $|x_{k}|, |y_{k}| \leq \left\| a^{(k)} \right\|$ \\
			$\Rightarrow (x_{k}), (y_{k})$ sind beschränkte Folgen in $\R$ $\xRightarrow[2.12]{HMI} (x_{k})$ enthält eine konvergente Teilfolge $(x_{k_{j}})$. $(y_{k_{j}})$ ist beschränkt $\xRightarrow[2.12]{HMI} (y_{k_{j}})$ enthält eine konvergente Teilfolge $(y_{k_{j_{e}}})$. \\
			Dann ist auch $(x_{k_{j_{e}}})$ konvergent $\xRightarrow[b)]{} \left( a^{(k_{j_{e}})} \right)$ ist konvergent.
		\end{enumerate}
	\end{proof}
\end{satz}

\index{Häufungspunkt}
\begin{definition}
	Sei $A \subseteq \R^{n}$. $x_{0} \in \R^{n}$ hei{\ss}t ein \textbf{Häufungspunkt} (HP) von $A$ $: \iff \exists$ Folge $\left(a^{(k)}\right)$ in $A \setminus \{ x_{0} \}$: $a^{(k)} \rightarrow x_{0}$.
\end{definition}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $A \coloneqq U_{1}(0)$. $x_{0}$ ist Häufungspunkt von $A \iff x_{0} \in \overline{U_{1}(0)}$.
		\item $0$ ist Häufungspunkt von $U_{1}(0) \setminus \{ 0 \}$.
		\item Endliche Mengen haben keine Häufungspunkte.
	\end{enumerate}	
\end{beispiele}


\begin{satz} \label{15.2:satz}
	Sei $A \subseteq \R^{n}$.
	\begin{enumerate}
		\item Die folgenden Aussagen sind äquivalent:
			\begin{enumerate}
				\item $A$ ist abgeschlossen.
				\item Für jede konvergente Folge $\left( a^{(k)} \right)$ in $A$ gilt: $\lim a^{(k)} \in A$.
				\item Jeder Häufungspunkt von $A$ gehört zu A.
			\end{enumerate}
		\item $A$ ist kompakt $\iff$ jede Folge in $A$ enthält eine konvergente Teilfolge deren Grenzwert zu $A$ gehört.
	\end{enumerate}

	\begin{proof}
		ohne Beweis.
	\end{proof}
\end{satz}


\begin{vereinbarung}
	Für Elemente des $\R^{2}$ schreiben wir meist $(x, y)$ statt $(x_{1}, x_{2})$ und im $\R^{3}$ meist $(x, y, z)$ anstatt $(x_{1}, x_{2}, x_{3})$.	
\end{vereinbarung}


\chapter{Grenzwerte bei Funktionen, Stetigkeit}


Stets i.d. $\S$en: $n, m \in \N$, $\emptyset \neq D \subseteq \R^{n}$ und $f \colon D \rightarrow \R^{m}$ eine (vektorwertige) Funktion. 

Mit $x = (x_{1}, \dotsc, x_{n}) \in D$ hat $f$  die Darstellung:
	$$ f(x) = f(x_{1}, \dotsc, x_{m}) = \left( f_{1}(x_{1}, \dotsc, x_{n}), f_{2}(x_{1}, \dotsc, x_{n}), \dotsc, f_{m}(x_{1}, \dotsc, x_{n)} \right) $$
wobei $f_{j} \colon D \rightarrow \R ~ (j = 1, \dotsc, m)$. Kurz: $f = (f_{1}, \dotsc, f_{m})$.


\begin{beispiel*}
	$n = 2$, $m = 3$, $D = \R^{2}$; $f(x, y) = (xy, x + y, xe^{y})$, also
	$$ f = (f_{1}, f_{2}, f_{3}) $$
	mit $f_{1}(x, y) = xy, f_{2}(x, y) = x + y,  f_{3}(x, y) = x e^{y}$.
\end{beispiel*}


\textbf{Veranschaulichung im Fall $m = 1$} (reellwertige Funktionen)
\begin{itemize}
	\item $n = 1$ (bekannt)
	 \begin{figure*}[ht!]
	  \begin{center}
		\begin{tikzpicture}[scale=1]
			\draw [dotted, fill=green!15] plot [smooth cycle] %
   				coordinates {(-1.14,-1)(-0.84, -.18) (-0.04, 0.3) (2.24, 0) %
   				(4.48, -0.56) (4.48, -1.46) (3.38,-1.84)(0.38, -1.28)};
			\draw [dotted, fill=red!15] plot [smooth cycle] %
    			coordinates {(-1.04, 1.54) (-0.52, 2.66) (1.22, 3.22) %
    			(4.48, 2.1)(4.44, 1.14) (3.38, 0.98) (0.84, 2.26)};
			\draw [dotted, fill=red!15] plot [smooth cycle] %
    			coordinates {(-1.04, 1.54) (-0.52, 2.16) (1.22, 2.72) %
    			(4.48, 2.1)(4.44, 1.14) (3.38, 0.98) (0.84, 2.26)};
			\draw[thick,->] (0,0) -- (-2,-1.5) node[below] {$x$};
			\draw[thick,->] (0,0) -- (5,0) node[right] {$y$};
			\draw[thick,->] (0,0) -- (0,3) node[above] {$z$};
			\filldraw (4.2,3.2) node[left] {$z=f(x,y)$};
			\draw [dashed] (3.2,-1) -- (3.2,1.1);
			\draw [dashed, lightgray] (3.2,1.1) -- (3.2,2.2);
			\filldraw (3.2,-1)circle (2pt) node[left] %
				{$\left(x_0,y_0\right)$};
			\filldraw (3.2,2.2)circle (2pt) node[left] % 
  				{$\left(x_0,y_0,f\left(x_0,y_0\right)\right)$};
		\end{tikzpicture}
	  \end{center}
	 \end{figure*}

	\item $n = 2$: ~\\% todo Bild Seite 1

	 \begin{figure*}[ht!]
	  \begin{center}
		\begin{tikzpicture}
			\draw [dotted, fill=gray!15] plot [smooth cycle] %
    			coordinates {(-0.5,-1)(-0.5,-0.5) (0.5,-0.25) (2.24, -0.1) %
    			(4.48, -0.56) (4.48, -1.46) (3.38,-1.84)(0.38, -1.28)};
			\draw [dotted, fill=red!15] plot [smooth cycle] %
    			coordinates {(0.1,2) (0.75,2.5) (2.4,2.9) %
    			(4.48, 2.1)(4.44, 1.14) (3.38, 1.28) (2,2)};
			\draw [dotted, fill=red!15] plot [smooth cycle] %
    			coordinates {(0.5,1.25) (0,2) (2,2.5) %
    			(4.48, 2.1)(4.44, 1.14) (3.38, 1.28) (2,2)};
			\draw[thick,->] (0,0) -- (-2,-1.5) node[below] {$x$};
			\draw[thick,->] (0,0) -- (5,0) node[right] {$y$};
			\draw[thick,->] (0,0) -- (0,3) node[above] {$z$};
			\draw [dashed] (3.2,-1) -- (3.2,1.1);
			\draw [dashed, lightgray] (3.2,1.1) -- (3.2,2.2);			
			\filldraw (3.2,-1)circle (2pt) node[left] %
				{\footnotesize  $\left(x_0,y_0\right)$};
			\filldraw (3.2,2.2)circle (2pt) node[left] % 
				{\footnotesize $\left(x_0,y_0,f\left(x_0,y_0\right)\right)$};
		\end{tikzpicture}
	  \end{center}
	 \end{figure*}
\end{itemize}


\begin{definition}
	Sei $x_{0} \in \R^{n}$ ein Häufungspunkt von $D$. Sei $y_{0} \in \R^{m}$. $\lim_{x \rightarrow x_{0}} f(x) = y_{0} : \iff$ für jede Folge $\left(x^{(k)} \right)$ in $D \setminus \{ x_{0} \}$ mit $x^{(k)} \rightarrow x_{0}$ gilt: $f\left( x^{(k)} \right) \rightarrow y_{0}$. In diesem Fall schreiben wir auch: $f(x) \rightarrow y_{0} ~ (x \rightarrow x_{0})$.
\end{definition}


\begin{beispiel*}
	Sei $f = (f_{1}, f_{2}, f_{3})$ wie in obigem Beispiel. Sei $\left( (x_{k}, y_{k}) \right)$ eine Folge in $\R^{2}$ mit $(x_{k}, y_{k}) \rightarrow (1, 1) \xRightarrow[\ref{15.1:satz}]{} x_{k} \rightarrow 1, y_{k} \rightarrow 1$
	$$ \Rightarrow f_{1}(x_{k}, y_{k}) = x_{k} y_{k} \rightarrow 1, ~ f_{2}(x_{k}, y_{k}) = x_{k} + y_{k} \rightarrow 2, ~ f{3}(x_{k}, y_{k}) = x_{k} e^{y_{k}} \rightarrow e. $$
	$\xRightarrow[\ref{15.1:satz}]{} f(x_{k}, y_{k}) \rightarrow (1, 2, e)$. Also: $\lim_{(x, y) \rightarrow (1, 1)} f(x, y) = (1, 2, e)$.
\end{beispiel*}


\begin{beispiel} $(m = 1, D = \R^{2})$ \label{16.1:bsp}
	$f(x, y) \coloneqq \begin{cases}
							\frac{xy}{x^{2} + y^{2}}, & (x, y) \neq (0, 0) \\
							0, & (x, y) = (0, 0)
						 \end{cases}$
	$$ \left( \frac{1}{k}, 0 \right) \rightarrow (0, 0), ~ f\left( \frac{1}{k}, 0 \right) = 0 \rightarrow 0 ~$$
	$$ \left( \frac{1}{k}, \frac{1}{k} \right) \rightarrow (0, 0),  f\left( \frac{1}{k}, \frac{1}{k} \right) = \frac{1}{2} \rightarrow \frac{1}{2} $$
	D.h. $\lim_{(x, y) \rightarrow (0, 0)} f(x, y)$ existiert nicht!	
\end{beispiel}


\begin{satz} \label{16.2:satz}
	$x_{0}$ sei ein Häufungspunkt von $D \subseteq \R^{n}$, $f, g \colon D \rightarrow \R^{m}$ und $h \colon D \rightarrow \R$ seien Funktionen. Es seien $y_{0}, z_{0} \in \R^{m}$ und $\alpha \in \R$.
	\begin{enumerate}
		\item Ist $f = (f_{1}, \dotsc, f_{m})$ und $y_{0} = (y_{1}, \dotsc, y_{m})$, so gilt für $j = 1, \dotsc, m$:
			$$ f(x) \rightarrow y_{0} ~(x \rightarrow x_{0}) ~ \iff ~ f_{j}(x) \rightarrow y_{j} ~(x \rightarrow x_{0}) $$
		\item Für alle $x \in D \setminus \{ x_{0} \}$ mit $\| x - x_{0} \| < \delta$:
			 $$ \lim_{x \rightarrow x_{0}} f(x) = y_{0} \iff \forall \epsilon > 0 ~\exists \delta > 0: \| f(x) - y_{0} \| < \epsilon $$
		\item Es gelte $f(x) \rightarrow y_{0}$, $g(x) \rightarrow z_{0}$ und $h(x) \rightarrow \alpha$ ($x \rightarrow x_{0}$). Dann:
			\begin{enumerate}
				\item $f(x) \otimes g(x) \rightarrow y_{0} \otimes z_{0} ~(x \rightarrow x_{0})$, wobei $\otimes \in \{ +, - , \cdot \}$
				\item  $h(x) f(x) \rightarrow \alpha y_{0} ~(x \rightarrow x_{0})$
				\item $\| f(x) \| \rightarrow \| y_{0} \| ~(x\rightarrow x_{0})$
				\item Ist $\forall x \in D$: $\alpha \neq 0$ und $h(x) \neq 0$, so gilt für $x \rightarrow x_{0}$: $\frac{1}{h(x)} \rightarrow \frac{1}{\alpha}$
			\end{enumerate} 
			wobei \enquote{$\cdot$} ein Skalarprodukt bezeichnet.
	\end{enumerate}
	
	\begin{proof}
		a) folgt aus \ref{15.1:satz}. Rest: wie in HMI $\left(\| \cdot \| \text{ statt } | \cdot | \right)$.
	\end{proof}
\end{satz}

\index{Stetigkeit} \index{$C$}
\begin{definition} ~\
	\begin{enumerate}
		\item $f$ hei{\ss}t \textbf{in $x_{0} \in D$ stetig} $: \iff$ für jede Folge $\left( x^{(k)} \right)$ in $D$ mit $x^{(k)} \rightarrow x_{0}$ gilt:
			$$ f\left( x^{(k)} \right) \rightarrow f\left( x_{0} \right). $$
		\item $f$ hei{\ss}t \textbf{auf $D$ stetig} $: \iff f$ ist in jedem $x \in D$ stetig. In diesem Fall schreiben wir: $f \in C \left( D, \R^{m} \right)$. 
	\end{enumerate}
\end{definition}


\begin{beispiel} \label{16.3:bsp}
	$f$ sei wie in \ref{16.1:bsp}. 
		$$ f\left( \frac{1}{k}, \frac{1}{k} \right) \longrightarrow \frac{1}{2} \neq 0 = f \left( 0, 0 \right) $$
	$f$ ist also in $(0, 0)$ nicht stetig. Aber: ist $(x_{0}, y_{0}) \in \R^{2} \setminus \left\{ (0, 0) \right\}$, so ist $f$ in $(x_{0}, y_{0})$ stetig.
\end{beispiel}


\begin{satz} \label{16.4:satz}
	Sei $x_{0} \in D$ und $g \colon D \rightarrow \R^{m}$ und $h \colon D \rightarrow \R$ seien weitere Funktionen.
	\begin{enumerate}
		\item $f$ ist in $x_{0}$ stetig $\iff$ alle $f_{j}$ sind in $x_{0}$ stetig 
			$$\iff \forall \epsilon > 0 ~\exists \delta > 0 ~\forall x \in D: \| x - x_{0} \| \delta: \| f(x) - f(x_{0}) \| < \epsilon. $$
		\item Ist $x_{0}$ Häufungspunkt von $D$, so gilt:
			$$ f \text{ ist stetig in } x_{0} ~ \iff ~ \lim_{x \rightarrow x_{0}} f(x) = f(x_{0}) $$
		\item $f, g$ und $h$ seien stetig in $x_{0}$. Dann sind stetig in $x_{0}$:
			\begin{itemize}
				\item $f \otimes g$ (wobei $\otimes \in \{ +, -, \cdot \}$)
				\item $hf$, $x \mapsto \| f(x) \|$ und
				\item $\frac{1}{h}$ (falls $h(x) \neq 0 ~\forall x \in D$),
			\end{itemize}
			wobei \enquote{$\cdot$} ein Skalarprodukt bezeichnet.
		\item $C \left( D, \R^{m} \right)$ ist ein reeller Vektorraum.
	\end{enumerate}
	
	\begin{proof}
		\ref{15.1:satz} bzw. wie in HMI.
	\end{proof}
\end{satz}

\index{Beschränktheit}
\begin{definition}
	$f$ hei{\ss}t \textbf{auf $D$ beschränkt} $: \iff \exists M \geq 0 ~\forall x \in D$: $\| f(x) \| \leq M$.
\end{definition}

Wie in HMI zeigt man:


\begin{satz} ~\ \label{16.5:satz}
	\begin{enumerate}
		\item $f \colon D \rightarrow \R^{m}$ sei in $x_{0} \in D$ stetig, es sei $E \subseteq \R^	{m}$, $f(D) \subseteq E$ und $g \colon E \rightarrow \R^{p}$ sei stetig in $f(x_{0})$. Dann ist
			$$ g \circ f \colon D \longrightarrow \R^{p} $$
			stetig in $x_{0}$.
		\item Es sei $D$ \textbf{kompakt} und $f \in C \left( D, \R^{m} \right)$. Dann:
			\begin{enumerate}
				\item $f(D)$ ist kompakt, insbesondere ist $f$ beschränkt.
				\item Ist $m = 1$, so existieren $x_{1}, x_{2} \in D ~\forall x \in D$: $f(x_{1}) \leq f(x) \leq f(x_{2})$.
			\end{enumerate}
	\end{enumerate}
\end{satz}


\begin{satz} ~\ \label{16.6:satz}
	Sei $f \colon \R^{n} \rightarrow \R^{m}$ linear. Dann:
		$$ f \in C\left(\R^{n}, \R^{m}\right) $$
	
	\begin{proof}
		Es existiert eine reelle $m \times n$-Matrix $A$: $f(x) = Ax ~(x \in \R^{n})$. Sei $x_{0} \in \R^{n}$:
			$$ \left\| f(x) - f(x_{0}) \right\| = \| Ax - A x_{0} \| = \| A(x - x_{0}) \| \overset{\S 15}{\leq} \|A\| \| x - x_{0} \| $$
		Also: $f(x) \rightarrow f(x_{0}) ~(x \rightarrow x_{0})$.
	\end{proof}
\end{satz}


\begin{beispiel*}
	$f \colon \R^{2} \rightarrow \R$, $f(x, y) = x$ ist stetig auf $\R^{2}$.	
\end{beispiel*}


\chapter{Analysis in \texorpdfstring{$\C$}{C}}


$\C$ und $\R^{2}$ sind Vektorräume über $\R$ der Dimension $2$. Sie unterscheiden sich also nur durch die Bezeichnung ihrer Elemente für $x, y \in \R$:
	$$ z = x + iy \in \C, \quad (x, y) \in \R^{2} $$
Beachtet man noch $|z| = |x + iy| = \left(x^{2} + y^{2}\right)^{\frac{1}{2}} = \| (x, y) \|$, so sieht man: alle aus der Addition, der Skalarmultiplikation und der Norm entwickelten Begriffe und Sätze der $\S$en 14 - 16 gelten in $\C$. Zum Beispiel:

\begin{unnamedtheorem*}[Konvergenz von Folgen]
	Sei $(z_{n})$ eine Folge in $\C$ und $z_{0} \in \C$. $(z_{n})$ konvergiert gegen $z_{0}$ $\iff |z_{n} - z_{0}| \rightarrow 0 \overset{}{\iff} \operatorname{Re}(z_{n}) \rightarrow \operatorname{Re}(z_{0})$ und $\operatorname{Im}(z_{n}) \rightarrow \operatorname{Im}(z_{0})$.
\end{unnamedtheorem*}

Zu den Sätzen in $\S$15 kommt hinzu:

\begin{satz} \label{17.1:satz}
	$(z_{n})$ und $(w_{n})$ seien Folgen in $\C$ mit $z_{n} \rightarrow z_{0}$ und $w_{n} \rightarrow w_{0}$. Dann:
	\begin{enumerate}
		\item $z_{n} w_{n} \rightarrow z_{0} w_{0}$
		\item Ist $z_{0} \neq 0$, so existieren $N \in \N ~\forall n \geq N$: $z_{n} \neq 0$ und $\frac{1}{z_{n}} \longrightarrow \frac{1}{z_{0}}$ 
	\end{enumerate}
	
	\begin{proof}
		wie in $\R$.
	\end{proof}
\end{satz}


\begin{beispiel*}
	Sei $w \in \C$ und $z_{n} \coloneqq w^{n} ~(n \in \N)$. $|z_{n}| = |w_{n}|^{n}$.
	\begin{itemize}
		\item Ist $|w| < 1$, so gilt: $z_{n} \longrightarrow 0$.
		\item Ist $|w| > 1$, so gilt $(z_{n})$ ist divergent.
		\item Im Falle $|w| = 1$ gilt:
			\begin{description}
				\item $w = 1$: $(z_{n})$ ist konvergent.
				\item $w \neq 1$: $(z_{n})$ ist divergent.
			\end{description}
	\end{itemize}
\end{beispiel*}

\index{konvergent} \index{divergent} \index{Reihenwert}
\begin{unnamedtheorem*}[Unendliche Reihen]
	Sei $(a_{n})$ eine Folge in $\C$ und $s_{n} \coloneqq a_{1} + \dotsc + a_{n} ~(n \in \N)$. Die Folge $(s_{n})$ hei{\ss}t eine unendliche Reihe und wird mit $\sum_{n=1}^{\infty} a_{n}$ bezeichnet.
	\begin{itemize}
		\item $\sum_{n=1}^{\infty} a_{n}$ hei{\ss}t \textbf{konvergent} (\textbf{divergent}) $: \iff (s_{n})$ ist konvergent (divergent).
		\item Im Konvergenzfall hei{\ss}t $\sum_{n=1}^{\infty} a_{n} \coloneqq \lim_{n \rightarrow \infty} s_{n}$ der \textbf{Reihenwert}.
	\end{itemize}
\end{unnamedtheorem*}


Die Definitionen und Sätze aus HMI, $\S$3 gelten wörtlich auch in $\C$, bis auf diejenigen Definitionen und Sätze in denen die Anordnung auf $\R$ eine Rolle spielt (z.B.: Monotoniekriterium, Leibnitzkriterium).

\index{geometrische Reihe}
\begin{beispiele} ~\
	\begin{enumerate}
		\item Sei $z \in \C$. $\sum_{n=0}^{\infty} z^{n}$ hei{\ss}t \textbf{geometrische Reihe}. 
			\begin{enumerate}
				\item Sei $|z| < 1$. Dann ist $\sum_{n=0}^{\infty} |z|^{n}$ konvergent, also ist $\sum_{n=0}^{\infty} z^{n}$ absolut konvergent und somit konvergent. Wie in HMI: $\sum_{n=0}^{\infty} z^{n} = \frac{1}{1 - z}$ (für $|z| < 1$).
				\item Sei $|z| \geq 1$. Dann: $|z|^{n} \not\rightarrow 0$, also $z^{n} \not\rightarrow 0$. Somit ist $\sum_{n=0}^{\infty} z^{n}$ divergent. \\
					Ist $z = \frac{i}{2}$, so ist $|z| < 1$, also $\sum_{n=0}^{\infty} \left( \frac{i}{2} \right)^{n}$ konvergent und 
					$$ \sum_{n=0}^{\infty} \left( \frac{i}{2} \right)^{n} = \frac{1}{1 - \frac{i}{2}} = \frac{2}{2 - i} = \frac{2 (2 + i)}{(2-i)(2+i)} = \frac{4 + 2i}{5} = \frac{4}{5} + i \frac{2}{5} $$
			\end{enumerate}
		\item $\sum_{n=0}^{\infty} \frac{z^{n}}{n!}$; $a_{n} \coloneqq \frac{z^{n}}{n!}$. Dann: $|a_{n}| = \frac{|z|^{n}}{n!}$ 
			$$ \xRightarrow[]{HMI} \sum_{n}^{\infty} |a_{n}| \text{ ist konvergent } (\text{und} =e^{|z|}). $$
			Also konvergiert $\sum_{n=0}^{\infty} \frac{z^{n}}{n!}$ absolut in jedem $z \in \C$.
		\item Wie in Beispiel b): die Reihen
			$$ \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n}}{(2n)!} \quad \text{und} \quad \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n+1}}{(2n+1)} $$
			konvergieren absolut in jedem $z \in \C$.
	\end{enumerate}	
\end{beispiele}


\begin{beispiel}  \label{17.2:satz}
	Sei $z = x + iy \in \C ~(x, y \in \R)$. HMI, \S12:
		$$ e^{z} = e^{x} \left( \cos y + i \sin y \right) $$
	Dann $\left| e^{z} \right| = e^{x}$. Es ist $\left| e^{z} \right| < 1 \iff x < 0 \iff \operatorname{Re}(z) < 0$. Fazit:
		$$ \text{ist } \operatorname{Re}(z) < 0, \text{ so konvergiert } \sum_{n=0}^{\infty} \left( e^{z} \right)^{n} = \sum_{n=0}^{\infty} e^{nz} \text{ absolut und } \sum_{n=0}^{\infty} \left( e^{z} \right)^{n} = \frac{1}{1 - e^{z}}. $$
\end{beispiel}

\index{Potenzreihe} \index{Konvergenzradius}
\begin{unnamedtheorem*}[Potenzreihen]
	Sei $(a_{n})$ eine Folge in $\C$ und $z_{n} \in \C$. Eine Reihe der Form
	$$ \sum_{n=0}^{\infty} a_{n} \left( z - z_{0} \right)^{n}, \quad (z \in \C) $$
	hei{\ss}t eine \textbf{Potenzreihe} (PR). Sei $\rho \coloneqq \limsup \sqrt[n]{|a_{n}|}$ (also $\rho = \infty$, falls $\left( \sqrt[n]{|a_{n}|} \right)$ unbeschränkt). Die Zahl
	$$ r \coloneqq \begin{cases} 0, & \text{ falls } \rho = 0 \\ \infty, & \text{ falls } \rho = 0 \\ \frac{1}{\rho}, & \text{ falls } 0 < \rho < \infty \end{cases} $$
	hei{\ss}t der \textbf{Konvergenzradius} (KR) der Potenzreihe. 
\end{unnamedtheorem*}

Wie im Beweis von 4.1 und 7.4 aus HMI zeigt man:

\begin{satz} \label{17.3:satz}
	$\sum_{n=0}^{\infty} a_{n} \left( z - z_{n} \right)^{n}$ und $r$ seien wie oben.
	\begin{enumerate}
		\item Ist $r = 0$, so konvergiert die Potenzreihe nur für $z = z_{n}$. \label{17.3:satz-a}
		\item Ist $r = \infty$, so konvergiert die Potenzreihe in jedem $z \in \C$ absolut. \label{17.3:satz-b}
		\item Ist ~$0 < r < \infty$, so konvergiert die Potenzreihe absolut in jedem $z \in \C$ mit $|z - z_{0}| < r$ und sie divergiert für $z \in \C$ mit $|z - z_{0}| > r$. Für $z \in \C$ mit $|z - z_{0}| = r$ ist keine allgemeine Aussage möglich. \label{17.3:satz-c} % todo Bild Seite 9
		\item Sei $r > 0$ und $D \coloneqq \{ z \in \C: |z - z_{0}| < r \}$ ($D \coloneqq \C$ falls $r = \infty$). Sei für $z \in D$: 
			$$ f(z) \coloneqq \sum_{n=0}^{\infty} a_{n} (z - z_{0})^{n}. $$
			Dann ist $f$ auf $D$ stetig. \label{17.3:satz-d}
	\end{enumerate}
\end{satz}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $\sum_{n=0}^{\infty} z^{n}$ hat den Konvergenzradius $r = 1$.
		\item Die Potenzreihen 
			$$ \sum_{n=0}^{\infty} \frac{z^{n}}{n!}, ~ \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n}}{(2n)!} \text{ und } \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n+1}}{(2n + 1)!} $$
			haben jeweils den Konvergenzradius $r = \infty$.
	\end{enumerate}	
\end{beispiele}


\begin{unnamedtheorem*}[Erinnerung]
	Für $z = x + iy ~(x, y \in \R)$ $e^{z} = e^{x} \left( \cos y + i \sin y \right)$,
		$$ \cos z \coloneqq \frac{1}{2} \left( e^{iz} + e^{-iz} \right), ~ \sin z = \frac{1}{2i} \left( e^{iz} - e^{-iz} \right) $$
\end{unnamedtheorem*}


\begin{satz} ~\ \label{17.4:satz}
	\begin{enumerate} 
		\item Für alle $z \in \C$: $e^{z} = \sum_{n=0}^{\infty} \frac{z^{n}}{n!}, ~ \sin z = \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n+1}}{(2n+1)!}, ~ \cos z = \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{2n}}{(2n)!}$
		\item Die Funktionen $e^{z}$, $\cos z$, $\sin z$ sind auf $\C$ stetig.
		\item $\sum_{n=0}^{\infty} \left( - z^{2} \right)^{n} = \sum_{n=0}^{\infty} (-1)^{n} z^{2n} = 1 - z^{2} + z^{4} - z^{6} + \dotsc$ hat den Konvergenzradius $r = 1$. Es gilt für $|z| < 1$: $\sum_{n=0}^{\infty} \left( -z^{2} \right)^{n} = \frac{1}{1 - \left(-z^{2}\right)} = \frac{1}{1 + z^{2}}$
	\end{enumerate}
	
	\begin{proof} ~\
		\begin{enumerate}
			\item ohne Beweis.
			\item folgt aus a) und $\ref{17.3:satz-d}$.
		\end{enumerate}
	\end{proof}
\end{satz}

\textbf{Fourierreihen im Komplexen}

\begin{definition}
	Seien $a, b \in \R$ mit $a < b$ und $g \colon [a, b] \rightarrow \C$ eine Funktion mit  
	$$ u \coloneqq \operatorname{Re} g : [a, b] \rightarrow \R, ~ v \coloneqq \operatorname{Im} g : [a, b] \rightarrow \R, $$
	es ist also $f(x) = u(x) + i v(x)$. Sind $u, v \in R\left([a, b]\right)$ so schreiben wir $f \in R\left([a, b], \C \right)$ und definieren
		$$ \int_{a}^{b} f(x) dx \coloneqq \int_{a}^{b} u(x) dx + i \int_{a}^{b} v(x) dx $$
\end{definition}


\begin{bemerkung}
	Ist auch $h \in R\left( [a, b], \C \right)$ und $\alpha, \beta \in \C$, so gilt
	\begin{enumerate}
		\item $\alpha g + \beta h \in R\left([a, b], \C\right)$, $g h \in R\left([a, b], \C \right)$ und
		\item $\int_{a}^{b} \alpha g + \beta h dx = \alpha \int_{a}^{b} g dx + \beta \int_{a}^{b} h dx$.
	\end{enumerate}	
\end{bemerkung}

\index{Fourierkoeffizienten}
\begin{definition}
	Sei $f \in R\left([a, b], \R \right)$. Dann hei{\ss}en für $n \in \Z$
		$$ c_{n} \coloneqq \frac{1}{2\pi} \int_{-\pi}^{\pi} f(x) e^{-inx} dx $$
	die komplexen \textbf{Fourierkoeffizienten} von $f$ und $\sum_{n=-\infty}^{\infty} c_{n} e^{inx}$ hei{\ss}t die zu $f$ gehörende komplexe Fourierreihe (Schreibweise: $f \sim \sum_{n=-\infty}^{\infty} c_{n} e^{inx}$).
\end{definition}
	
	Sei $f \in R\left([-\pi, \pi]\right)$ (reellwertig) und $a_{n} ~(n \in \N_{0})$, $b_{n} ~(n \in \N)$ die zugehörigen Fourierkoeffizienten (wie in \S13). Dann gilt für $n \in \N$:
	\begin{align*}
		c_{n} & = \frac{1}{2\pi} \int_{-\pi}^{\pi} f(x) \left( \cos(nx) - i \sin(nx) \right) dx = \frac{1}{2} \left( a_{n} - i b_{n} \right), \\
		c_{0} & = \frac{1}{2\pi} \int_{-\pi}^{\pi} f(x) 1 dx = \frac{1}{2} a_{0}, \\
		c_{-n} & = \frac{1}{2\pi} \int_{-\pi}^{\pi} f(x) e^{inx} dx = \frac{1}{2} \left( a_{n} + i b_{n} \right).
	\end{align*} 
	Also 
	$$ \sum_{k=-n}^{n} c_{k} e^{ikx} = \frac{a_{0}}{2} + \sum_{k=1}^{n} \left( c_{k} e^{ikx} + c_{-k} e^{-ikx} \right). $$ 
	Wegen
	\begin{align*}
		c_{k} e^{ikx} + e_{-k} e^{-ikx} & = \cos(kx) \left( c_{k} + c_{-k} \right) + i \sin(kx) \left( c_{k} - c_{-k} \right) \\
		& = a_{k} \cos(kx) + i (-i b_{n}) \sin(kx) \\
		& = a_{k} \cos(kx) + b_{k} \sin(kx)
	\end{align*}
	folgt
	$$ \sum_{k=-n}^{n} c_{k} e^{ikx} = \frac{a_{0}}{2} + \sum_{k=1}^{n} a_{k} \cos(kx) + b_{k} \sin(kx). $$

\begin{definition}
	Sei $(c_{n})$ eine Folge in $\C$ und $x \in \R$.
		$$ \sum_{k=-\infty}^{\infty} c_{n} e^{inx} \text{ konvergiert } \iff \lim_{n \rightarrow \infty} \sum_{k=-n}^{n} c_{k} e^{ikx} \text{ existiert (und ist} \in \C) $$
\end{definition}


\begin{bemerkung}
	Ist $f \in R\left([-\pi, \pi]\right)$ (reellwertig) und $x \in \R$, so gilt also: Die komplexe Fourierreihe konvergiert in $x \iff$ Die reelle Fourierreihe konvergiert in $x$.	
\end{bemerkung}


\chapter{Differentialrechnung im \texorpdfstring{$\R^{n}$}{Rn} (reellwertige Funktionen)}


\begin{beispiele} ~\
	\begin{enumerate}
		\item Für $(x, y) \in \R^{2}$ sei $f(x, y) = x^{2}y^{2}$. Fasst man (vorübergehend) $y$ als Konstante auf, so kann man den Ausdruck $x^{2}y^{2}$ nach $x$ differenzieren. Diese Ableitung wird mit $f_{x}(x, y)$ oder mit $\frac{\partial f}{\partial x} (x, y)$ bezeichnet. Also:
			$$ f_{x}(x, y) = 2xy^{2} = \frac{\partial f}{\partial x}(x, y). $$
			Zum Beispiel: $f_{x}(1, 2) = 2 \cdot 1 \cdot 2^{2} = 8$. Entsprechend fasse $x$ als Konstante auf und differenziere nach $y$:
			$$ f_{y}(x, y) = 2 x^{2} y = \frac{\partial f}{\partial y}(x, y). $$
			Zum Beispiel: $f_{y}(1, 2) = 2$.
		\item $f(x, y, z) = xz+ e^{xyz}$. Fasst man $y$ und $z$ als Konstanten auf und differenziert man nach $x$:
			$$ f_{x}(x,y,z) = z + yze^{xyz} = \frac{\partial f}{\partial x}(x, y, z). $$
			Entsprechend: 
			\begin{align*}
				f_{y}(x, y, z) &= xze^{xyz} = \frac{\partial f}{\partial y}(x, y, z) \\
				f_{z}(x, y, z) &= x + xye^{xyz} = \frac{\partial f}{\partial z}(x, y, z)
			\end{align*}
	\end{enumerate}	
\end{beispiele}


\begin{vereinbarung}
	I. d. $\S$en sei stets: $\emptyset \neq D \subseteq \R^{n}$, $D$ offen und $f \colon D \rightarrow \R$ eine Funktion.
\end{vereinbarung}

\index{Partielle Ableitung} \index{differenzierbar!partiell}
\begin{definition} % todo Bild Seite 12
	Sei $x_{0} = (\xi_{1}, \dotsc, \xi_{n}) \in D$ und $i \in \{1, \dotsc, n \}$. $e_{i} = (0, \dotsc, 0, 1, 0, \dotsc, 0)$ ($i$-ter Einheitsvektor). Dann gilt
	$$ x_{0} + t e_{i} = (\xi_{1}, \dotsc, \xi_{i-1}, \xi_{i} + t, \xi_{i+1}, \dotsc, \xi_{n}) .$$
	$f$ hei{\ss}t \textbf{in $x_{0}$ partiell differenzierbar (pdb) nach $x_{i}$} $:\iff$ es existiert der Grenzwert
		$$ f_{x_{i}}(x_{0} \coloneqq \frac{\partial f}{\partial x_{i}} (x_{0}) = \lim_{t \rightarrow 0} \frac{f(x_{0} + t e_{i}) - f(x_{0})}{t} $$
	und ist $\in \R$. I.d. Fall hei{\ss}t $f_{x_{i}}(x_{0})$ die \textbf{partielle Ableitung von $f$ in $x_{0}$ nach $x_{i}$}.
\end{definition}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $f(x,y) = \begin{cases} \frac{xy}{x^{2}+y^{2}}, & \text{für } (x, y) \neq (0,0) \\ 0, & \text{für } (x, y) = (0, 0) \end{cases}$, $x_{0} = (0,0)$, $x_{0} + te_{1} = (t, 0)$.
			$$ \frac{f(x_{0} + te_{1}) - f(x_{0})}{t} = \frac{f(t, 0) - f(0,0)}{t} = 0 \rightarrow 0 \quad (t \rightarrow 0) $$
			Das hei{\ss}t $f$ ist in $(0,0)$ partiell differenzierbar nach $x$ und $f_{x}(0,0) = 0$. Für ~\\
			$x_{0} + te_{2} = (0, t)$:
			$$ \frac{f(x_{0} + t_{1}e_{2}) - f(x_{0})}{t} = \frac{f(0, t) - f(0, 0)}{t} = 0 \longrightarrow 0 \quad (t \rightarrow 0) $$
			D.h. $f$ ist zu $(0,0)$ partiell differenzierbar nach $y$ und $f_{y}(0, 0) = 0$.
		\item $f(x, y) = \sqrt{x^{2} + y^{2}} = \|(x, y) \|$. Für $(x, y) \neq (0, 0)$:
			$$ f_{x}(x, y) = \frac{x}{\sqrt{x^{2} + y^{2}}}, \quad f_{y}(x,y) = \frac{y}{\sqrt{x^{2} + y^{2}}} $$
			Sei $(x, y) = (0, 0)$:
			$$ \frac{f(t,0) - f(0,0)}{t} = \frac{\sqrt{t^{2}}}{t} = \frac{|t|}{t} = \begin{cases}1, & t > 0 \\ -1, & t < 0 \end{cases} $$
			D.h. $f$ ist in $(0,0)$ nicht partiell differenzierbar nach $x$. Analog: $f$ ist in $(0,0)$ nicht partiell differenzierbar nach $y$.
	\end{enumerate}
\end{beispiele}

\index{differenzierbar!partiell} \index{Gradient}
\begin{definition} ~\
	\begin{enumerate}
		\item $f$ hei{\ss}t \textbf{in $x_{0} \in D$ partiell differenzierbar} $:\iff f$ ist in $x_{0}$ partiell differenzierbar nach allen Variablen $x_{1}, \dotsc, x_{n}$. In diesem Fall hei{\ss}t
			$$ \operatorname{grad} f(x_{0}) \coloneqq \left( f_{x_{1}}(x_{0}), \dotsc, f_{x_{n}}(x_{0})\right) $$
			der \textbf{Gradient von $f$ in $x_{0}$}.
		\item $f$ hei{\ss}t \textbf{auf $D$ partiell differenzierbar} $:\iff f$ ist in jedem $x \in D$ partiell differenzierbar.
		\item Sei $i \in \{1, \dotsc, n\}$. \textbf{$f_{x_{i}}$ ist auf $D$ vorhanden} $:\iff f$ ist in jedem $x \in D$ partiell differenzierbar nach $x_{i}$. In diesem Fall hei{\ss}t 
			$$ f_{x_{i}} \colon D \rightarrow \R $$
			die partielle Ableitung von $f$ nach $x_{i}$.
		\item $f$ hei{\ss}t \textbf{auf $D$ stetig partiell differenzierbar} $:\iff f$ ist auf $D$ partiell differenzierbar und $f_{x_{1}}, \dotsc, f_{x_{n}} \in C\left(D, \R\right)$.
	\end{enumerate}
\end{definition}


\begin{beispiele} ~\
	\begin{enumerate}
		\item Sei $f$ wie in obigem Beispiel a). $f$ ist in $(0,0)$ partiell differenzierbar und 
		$$ \operatorname{grad} f(0,0) = (0, 0). $$
		\item $f(x, y) = \sqrt{x^{2} + y^{2}}$. $f$ ist auf $\R^{2} \setminus \{ (0,0) \}$ partiell differenzierbar und
			$$ \operatorname{grad} f(x, y) = \frac{(x, y)}{\|(x, y) \|}.$$
	\end{enumerate}
\end{beispiele}

\index{Partielle Ableitung!2. Ordnung} \index{Partielle Ableitung!höherer Ordnung}
\begin{definition}
	Sei $i \in \{1, \dotsc, n \}$ und $f_{x_{i}}$ sei auf $D$ vorhanden. Also haben wir die partielle Ableitung von $f$ nach $x_{i}$:
	$$ f_{x_{i}} \colon D \rightarrow \R. $$
	Sei $x_{0} \in D$ und $j \in \{1, \dotsc, n \}$. Ist $f_{x_{i}}$ in $x_{0}$ partiell differenzierbar nach $x_{j}$, so hei{\ss}t
	$$ f_{x_{i} x_{j}} (x_{0}) \coloneqq \frac{\partial^{2} f}{\partial x_{j} \partial x_{i}} (x_{0}) \coloneqq \left( f_{x_{i}} \right)_{x_{j}} (x_{0}) $$
	\textbf{partielle Ableitung 2. Ordnung von $f$ in $x_{0}$ nach $x_{i}$ und $x_{j}$}. Entsprechend definiert man Ableitungen höherer Ordnung, falls vorhanden! Schreibweisen:
	$$ \frac{\partial^{3} f}{\partial y \partial x^{2}} = f_{xxy}, \quad \frac{\partial^{7} f}{\partial y^{4} \partial x^{3}} = f_{xxxyyyy}, \quad \frac{\partial^{5} f}{\partial z^{2} \partial y \partial x^{2}} = f_{xxyzz}. $$
\end{definition}


\begin{beispiel*}
	$f(x,y,z) =  x y^{2} \sin z$
	$$ f_{x} = y^{2} \sin z, ~\quad f_{xy} = 2y \sin z, \quad f_{xyz} = 2y \cos z, $$
	$$ f_{y} = 2xy \sin z, \quad f_{yx} = 2y \sin z, \quad f_{yxz} = 2 y \cos z. $$
\end{beispiel*}

\index{differenzierbar!stetig partiell}
\begin{definition}
	Sei $m \in \N$: $f$ hei{\ss}t \textbf{auf $D$ $m$-mal stetig partiell differenzierbar} $:\iff$ alle partiellen Ableitungen von $f$ der Ordnung $\leq m$ sind auf $D$ vorhanden und dort stetig. ~\\
	Bezeichnung in diesem Fall: $f \in C^{m}(D, \R)$.
\end{definition}

Ohne Beweis:

\begin{unnamedtheorem}[Satz von Schwarz] \label{18.1:satz}
	Sei $m \in \N$ und $f \in C^{m}(D, \R)$. Dann ist jede partielle Ableitung von $f$ der Ordnung $\leq m$ unabhängig von der Reihenfolge der Differentiation.
\end{unnamedtheorem}

Ist z.B. $m = 2$, so gilt $\forall x \in D$ $\forall i, j \in \{1, \dotsc n\}$:
	$$ f_{x_{i} x_{j}} (x) = f_{x_{j} x_{i}}(x) $$

\begin{motivation}
	$f(x, y) \coloneqq \begin{cases} \frac{xy}{x^{2} + y^{2}}, & \text{für } (x, y) \neq (0, 0) \\ 0, & \text{für } (x, y) = (0, 0). \end{cases}$ 
	
	\bigskip
	
	Bekannt: $f$ ist in $(0, 0)$ partiell differenzierbar $\xRightarrow[]{\ref{16.3:bsp}} f$ ist in $(0,0)$ nicht stetig.
\end{motivation}

Wir suchen einen Differenzierbarkeitsbegriff, der Stetigkeit nach sich zieht.

\begin{erinnerung}
	Sei $I \subseteq \R$ ein Intervall, $g \colon I \rightarrow \R$ eine Funktion und $x_{0} \in I$.
	
	\begin{align*}
		\text{$g$ ist in $x_{0}$ differenzierbar} & \iff \exists a \in \R: \lim_{h \rightarrow 0} \frac{g(x_{0} + h) - g(x_{0})}{h} = a \\
		& \iff \exists a \in \R: \lim_{h \rightarrow 0} \frac{g(x_{0} + h) - g(x_{0}) - a h}{h} = 0 \\
		& \iff \exists a \in \R: \lim_{h \rightarrow 0} \frac{g(x_{0} + h) - g(x_{0}) - ah}{|h|} = 0
	\end{align*}	
\end{erinnerung}

\index{differenzierbar}
\begin{definition}
	$f$ hei{\ss}t \textbf{in $x_{0} \in D$ differenzierbar} (db)
	$$ :\iff \exists a \in \R^{n}: ~ \lim_{h \rightarrow 0} \frac{f(x_{0} + h) - f(x_{0}) - a \cdot h}{\| h \|} = 0 $$
	$$ \left( \iff \exists a \in \R^{n}: ~\lim_{x \rightarrow x_{0}} \frac{f(x) - f(x_{0}) - a \cdot (x - x_{0})}{\| x - x_{0} \|} = 0 \right) $$
	wobei \enquote{$\cdot$} das Skalarprodukt bezeichnet.
\end{definition}

\index{Ableitung}
\begin{unnamedtheorem}[Satz und Definition (ohne Beweis)] \label{18.2:satz}
	Sei $x_{0} \in D$. 
	\begin{enumerate}
		\item Ist $f$ in $x_{0}$ differenzierbar, so ist $f$ in $x_{0}$ stetig und partiell differenzierbar.
		\item Ist $f$ in $x_{0}$ differenzierbar, so ist der Vektor $a$ in obiger Definition eindeutig bestimmt und es gilt $a = \operatorname{grad} f(x_{0})$.
			$$ f'(x_{0}) \coloneqq a = \operatorname{grad} f(x_{0}) $$
			hei{\ss}t \textbf{Ableitung} von $f$ in $x_{0}$.
		\item $f$ ist in $x_{0}$ differenzierbar $\iff f$ ist in $x_{0}$ partiell differenzierbar und
			$$ \lim_{h \rightarrow 0} \frac{f(x_{0} + h) - f(x_{0}) - \operatorname{grad} f(x_{0}) \cdot h}{\| h \|} = 0. $$
	\end{enumerate}
\end{unnamedtheorem}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $f(x, y) = \begin{cases} \frac{xy}{x^{2} + y^{2}}, & (x, y) \neq (0, 0) \\ 0, & (x, y) = (0, 0) \end{cases}$
		
			\bigskip
			
			Bekannt: $f$ ist in $(0, 0)$ nicht stetig $\xRightarrow[]{\ref{18.2:satz}} f$ ist in $(0, 0)$ nicht differenzierbar.
		\item $f(x, y) = \begin{cases} \left( x^{2} + y^{2} \right) \log \left( x^{2} + y^{2} \right), & (x, y) \neq (0, 0) \\ 0, & (x, y) = (0, 0) \end{cases}$
			\begin{align*}
				\frac{f(t, 0) - f(0, 0)}{t} & = \frac{t^{2} \log t^{2}}{t} = 2 t \log |t| \longrightarrow 0 ~(t \rightarrow 0) \\
				\frac{f(0, t) - f(0, 0)}{t} & = 2 t \log |t| \longrightarrow 0 ~(t \rightarrow 0)
			\end{align*}
			$f$ ist also partiell differenzierbar in $(0, 0)$ und $\operatorname{grad} f(0, 0) = (0, 0)$, Sei $h = (h_{1}, h_{2}) \neq (0, 0)$
			$$ \frac{f(h) - f(0, 0) - \operatorname{grad} f(0, 0) \cdot h}{\| h \|} = \frac{\|h\|^{2} \log \left( \|h\|^{2} \right)}{\|h\|} = 2 \|h\| \log \left( \|h\| \right) \longrightarrow 0 ~ (h \rightarrow 0) $$
			$f$ ist also in $(0, 0)$ differenzierbar und $f'(0, 0) = (0, 0)$.
		\item $f(x, y) = \begin{cases} \frac{x \sin y}{\sqrt{x^{2} + y^{2}}}, & (x, y) \neq (0, 0) \\ 0, & (x, y) = (0, 0) \end{cases}$
			$$ \frac{f(t, 0) - f(0, 0)}{t} = \frac{f(0, t) - f(0, 0)}{t} = 0 \longrightarrow 0 ~ (t \rightarrow 0) $$
			$f$ ist also partiell differenzierbar in $(0, 0)$ und $\operatorname{grad} f(0,0) = (0, 0)$. Sei $h = (h_{1}, h_{2}) \neq (0, 0)$
			$$ Q(h) \coloneqq \frac{f(h) - f(0, 0) - \operatorname{grad}f(0, 0) \cdot h}{\| h \|} = \frac{h_{1} \sin h_{2}}{\|h\|^{2}} = \frac{h_{1} \sin h_{2}}{h_{1}^{2} + h_{2}^{2}} $$
			Für $h_{1} = h_{2}$: 
			$$ Q(h) = \frac{h_{1} \sin h_{1}}{2 h_{1}^{2}} = \frac{1}{2} \cdot \frac{\sin h_{1}}{h_{1}} \longrightarrow \frac{1}{2} ~ (h_{1} \rightarrow 0) $$
			D.h. $Q(h) \not\rightarrow 0 ~(h \rightarrow 0)$. $f$ ist also in $(0, 0)$ nicht differenzierbar. % todo Bild Seite 17
	\end{enumerate}	
\end{beispiele}

\index{differenzierbar}
\begin{definition}
	$f$ hei{\ss}t \textbf{auf $D$ differenzierbar} $:\iff f$ ist in jedem $x \in D$ differenzierbar.
\end{definition}


\begin{satz}[ohne Beweis] \label{18.3:satz}
	$f$ sei auf $D$ partiell differenzierbar und $f_{x_{1}}, \dotsc f_{x_{n}}$ seien in $x_0 \in D$ stetig. Dann ist $f$ in $x_{0}$ differenzierbar. Ist $f \in C^{1}(D, \R)$, so ist $f$ auf $D$ differenzierbar.
\end{satz}

\index{differenzierbar}
\begin{definition}
	Sei $I \subseteq \R$ ein Intervall und $g = (g_1, \dotsc, g_n) \colon I \rightarrow \R^{n}$ eine Funktion, also $g_{j} \colon I \rightarrow \R$ ($j = 1, \dotsc, n$).
	
	\bigskip
	
	$g$ hei{\ss}t \textbf{in $t_0 \in I$ differenzierbar} $: \iff g_1, \dotsc, g_n$ sind in $t_0 \in I$ differenzierbar. ~\\
	In diesem Fall:
	$$ g'(t_0) \coloneqq \left( g_1'(t_0), \dotsc, g_n'(t_0) \right) $$
	Entsprechend definiert man \enquote{auf $I$ differenzierbar} und \enquote{auf $I$ stetig differenzierbar}.
\end{definition}

\index{Verbindungsstrecke}
\begin{beispiele} ~\
	\begin{enumerate}
		\item $(n=2)$: $g(t) = \left( \cos t, \sin t \right)$, $g(t) = \left( -\sin t, \cos t \right)$.
		\item Für $a, b \in \R^{n}$: $g(t) \coloneqq a + t \left( b - a \right)$ $\left(t \in [0, 1]\right)$. Ist $a = (a_1, \dotsc, a_n)$, $b = (b_1, \dotsc, b_n)$, so ist
				$$ g_j(t) = a_j + t (b_j - a_j), \text{ also } g'(t) = b_j - a_j. $$
			Somit: $g'(t) = b - a$.
			% todo Bild Seite 18
	\end{enumerate}	
\end{beispiele}

\begin{bezeichnung}
	$S[a, b] \coloneqq \left\{ a + t (b - a) : t \in [0, 1] \right\}$ \textbf{Verbindungsstrecke} von $a$ und $b$.
\end{bezeichnung}


\index{Kettenregel} 
\begin{satz}[Kettenregel (ohne Beweis)] \label{18.4:satz}
	Sei $I \subseteq \R$ ein Intervall, $g = (g_1, \dotsc, g_n) \colon I \rightarrow \R^{n}$ differenzierbar in $t_{0} \in I$, $g(I) \subseteq D$ und $f$ sei in $x_{0} \coloneqq g(t_0)$ differenzierbar. Dann ist
	$$ f \circ g \colon I \rightarrow \R \text{ differenzierbar in } t_0 $$
	und $\left( f \circ g \right)'(t_0) = f'(g(t_{0})) \cdot g'(t_{0})$, wobei \enquote{$\cdot$} das Skalarprodukt darstellt.
\end{satz}

\begin{beispiel*}
	Sei $g \colon [0, 1] \rightarrow \R^{2}$, $g(t) = \left( \cos t, \sin t \right)$ und $f \colon \R^{2} \rightarrow \R$, $f(x, y) = x^{2} y$. ~\\
	Wir können direkt nachrechnen: $\left( f \circ g \right) (t) = \cos^{2}t \sin t$, 
		$$ \left( f \circ g \right)'(t) = 2 \cos t \left( - \sin t \right) \sin t + \cos^{2} t \cos t = - 2 \cos t \sin^{2} t + \cos^{3} t. $$
	Mit \ref{18.4:satz} gilt: $f'(x,y) = \left( 2 x y, x^{2} \right)$,
	$$ \left( f \circ g \right)'(t) = \left( 2 \cos t \sin t , \cos^{2} t \right) \cdot \left( - \sin t, \cos t \right) = - 2 \cos t \sin^{2} t + \cos^{3} t. $$
\end{beispiel*}

\index{Streckenzug}
\begin{definition} ~\
	\begin{enumerate}
		\item Seien $x^{(0)}, \dotsc, x^{(m)} \in \R^{n}$,
			$$ S\left[x^{(0)}, \dotsc, x^{(m)}\right] = \bigcup_{j=1}^{m} S\left[x^{(j-1)}, x^{(j)}\right] $$
			hei{\ss}t \textbf{Streckenzug} durch $x^{(0)}, \dotsc, x^{(m)}$.
			% todo Bild Seite 19
		\item Sei $M \subseteq \R^{n}$. $M$ hei{\ss}t ein \textbf{Gebiet} $: \iff M$ ist offen und zu je zwei Punkten $a, b \in M$ existieren $x^{(0)}, \dotsc, x^{(m)} \in M$ mit:
			$$ a = x^{(0)}, b = x^{(x)} \text{ und } S \left[ x^{(0)}, \dotsc, x^{(m)} \right] \subseteq M. $$
			% todo Bild Seite 19
	\end{enumerate}
\end{definition}


\begin{unnamedtheorem}[Der Mittelwertsatz] \label{18.5:mws}
	Sei $f \colon D \rightarrow \R$ auf $D$ differenzierbar, es seien $a, b \in D$ und $S[a, b] \subseteq D$. Dann existiert ein $\xi \in S[a, b]$:
	$$ f(b) - f(a) = f'(\xi) \cdot (b - a). $$
	% todo Bild Seite 20 
	\begin{proof}
		Für $t \in [0, 1]$ sei
		\begin{align*}
			g(t) & \coloneqq a + t (b - a) \\
			\phi(t) & \coloneqq f \left( g (t) \right)
		\end{align*}
		$\xRightarrow[]{\ref{18.4:satz}}$ $\phi$ ist auf $[0, 1]$ differenzierbar und $\phi'(t) = f'(g(t)) \cdot g'(t) = f'(g(t)) \cdot ( b - a)$. Es ist
		\begin{align*}
			f(b) - f(a) & = f(g(1)) - f(g(0)) = \phi(1) - \phi(0) \\
						& = \frac{\phi(1) - \phi(0)}{1 - 0} \overset{MWS}{\underset{HM I}{=}} \phi'(t_{0}),
		\end{align*}
		für ein $t_{0} \in [0, 1]$. Also: $f(b) - f(a) = f'\big( \underbrace{g(t_{0})}_{\eqqcolon \xi}\big) \cdot ( b - a)$.
	\end{proof}
\end{unnamedtheorem}


\begin{folgerung} \label{18.6:folg}
	Ist $D$ ein Gebiet, $f \colon D \rightarrow \R$ differenzierbar auf $D$ und $\forall x \in D$ gilt $f'(x) = 0$, so ist $f$ auf $D$ konstant.
	
	\begin{proof}
		Übung, mit \ref{18.5:mws}.
	\end{proof}
\end{folgerung}

\index{Richtung} \index{Richtungsvektor} \index{differenzierbar!in Richtung} \index{Richtungsableitung}
\begin{definition} ~\
	\begin{enumerate}
		\item Sei $a \in \R^{n}$. Ist $\| a \| = 1$, so hei{\ss}t $a$ eine \textbf{Richtung} oder ein \textbf{Richtungsvektor}.
		\item Sei $x_{0} \in D$ und $a \in \R^{n}$ eine Richtung. $f$ hei{\ss}t in $x_{0}$ Richtung $a$ differenzierbar $: \iff$ es existiert der Grenzwert
		$$ \frac{\partial f}{\partial a}(x_{0}) \coloneqq \lim_{t \rightarrow 0} \frac{f(x_{0} + t a ) - f(x_{0})}{t} $$
		und ist $\in \R$. In diesem Fall hei{\ss}t $\frac{\partial f}{\partial a}(x_{0})$ die \textbf{Richtungsableitung von $f$ in $x_{0}$ in Richtung $a$}.
		% todo Bild Seite 21
	\end{enumerate}
\end{definition}


\begin{bemerkung}
	Ist $a = e_{i} = i$-ter Einheitsvektor, so ist (falls vorhanden)
		$$ \frac{\partial f}{\partial a} (x_{0}) = \frac{\partial f}{\partial x_{i}}(x_{0}) = f_{x_{i}}(x_{0}). $$
\end{bemerkung}


\begin{beispiele} ~\
	\begin{enumerate}
		\item Sei $x_{0} = (0, 0)$ und 
			$$ f(x, y) \coloneqq \begin{cases} \frac{xy}{x^{2} + y^{2}}, & (x, y) \neq (0, 0) \\ 0, & (x, y) = (0, 0). \end{cases}$$ Sei $a = (a_{1}, a_{2}) \in \R^{2}$ eine Richtung, also $a_{1}^{2} + a_{2}^{2} = 1$.
			$$ \frac{f(ta) - f(0, 0)}{t} = \frac{1}{t} \cdot \frac{t^{2} a_{1} a_{2}}{t^{2}} = \frac{a_{1} a_{2}}{t} $$
			D.h. $\frac{\partial f}{\partial a}(0, 0)$ existiert $\iff a_{1} = 0$ oder $a_{2} = 0$
			$$ \iff a \in \left\{ (1, 0), (-1, 0), (0, 1), (0, -1) \right\}. $$
			In diesem Fall: $\frac{\partial f}{\partial a}(0, 0) = 0$.
		\item Sei $x_{0} \coloneqq (0, 0)$ und
			$$ f(x, y) \coloneqq \begin{cases} \frac{xy^{2}}{x^{2} + y^{4}}, & \text{für } (x, y) \neq (0, 0) \\ 0, & \text{für } (x, y) = (0, 0). \end{cases} $$
			Sei $a = (a_{1}, a_{2}) \in \R^{2}$ eine Richtung.
			$$ \frac{f(ta) - f(0,0)}{t} = \frac{1}{t} \cdot \frac{r^{3} a_{1} a_{2}^{2}}{t^{2} a_{1}^{2} + t^{4} a_{2}^{4}} = \frac{a_{1} a_{2}^{2}}{a_{1}^{2} + t^{2} a_{2}^{4}} \xrightarrow[t \rightarrow 0]{\qquad} \begin{cases} 0, & a_{1} = 0 \\ \frac{a_{2}^{2}}{a_{1}}, & a_{1} \neq 0. \end{cases} $$
			D.h. $\frac{\partial f}{\partial a}(0,0)$ existiert für jede Richtung $a \in \R^{2}$.
			
			\bigskip
			
			Aber: Sei $x > 0$. $f(x, \sqrt{x}) = \frac{x^{2}}{2 x^{2}} = \frac{1}{2} \rightarrow \frac{1}{2} \neq 0 = f(0, 0)$ $(x \rightarrow 0)$. D.h. $f$ ist in $(0, 0)$ nicht stetig.
	\end{enumerate}	
\end{beispiele}


\begin{satz}[ohne Beweis] \label{18.7:satz}
	Ist $f$ in $x_{0} \in D$ differenzierbar und $a \in \R^{n}$ eine Richtung, so existiert $\frac{\partial f}{\partial a}(x_{0})$ und
	$$ \frac{\partial f}{\partial a} (x_{0}) = a \cdot \operatorname{grad} f(x_{0}) $$
\end{satz}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $f$ sei wie in obigem Beispiel b). $x_{0} = (0, 0)$; $a \coloneqq \frac{1}{\sqrt{2}} (1, 1)$. Dann:
			$$ \frac{\partial f}{\partial a} (0,0) = \frac{1}{\sqrt{2}}, \operatorname{grad} f(0,0) = (0, 0), $$
			also
			$$ a \cdot \operatorname{grad} f(0,0) = 0 \neq \frac{\partial f}{\partial a} (0,0) = \frac{\frac{1}{2}}{\frac{1}{\sqrt{2}}} = \frac{1}{\sqrt{2}}. $$
			$f$ ist in $(0,0)$ nicht differenzierbar!
		\item $f(x,y) \coloneqq \begin{cases} \frac{x |x| + y^{4}}{\sqrt{x^{2} + y^{2}}}, & (x, y) \neq (0, 0) \\ 0, & (x, y) = (0,0). \end{cases}$
			Übung: $f$ ist in $(0, 0)$ stetig.
			
			\bigskip
			
			Sei $a = (a_{1}, a_{2}) \in \R^{2}$ eine Richtung.
			\begin{align*}
				\frac{f(ta) - f(0,0)}{t} & = \frac{1}{t} \cdot \frac{t |t| a_{1} |a_{1}| + t^{4} a_{2}^{4}}{|t|} = \frac{t |t| a_{1} |a_{1}| + \left( t |t| \right)^{2} a_{2}^{4}}{t |t|}  \\ 
				& = a_{1} |a_{1}| + t |t| a_{2}^{4} ~\longrightarrow~ a_{1} |a_{1}| 
			\end{align*} 
			Also existiert $\frac{\partial f}{\partial a} (0, 0)$ für jede Richtung $a$ und $\frac{\partial f}{\partial a}(0, 0) = a_{1} |a_{1}|$. Insbesondere: 
				$$\operatorname{grad} f(0,0) = (1, 0). $$
			Sei $a \coloneqq \frac{1}{\sqrt{2}} (1, 1)$. Dann:
				$$ \frac{1}{2} = \frac{\partial f}{\partial a}(0, 0) \neq a \cdot \operatorname{grad} f(0, 0) = \frac{1}{\sqrt{2}}. $$
			$f$ ist also in $(0, 0)$ nicht differenzierbar.
	\end{enumerate}
\end{beispiele}

\begin{bezeichnung}
	Sei $A$ eine reelle $n \times n$-Matrix und $x \in \R^{n}$:
	$$ \left( A x \right) \cdot x \coloneqq \left( A x^{T} \right) \cdot x. $$	
\end{bezeichnung}

\index{Hesse-Matrix}
\begin{definition}
	Sei $f \in C^{2}\left( D, \R \right)$ und $x_{0} \in D$,
	$$ H_{f}(x_{0}) \coloneqq \begin{pmatrix} f_{x_{1} x_{1}}(x_{0}) & f_{x_{1} x_{2}}(x_{0}) & \dotsc & f_{x_{1} x_{n}}(x_{0}) \\ \vdots & ~ & ~ & \vdots \\ f_{x_{n} x_{1}}(x_{0}) & f_{x_{n} x_{2}}(x_{0}) & \cdots & f_{x_{n} x_{n}}(x_{0}) \end{pmatrix} $$
	hei{\ss}t \textbf{Hesse-Matrix von $f$ in $x_{0}$} $\xRightarrow[]{\ref{18.1:satz}} H_{f}(x_{0})$ ist symmetrisch.
\end{definition}


\begin{beispiel*}
	$f(x, y) = x^{3} y + x y$, ~ $f_{x} = 3 x^{2} y + y$, $f_{y} = x^{3} + x$
	$$ f_{xx} = 6xy, ~ f_{xy} = 3x^{2} + 1, ~ ~ f_{yy} = 0, f_{yx} = 3 x^{2} + 1 $$	
	Damit ist
	$$ H_{f} (x, y) = \begin{pmatrix} 6 xy & 3 x^{2} + 1 \\ 3x^{2} + 1 & 0 \end{pmatrix}. $$
\end{beispiel*}


\begin{satz}[Satz von Taylor (ohne Beweis)] \label{18.8:satz} % todo Bild Seite 24
	Sei $f \in C^{2}(D, \R)$, $x_{0} \in D$, $h \in \R^{n}$ und $S[x_{0}, x_{0} + h] \subseteq D$. Dann existiert ein $\xi \in S[x_{0}, x_{0} + h]$:
	$$ f(x_{0} + h) = f(x_{0}) + \operatorname{grad} f(x_{0}) \cdot h + \frac{1}{2} \left( H_{f}(\xi) h \right) \cdot h. $$	
\end{satz}

\index{definit!positiv} \index{definit} \index{definit!negativ} \index{definit!} \index{indefinit}
\begin{definition}
	$A$ sei eine reelle, symmetrische $n \times n$-Matrix. $A$ hei{\ss}t
	\begin{itemize}
		\item \textbf{positiv definit} (pd) $: \iff \forall x \in \R^{n} \setminus \{ 0 \}$: $\left( A x \right) \cdot x > 0$
		\item \textbf{negativ definit} (nd) $: \iff \forall x \in \R^{n} \setminus \{ 0 \}$: $\left( A x \right) \cdot x < 0$
		\item \textbf{indefinit} (id) $: \iff \exists u, v \in \R^{n}: \left( A u \right) \cdot u > 0 \text{ und } \left( A v \right) \cdot v < 0$
	\end{itemize}
\end{definition}


\begin{beispiel*}
	$A = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}$ mit $x = (x_{1}, x_{2}) \in \R^{2}$:
	$$ Ax = (x_{1}, 0), ~ \left( A x \right) \cdot x = x_{1}^{2} \geq 0. $$
	$A$ ist weder negativ definit, noch indefinit, noch positiv definit: 
	$$ \forall x = (0, t): ~ \left( Ax \right) \cdot x = 0. $$ 
\end{beispiel*}


\begin{satz}[ohne Beweis] \label{18.9:satz}
	$A$ sei wie in obiger Definition.
	\begin{enumerate}
		\item \begin{itemize}
				\item $A$ ist positiv definit $\iff$ alle Eigenwert von $A$ sind $> 0$
				\item $A$ ist negativ definit $\iff$ alle Eigenwert von $A$ sind $< 0$
				\item $A$ ist indefinit $\iff \exists$ Eigenwerte $\lambda, \mu$ von $A$ mit $\lambda > 0$, $\mu < 0$
			  \end{itemize}
		\item Sei $n = 2$, $A = \begin{pmatrix} \alpha & \beta \\ \beta & \gamma \end{pmatrix}$
			  \begin{itemize}
			  	\item $A$ ist positiv definit $\iff \alpha > 0$, $\det A > 0$
			  	\item $A$ ist negativ definit $\iff \alpha < 0$, $\det A > 0$
			  	\item $A$ ist indefinit $\iff \det A < 0$
			  \end{itemize}
	\end{enumerate}
\end{satz}

\index{Maximum!lokales} \index{Minimum!lokales} 
\begin{definition}
	$f$ hat in $x_{0} \in D$ ein 
	\begin{itemize}
		\item \textbf{lokales Maximum} $:\iff \exists \delta > 0$: $U_{\delta}(x_{0}) \subseteq D$ und $\forall x \in U_{\delta}(x_{0})$: $f(x) \leq f(x_{0})$
		\item \textbf{lokales Minimum} $:\iff \exists \delta > 0$: $U_{\delta}(x_{0}) \subseteq D$ und $\forall x \in U_{\delta}(x_{0})$: $f(x) \geq f(x_{0})$
	\end{itemize}
	\textbf{lokales Extremum} = lokales Maximum oder lokales Minimum von $f \colon M \rightarrow \R$; analog für globale Extrema.
\end{definition}


\begin{satz}[ohne Beweis] ~\ \label{18.10:satz}
	\begin{enumerate}
		\item Ist $f$ in $x_{0} \in D$ partiell differenzierbar und hat $f$ in $x_{0}$ ein lokales Extremum, so ist $\operatorname{grad} f(x_{0}) = 0$.
		\item Ist $f \in C^{2}(D, \R)$ und $\operatorname{grad} f(x_{0}) =0$, so gilt: 
			\begin{itemize}
				\item Ist $H_{f}(x_{0})$ positiv definit, so hat $f$ in $x_{0}$ ein lokales Minimum.
				\item Ist $H_{f}(x_{0})$ negativ definit, so hat $f$ in $x_{0}$ ein lokales Maximum.
				\item Ist $H_{f}(x_{0})$ indefinit, so hat $f$ in $x_{0}$ kein lokales Extremum.
			\end{itemize}
	\end{enumerate}
	
	\begin{proof}[Beweisideen] ~\
		\begin{enumerate}
			\item Ist z.B. $x_{0}$ eine lokale Maximalstelle und $i \in \{1, \dotsc, n \}$, so ist
				$$ \frac{f(x_{0} + t e_{i}) - f(x_{0})}{t} \begin{cases} ~\leq 0, & t \in (0, \delta) \\ ~\geq 0, & t \in (-\delta, 0), \end{cases} $$
				also $f_{x_{i}}(x_{0}) = 0$.
			\item Ist z.B. $H_{f}(x_{0})$ positiv definit, so ist $H_{f}(x)$ positiv definit in einer Umgebung $U_{\delta}(x_{0}) \subseteq D$ (wg. $f \in C^{2}(D, \R)$). Nach \ref{18.8:satz} gilt für $\|h\| < \delta$:
				$$ f(x_{0} + h) = f(x_{0}) + \underbrace{\left( \operatorname{grad} f(x_{0}) \right)}_{= 0} \cdot h + \underbrace{\frac{1}{2} \left( H_{f}(\xi) \cdot h \right) \cdot h}_{\geq 0} $$
				für ein $\xi \in S\left[ x_{0}, x_{0} + h \right] \subseteq U_{\delta}(x_{0})$ $\Rightarrow f(x_{0} + h) \geq f(x_{0})$.
		\end{enumerate}
	\end{proof}
\end{satz}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $D = \R^{2}$, $f(x, y) = x^{4} + y^{4}$. Somit: $f_{x} = 4x^{3}, ~ f_{y} = 4 y^{3}$;
			$$ \operatorname{grad}f(x, y) = (0, 0) ~ \iff ~ (x, y) = (0, 0) $$
			$f_{xx} = 12 x^{2}$, $f_{xy} = 0 = f_{yx}$, $f_{yy} = 12 y^{2}$; also ist
			$$ H_{f}(0, 0) = \begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix} $$
			weder positiv definit, noch negativ definit, noch indefinit! Was nun?
			$$ f(x, y) \geq 0 = f(0, 0) \quad \forall (x, y) \in \R^{2}. $$
			Also hat $f$ in $(0, 0)$ ein globales Minimum!
		\item $f(x, y) = x^{2} - y^{2}$ ($D = \R^{2}$). Somit: $f_{x} = 2x$, $f_{y} = - 2y$;
			$$ \operatorname{grad} f(x, y) = (0, 0) ~\iff~(x, y) = (0, 0) $$
			$f_{xx} = 2$, $f_{xy} = 0 = f_{yx}$, $f_{yy} = -2$; also ist
			$$ H_{f}(0, 0) = \begin{pmatrix} 2 & 0 \\ 0 & -2 \end{pmatrix} $$
			und $\det H_{f}(0, 0) = -4 < 0$. $H_{f}(0, 0)$ ist also indefinit. $f$ hat in $(0, 0)$ kein lokales Extremum. Kann man auch so sehen:
			\begin{align*}
				f(x, 0) =  ~ x^{2} ~ & \geq f(0, 0), \quad \forall x \in \R \\
				f(0, y) = - y^{2} & \leq f(0, 0), \quad \forall y \in \R 
			\end{align*}
			% todo Bild Seite 26
		\item $D = \R^{2}$, $f(x, y) = x^{3} - 12 xy + 8 y^{3}$. Somit: $f_{x} = 3 x^{2} - 12 y$, $f_{y} = -12x + 24y^{2}$; also ist
			$$ \operatorname{grad} f(x, y) = (0, 0) ~ \iff ~ x^{2} = 4y \text{ und } 2y^{2} = x $$
			$\Rightarrow 4y^{4} = 4y ~\iff~ y^{3} = 1$ oder $y = 0 \iff y = 0$ oder $y = 1$. 
			\begin{align*}
				\text{Ist } & y = 0, \text{ so ist } x = 0; ~ \operatorname{grad} f(0, 0) = (0, 0), \\
				\text{Ist } & y = 1, \text{ so ist } x = 2; ~ \operatorname{grad} f(2, 1) = (0, 0).
			\end{align*}
			Extremwertverdächtig: $(0, 0)$, $(2, 1)$.
			$$ H_{f}(x, y) = \begin{pmatrix} 6x & -12 \\ -12 & 48y \end{pmatrix} $$
			  \begin{itemize}
				\item $H_{f}(0, 0) = \begin{pmatrix} 0 & -12 \\ -12 & 0 \end{pmatrix}$; $\det H_{f}(0, 0) < 0$. 
					$$f  \text{ hat also in } (0, 0) \text{ kein Extremum.} $$ 
				\item $H_{f}(2, 1) = \begin{pmatrix} 12 & -12 \\ -12 & 48 \end{pmatrix}$; $12 > 0$, $\det H_{f}(2, 1) = 12 \cdot 48 - 12 \cdot 12 > 0$. 
					$$ f \text{ hat also in } (2, 1) \text{ ein lokales Minimum}. $$ 
			  \end{itemize}
			$(2, 1)$ ist keine globale Minimalstelle, denn z.B. $f(t, 0) = t^{3} \longrightarrow - \infty$ $(t \rightarrow -\infty)$.
		\item $f(x, y) = - 8x^{3} - 12 x^{2} + 3xy^{2} + y^{3} + 3 y^{2}$. Übung:
			$$ \operatorname{grad} f(x, y) = (0, 0) \iff (x, y) \in \{ (1, -4), (-1, 0), (0, 0) \} $$
			$f$ hat in $(0, 0)$ kein Extremum! $f$ hat in $(1, -4)$ ein lokales Maximum.
			
			\bigskip
			
			Es ist $ H_{f}(x, y) = \begin{pmatrix} -48x - 24 & 6y \\ 6y & 6x + 6y + 6 \end{pmatrix}$. Damit ist
			$$ H_{f}(-1, 0) = \begin{pmatrix} 24 & 0 \\ 0 & 0 \end{pmatrix} $$
			weder positiv definit, noch negativ definit noch indefinit! Was nun? % todo Bild Seite 27
			$$ f(-1, t) = 8 - 12 - 3 t^{2} + t^{3} + 3 t^{2} = t^{3} - 4; ~ f(-1, 0) = -4. $$
			$$ \begin{rcases} \text{für } t > 0: f(-1, t) > -4  & = f(-1, 0) \\ \text{für } t < 0: f(-1, t) < -4  & = f(-1, 0) \end{rcases} \Rightarrow f \text{ hat in } (-1, 0) \text{ kein lok. Extremum.} $$
 	\end{enumerate}	
\end{beispiele}


\begin{unnamedtheorem*}[Problem]
	Bestimme $\begin{cases} ~ \begin{rcases}  \max x^{2} + y^{2} - x : x^{2} + y^{2} \leq 1 \\ \min x^{2} + y^{2} - x : x^{2} + y^{2} \leq 1 \end{rcases} ~ \end{cases}$
		$$ D \coloneqq \left\{ (x,y) : x^{2} + y^{2} < 1 \right\}, ~ \overline{D} = \left\{ (x,y) : x^{2} + y^{2} \leq 1 \right\} $$
	$f \colon \overline{D} \rightarrow \R$, $f(x,y) = x^{2} + y^{2} - x$. $f$ ist stetig und $\overline{D}$ ist kompakt $\xRightarrow[]{\ref{16.5:satz}}$ exist. Minimum und Maximum.
	
	\bigskip

	Suche lokale Extremalstelle in $D$:
		$$ \begin{rcases} f_{x}(x, y) = 2x - 1 = 0 \\ f_{y}(x,y) = 2y = 0 ~\end{rcases} \iff (x, y) = \left( \frac{1}{2}, 0 \right) $$
	$H_{f}(x,y) = \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix}$, $H_{f}\left(\frac{1}{2}, 0\right)$ ist partiell differenzierbar.
		$$ \left( \frac{1}{2}, 0 \right) \text{ ist eine lokale Minimalstelle} $$
	Keine weiteren lokalen Extremalstellen in $D$. 
	\begin{align*}
	 	\Rightarrow \max \left\{ x^{2} + y^{2} - x : x^{2} + y^{2} \leq 1 \right\} & = \max \left\{ x^{2} + y^{2} - x : x^{2} + y^{2} = 1  \right\} \\
		 & = \max \left\{ 1 - x : x^{2} + y^{2} \leq 1  \right\} 
	\end{align*}
	Es gilt: $x^{2} + y^{2} = 1 \Rightarrow x^{2} \leq 1 \Rightarrow -1 \leq x \leq 1 \Rightarrow 1 - x \leq 2$ wegen $f(-1, 9) = 2$ folgt:
		$$ \max \left\{ x^{2} + y^{2} - x : x^{2} + y^{2} \leq 1 \right\} = 2. $$
	Ebenso: $x^{2} + y^{2} = 1 \Rightarrow 1 - x \geq 0$. Wegen $f \left( \frac{1}{2}, 0 \right) = \frac{1}{4} - \frac{1}{2} = - \frac{1}{4}$ folgt:
		$$ \min \left\{ x^{2} + y^{2} - x : x^{2} + y^{2} \leq 1 \right\} = - \frac{1}{4}. $$
\end{unnamedtheorem*}

\chapter{Differentialrechnung im \texorpdfstring{$\R^{n}$}{Rn} (vektorwertige Funktionen)}


Stets i.d. $\S$en: $\emptyset \neq D \subseteq \R^{n}$, $D$ offen und $f = (f_{1}, \dotsc, f_{n}) \colon D \rightarrow \R^{m}$ eine Funktion, also $f_{j} \colon D \rightarrow \R ~(j =1, \dotsc, m)$.

\index{differenzierbar} \index{differenzierbar!vektorwertige Funktionen} \index{Jacobimatrix} \index{Funktionalmatrix} \index{$C^{p}$}
\begin{definition} ~\
	\begin{enumerate}
		\item Sei $x_{0} \in D$. $f$ hei{\ss}t \textbf{in $x_{0}$ partiell differenzierbar} $:\iff$ alle $f_{j}$ sind in $x_{0}$ partiell differenzierbar. In diesem Fall hei{\ss}t
			$$ \frac{\partial f}{\partial x}(x_{0}) \coloneqq \frac{\partial \left( f_{1}, \dotsc, f_{m}\right)}{\partial \left( x_{1}, \dotsc, x_{n} \right)} (x_{0}) \coloneqq J_{f}(x_{0}) \coloneqq \begin{pmatrix} \frac{\partial f_{1}}{\partial x_{1}}(x_{0}) & \dotsc & \frac{\partial f_{1}}{\partial x_{n}}(x_{0}) \\ \vdots & ~& \vdots \\ \frac{\partial f_{m}}{\partial x_{1}}(x_{0}) & \dotsc & \frac{\partial f_{m}}{\partial x_{n}}(x_{0}) \end{pmatrix} $$
			die \textbf{Jacobi-} oder \textbf{Funktionalmatrix von $f$ in $x_{0}$}.
		\item Sei $p \in \N$: $f \in C^{p}(D, \R^{m}) :\iff f_{j} \in C^{p}(D, \R) ~(j = 1, \dotsc, m)$.
		\item $f$ hei{\ss}t in $x_{0} \in D$ \textbf{differenzierbar} $:\iff \exists m \times n$-Matrix:
			$$ \lim_{h \rightarrow 0} \frac{f(x_{0} + h) - f(x_{0}) - Ah}{\|h\|} = 0. $$
	\end{enumerate}
\end{definition}

\index{Ableitung}
\begin{unnamedtheorem}[Satz und Definition (ohne Beweis)] \label{19.1:satz}
	Sei $x_{0} \in D$.
	\begin{enumerate}
		\item $f$ ist in $x_{0}$ differenzierbar $\iff$ alle $f_{j}$ sind in $x_{0}$ differenzierbar. In diesem Fall:
			\begin{enumerate}
				\item $f$ ist in $x_{0}$ stetig
				\item $f$ ist in $x_{0}$ partiell differenzierbar
				\item Die Matrix $A$ in obiger Definition c) ist eindeutig bestimmt: $A = J_{f}(x_{0})$
			\end{enumerate}
		\item Ist $f$ in $x_{0}$ differenzierbar, so hei{\ss}t $f'(x_{0}) \coloneqq J_{f}(x_{0})$ die \textbf{Ableitung von $f$ in $x_{0}$}.
	\end{enumerate}
\end{unnamedtheorem}

Aus \ref{19.1:satz} und \ref{18.3:satz} folgt:

\begin{satz} \label{19.2:satz}
	Sind alle partiellen Ableitungen $\frac{\partial f_{j}}{\partial x_{k}}$ auf $D$ vorhanden und in $x_{0}$ stetig, so ist $f$ in $x_{0}$ differenzierbar. Ist $f \in C^{1}(D, \R^{m})$, so ist $f$ auf $D$ differenzierbar.
\end{satz}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $D = \R^{2}$, $f(x, y) = \Big( \underbrace{x + y}_{f_{1}}, \underbrace{xy}_{f_{2}}, \underbrace{x^{2}y}_{f_{3}} \Big)$ ($m = 3$).
			$$ \frac{\partial f_{1}}{\partial x} = 1, ~ \frac{\partial f_{1}}{\partial y} = 1, ~ \frac{\partial f_{2}}{\partial x} = y, ~ \frac{\partial f_{2}}{\partial y} = x, ~ \frac{\partial f_{3}}{\partial x} = 2xy, ~ \frac{\partial f_{3}}{\partial y} = x^{2} $$
			Also: $f'(x, y) = J_{f}(x, y) = \begin{pmatrix} 1 & 1 \\ y & x \\ 2xy & x^{2} \end{pmatrix}$.
		\item Sei $A$ eine $m \times n$-Matrix, $b \in \R^{n}$ und $f(x) \coloneqq Ax + b$ ($x \in \R^{n}$). Sei $x_{0} \in \R^{n}$:
			$$ f(x_{0} + h) - f(x_{0}) - Ah = A(x_{0} + h) + b - (Ax_{0} + b) - Ah = 0 $$
			$f$ ist also in $x_{0}$ differenzierbar und $f(x_{0}) = A \Rightarrow x_{0} \in \R^{n}$ beliebig $\Rightarrow f$ ist auf $\R^{n}$ differenzierbar und $\forall x \in \R^{n}$: $f'(x) = A$.
	\end{enumerate}
\end{beispiele}


\begin{unnamedtheorem}[Die Kettenregel (ohne Beweis)] \label{19.3:satz}
	$f \colon D \rightarrow \R^{m}$ sei in $x_{0} \in D$ differenzierbar. Es sei $\tilde{D} \subseteq \R^{m}$ offen, $f(D) \subseteq \tilde{D}$ und $g \colon \tilde{D} \rightarrow \R^{p}$ sei differenzierbar in $y_{0} \coloneqq f(x_{0})$. Dann ist
		$$ \phi \coloneqq g \circ f \colon D \rightarrow \R^{p} $$
		in $x_{0}$ differenzierbar und 
		$$ \phi'(x_{0}) = \left( g \circ f \right)'(x_{0}) = \underbrace{g'(f(x_{0})) \cdot f'(x_{0})}_{\genfrac{}{}{0pt}{}{\text{Produkt v. Matrizen!}}{\text{(Reihenfolge!)}}}  $$
\end{unnamedtheorem}


\textbf{Wichtigster Fall}: $p = 1$, also $g = g(z_{1}, \dotsc, z_{m})$ reellwertig. Dann: $\phi \colon D \rightarrow \R$,
	$$ \phi(x) = g(f(x)) = g( f_{1}(x), f_{2}(x), \dotsc, f_{m}(x)) = \phi(x_{1}, \dotsc, x_{n}) $$

\begin{align*}
	\xRightarrow[]{\ref{19.3:satz}} \operatorname{grad} \phi(x) & = \phi'(x) = g'(f(x)) \cdot f'(x) = \operatorname{grad} g(f(x)) \cdot J_{f}(x) \\
		& = \left( g_{z_{1}}(f(x)), g_{z_{2}}(f(x)), \dotsc, g_{z_{m}}(f(x)) \right) \cdot \begin{pmatrix}
			\frac{\partial f_{1}}{\partial x_{1}}(x) & \dotsc & \frac{\partial f_{1}}{\partial x_{n}}(x) \\ \vdots & ~ & \vdots \\ \frac{\partial f_{m}}{\partial x_{1}}(x) & \dotsc & \frac{\partial f_{m}}{\partial x_{n}}(x)
		\end{pmatrix}
\end{align*}

Dann:
	$$ \phi_{x_{1}}(x) = g_{z_{1}}(f(x)) \frac{\partial f_{1}}{\partial x_{1}}(x) + g_{z_{2}} \frac{\partial f_{2}}{\partial x_{1}}(x) + \dotsc + g_{z_{m}} \frac{\partial f_{m}}{\partial x_{1}}(x) $$
Allgemein $\forall j \in \{1, \dotsc, n \}$:
	$$ \phi_{x_{j}}(x) = g_{z_{1}}(f(x)) \frac{\partial f_{1}}{\partial x_{j}}(x) + g_{z_{2}} \frac{\partial f_{2}}{\partial x_{j}}(x) + \dotsc + g_{z_{m}} \frac{\partial f_{m}}{\partial x_{j}}(x) $$

\begin{beispiele} ~\
	\begin{enumerate}
		\item $n = 2$, $m = 3$, $p = 1$: $\phi(x, y) = g(x^{2}y, xy, x \sin y)$, ($g = g(z_{1}, z_{2}, z_{3})$)
			\begin{align*}
				\phi_{x}(x, y) & = g_{z_{1}}(x^{2}y, xy, x \sin y ) \cdot 2 xy + g_{z_{2}}(x^{2}y, xy, x \sin y ) \cdot y \\
				& ~\qquad + g_{z_{3}}(x^{2}y, xy, x \sin y ) \cdot \sin y  \\
				\phi_{x}(x, y) & = g_{z_{1}}(x^{2}y, xy, x \sin y ) \cdot x^{2} + g_{z_{2}}(x^{2}y, xy, x \sin y ) \cdot x + \\
				& ~\qquad g_{z_{3}}(x^{2}y, xy, x \sin y ) \cdot x \cos y 
			\end{align*}
		\item Gegeben: $f \colon \R^{2} \rightarrow \R$. Polarkoordinaten: 
			$$x = r \cos \varphi, ~ y = r \sin \varphi; $$
			
			Sei $u(r, \varphi) \coloneqq f(r \cos \varphi, r \sin \varphi)$
		 	$$ u_{r}(r, \varphi) = f_{x}(r \cos \varphi, r \sin \varphi) \cos \varphi + f_{y}(r \cos \varphi, r \sin \varphi) \sin \varphi $$
		 	$$ u_{\varphi}(r, \varphi) = f_{x}(r \cos \varphi, r \sin \varphi) \left( -r \sin \varphi \right) + f_{y}(r \cos \varphi, r \sin \varphi) r \cos \varphi $$
	\end{enumerate}
\end{beispiele}


\subsubsection*{Implizit definierte Funktionen}

\begin{motivation} ~\
	\begin{enumerate}
		\item $f(x, y) = 2 x^{3} + y$; $f(x, y) = 0 \iff y = - 2 x^{3}$. Setzt man $g(x) \coloneqq - 2x^{3}$, so gilt $\forall x \in \R$:
			$$ f(x, g(x)) = 0. $$
			Man sagt: \enquote{Die Gleichung $f(x, y) = 0$ kann nach $y$ aufgelöst werden in der Form $y = g(x)$} 
			oder \enquote{durch die Gleichung $f(x, y) = 0$ wird eine Funktion $f$ definiert mit $f(x, g(x)) = 0$}.
			
			\bigskip
			
			Also $\forall x \in \R$: $0 = f(x, g(x))$. Differenzieren nach $x$:
			$$ 0 = f_{x}(x, g(x)) \cdot 1 + f_{y}(x, g(x)) \cdot g'(x). $$
			$\Rightarrow g'(x) = - \frac{f_{x}(x, g(x))}{f_{y}(x, g(x))}$.
		\item Auch in Fällen, in denen keine \enquote{formelmä{\ss}ige} (also explizite) Auflösung der Gleichung $f(x, y) = $ nach $y$ möglich ist, kann manchmal die Existenz einer implizit definierten Funktion $g$ gesichert werden, also die Existenz einer Funktion $g$ mit $f(x, g(x)) = 0$.
	\end{enumerate}
\end{motivation}


\begin{beispiel*}
	$f(x, y) = y + xy^{2} - e^{xy}$. Unten werden wir sehen: $\exists \delta > 0$ und genau eine differenzierbare Funktion $g \colon (-\delta, \delta) \rightarrow \R$ mit $\forall x \in (-\delta, \delta)$:
	$$ f(x, g(x)) = 0 \text{ und } g(0) = 1.  $$	
	\textbf{Frage}: Was ist $g'(0)$?
	$$ 0 = f(x, g(x)) \quad \forall x \in (-\delta, \delta). $$
	Differenzieren nach $x$: $0 = f_{x}(x, g(x)) \cdot 1 + f_{y}(x, g(x)) \cdot g'(x) \xRightarrow[x = 0]{} 0 = f_{x}(0, 1) + f_{y}(0, 1) g'(0)$.
	\begin{align*}
		f_{x} & = y^{2} - y e^{xy} \Rightarrow f_{x}(0, 1) = 0, \\
		f_{y} & = 1 + 2xy - xe^{xy}, ~ f_{y}(0, 1) = 1;
	\end{align*}
	also: $g'(0) = 0$.
\end{beispiel*}

\begin{unnamedtheorem}[Spezialfall (ohne Beweis)] \label{19.4:satz}
	Sei $n = 2$, $f \in C^{1}(D, \R)$, $(x_{0}, y_{0}) \in D$, $f(x_{0}, y_{0}) = 0$ und $f_{y}(x_{0}, y_{0}) \neq 0$. Dann existiert ein $\delta > 0$ und genau eine stetig differenzierbare Funktion
	$$ g \colon (x_{0} - \delta, x_{0} + \delta ) \rightarrow \R $$
	mit $g(x_{0}) = y_{0}$ und $\forall x \in (x_{0} - \delta, x_{0} + \delta)$: $f(x, g(x)) = 0$ (\enquote{$g$ wird durch die Gleichung $f(x, y) = 0$ implizit definiert}).
\end{unnamedtheorem}

\textbf{Zurück zu obigem Beispiel}: Es ist $f(0, 1) = 0$ und $f_{y}(0, 1) = 1 \neq 0$. Also existiert ein $\delta > 0$ und genau eine stetig differenzierbare Funktion $g \colon (-\delta, \delta) \rightarrow \R$ mit $g(0) = 1$ und $\forall x \in (-\delta, \delta)$: $f(x, g(x)) = 0$. 

\bigskip

\begin{unnamedtheorem*}[Noch ein Beispiel]	
	$f(x, y) = e^{\sin(xy)} + x^{2} - 2y - 1$. ~\\
	Beh.: $\exists \delta > 0$ und genau eine stetig differenzierbare Funktion $g \colon (-\delta, \delta) \rightarrow \R$ mit $\forall x \in (-\delta, \delta)$:
	$$ f(x, g(x)) = 0 \text{ und } g(0) = 0. $$
	\begin{proof}
		$x_{0} = y_{0} = 0$. $f(0, 0) = 0$; 
	$$f_{y} = e^{\sin(xy)} \cos(xy) x - 2, ~ f_{y}(0, 0) = -2 \neq 0. $$
	Behauptung folgt aus \ref{19.4:satz}. Berechne $g'(0)$: $\forall x \in (-\delta, \delta)$
	$$ 0 = f(x, g(x)) $$
	Differenzieren nach $x$: $0 = f_{x}(x, g(x)) \cdot 1 + f_{y}(x, g(x)) \cdot g'(x)$
	$$ \xRightarrow[]{x = 0} 0 = f_{x}(0, 0) + f_{y}(0, 0) g'(0) = f_{x}(0, 0) - 2 g'(0). $$
	$f_{x} = e^{\sin(xy)} \cos(xy) \cdot y + 2x$, $f_{x}(0, 0) = 0 \Rightarrow g'(0) = 0$.
	\end{proof} 
\end{unnamedtheorem*} 

\index{Umgebung}
\begin{definition}
	Sei $x_{0} \in \R^{n}$ und $U \subseteq \R^{n}$. $U$ hei{\ss}t \textbf{Umgebung von $x_{0}$} 
	$$ :\iff \exists \delta > 0: ~ U_{\delta}(x_{0}) \subseteq U. $$
\end{definition}

Im Folgenden seien $n, p \in \N$, $\emptyset \neq D \subseteq \R^{n+p}$, $D$ offen und $f = (f_{1}, \dotsc, f_{p}) \in C^{1}(D, \R^{p}$. 

\bigskip

Die Punkte in $D$ schreiben wir in der Form $(x, y)$, wobei $x = (x_{1}, \dotsc, x_{n}) \in \R^{n}$ und $y = (y_{1}, \dotsc, y_{p}) \in \R^{p}$, also $(x, y) = (x_{1}, \dotsc, x_{n}, y_{1}, \dotsc, y_{p})$
	$$ \frac{\partial f}{\partial x} = \underbrace{\begin{pmatrix} \frac{\partial f_{1}}{\partial x_{1}} & \dotsc & \frac{\partial f_{1}}{\partial x_{n}} \\ \vdots & ~ & \vdots \\ \frac{\partial f_{p}}{\partial x_{1}} & \dotsc & \frac{\partial f_{p}}{\partial x_{n}}  \end{pmatrix}}_{p \times n\text{-Matrix}}, \qquad \frac{\partial f}{\partial y} = \underbrace{\begin{pmatrix} \frac{\partial f_{1}}{\partial y_{1}} & \dotsc & \frac{\partial f_{1}}{\partial y_{p}} \\ \vdots & ~ & \vdots \\ \frac{\partial f_{p}}{\partial y_{1}} & \dotsc & \frac{\partial f_{p}}{\partial y_{p}}  \end{pmatrix}}_{p \times p\text{-Matrix}} $$
Dann: $f'(x, y) = J_{f}(x, y) = \left( \frac{\partial f}{\partial x}(x, y), \frac{\partial f}{\partial y} (x, y) \right)$ ($p \times (n + p)$-Matrix)


\begin{unnamedtheorem}[Satz über implizit definierte Funktionen (ohne Beweis)] \label{19.5:satz}
	Sei $(x_{0}, y_{0}) \in D$, $f(x_{0}, y_{0}) = 0$ und $\det \frac{\partial f}{\partial y}(x_{0}, y_{0}) \neq 0$. Dann existiert eine offene Umgebung $U \subseteq \R^{n}$ von $x_{0}$ und genau eine Funktion $g \colon U \rightarrow \R^{p}$ mit:
	\begin{itemize}
		\item $g(x_{0}) = y_{0}$
		\item $\forall x \in U$: $(x, g(x)) \in D$
		\item $\forall x \in U$: $f(x, g(x)) = 0$ 
		\item $\forall x \in U$: $\det \frac{\partial f}{\partial y}(x, g(x)) \neq 0$
		\item $g \in C^{1}(U, \R^{p})$ und $\forall x \in U$: $g'(x) = - \left( \frac{\partial f}{\partial y}(x, g(x))\right)^{-1} \cdot \frac{\partial f}{\partial x}(x, g(x))$.
	\end{itemize}
	Zusatz: ist $f \in C^{l}(D, \R^{p})$, so ist $g \in C^{l}(U, \R^{p})$.
\end{unnamedtheorem}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $D = \R^{3}$ ($n =2$, $p = 1$)
			$$ f(x, y, z) = x^{4} + 2x \cos y + \sin z $$
			Zeige: es existiert eine offene Umgebung $U \subseteq \R^{2}$ von $(0, 0)$ und genau eine Funktion $g \colon U \rightarrow \R$ mit $\forall (x, y) \in U$:
			$$ g(0, 0) = 0 \text{ und } f(x, y, g(x, y)) = 0. $$
			Berechne $g'(0, 0)$. Lösung: $(x_{0}, y_{0}, z_{0}) = (0, 0, 0)$
			$$ f(0,0,0) = 0 ~\checkmark , \quad f_{z} = \cos z, \quad f_{z} (0,0,0) = 1 \neq 0 ~\checkmark $$
			Behauptung folgt aus \ref{19.5:satz}. Also $\forall (x, y) \in U$:
			\begin{equation*}
				0 = f(x, y, g(x, y)) = 0 \tag*{$(*)$}
			\end{equation*}
			Differenzieren von $(*)$ nach $x$:
			$$ 0 = f_{x}(x, y, g(x, y)) \cdot 1 + f_{y}(x, y, g(x,y)) \cdot 0 + f_{z}(x,y, g(x,y)) \cdot g_{x}(x, y) $$
			$\Rightarrow 0 = f_{x}(0,0,0) + f_{z}(0,0,0) f_{x}(0,0)$. Differenzieren von $(*)$ nach $y$:
			$$ 0 = f_{x}(x, y, g(x, y)) \cdot 0 + f_{y}(x, y, g(x,y)) \cdot 1 + f_{z}(x,y, g(x,y)) \cdot g_{y}(x, y) $$
			$\Rightarrow 0 = f_{y}(0,0,0) + f_{z}(0,0,0) f_{y}(0,0)$.
			$$ \Longrightarrow g_{x}(0,0) = -f_{x}(0,0,0), ~ g_{y}(0,0) = - f_{y}(0,0,0), $$ 
			$$ f_{x} = 4x^{3} + 2 \cos y, f_{y} = -2x \sin y $$
			Daraus folgt: $f_{x}(0,0,0) = 2$, $f_{y}(0,0,0) = 0 \Rightarrow g'(0,0) = (-2, 0)$.
		\item Zeige: es existiert eine Umgebung $U \subseteq \R^{2}$ von $(0,0)$ und eine stetig differenzierbare Funktion $g \colon \rightarrow \R$ mit $\forall (x, y) \in U$:
			$$ g(0, e) = 2 \text{ und } y^{2} + x g(x, y) + \left( g(x, y) \right)^{2} - e^{g(x, y)} = 4 $$
			Berechne $g_{x}(0, e)$. Lösung: $f(x, y, z) \coloneqq y^{2} + xz + z^{2} - e^{z} - 4$, $(x_{0}, y_{0}, z_{0}) = (0, e, 2)$.
			$$ f(x_{0}, y_{0}, z_{0}) = e^{2} + 0 + 4 - e^{2} - 4 = 0 ~\checkmark $$
			$$ f_{z} = x + 2z - e^{z}, \quad f_{z}(0, e, 2) = 0 + 4 - e^{2} \neq 0 ~\checkmark $$
			Behauptung folgt aus \ref{19.5:satz}. Es ist $\forall (x, y) \in U$:
			$$ 4 = y^{2} + x g(x, y) + g(x, y)^{2} - e^{g(x, y)} $$
			Differenzieren nach $x$:
			$$ 0 = g(x, y) + x g_{x}(x,y) + 2 g(x,y) g_{x}(x, y) - e^{g(x, y)} g_{x}(x, y) $$
			$\Rightarrow 0 = 2 + 4 g_{x}(0, e) - e^{2} g_{x}(0, e) = 2 + \left( 4 - e^{2} \right) g_{x}(0, e) \Rightarrow g_{x}(0, e) = \frac{2}{e^{2} - 4}$.
	\end{enumerate}
\end{beispiele}


\begin{unnamedtheorem}[Der Umkehrsatz (ohne Beweis)] \label{19.6:satz}
	Sei $D \subseteq \R^{n}$ offen und $f \in C^{1}(D, \R^{n})$. Ist $x_{0} \in D$ und $\det f'(x_{0}) \neq 0$, so existiert eine offene Umgebung $U \subseteq D$ von $x_{0}$: 
	\begin{enumerate}
		\item $f(U)$ ist offen;
		\item $f$ ist auf $U$ injektiv,
		\item $f^{-1}: f(U) \rightarrow U$ ist in $C^{1}( f(U), \R^{n})$, mit $\det f'(x) \neq 0 ~\forall x \in U$ und 
			$$ \left( f^{-1} \right)'(y) = \left( f'(x) \right)^{-1} \quad \forall y = f(x) ~(x \in U). $$
			d.h. $\left( f^{-1} \right)'(y) = \left( f' \left( f^{-1}(y) \right) \right)^{-1}$ ($y \in f(U)$).
	\end{enumerate}
\end{unnamedtheorem}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $D = \R^{2}$, $f(x, y) = \left( x \cos y, x \sin y \right)$
			$$ f'(x, y) = \begin{pmatrix} \cos y & - x \sin y \\ \sin y & x \cos y \end{pmatrix} $$
			$\det f'(x, y) = x \cos^{2} y + x \sin^{2} y = x \neq 0 \iff x \neq 0$.
			
			\bigskip
			
			$\tilde{D} \coloneqq \{ (x, y) \in \R^{2} : x \neq 0 \}$. Sei $(x_{0}, y_{0}) \in \tilde{D} \xRightarrow[]{\ref{19.6:satz}} \exists$ offene Umgebung $U$ von $(x_{0}, y_{0})$: $f$ ist auf $U$ injektiv, 
			% todo Bild Seite 38
			$f$ ist aber auf $\tilde{D}$ nicht injektiv:
			$$ f(x, y) = f(x, y + 2k\pi) \quad \forall k \in \Z $$
			% todo Bild Seite 38
			$(x_{0}, y_{0}) \coloneqq \left( 1, \frac{\pi}{2} \right)$. $f\left(1, \frac{\pi}{2} \right) = (0, 1)$, also $f^{-1}(0, 1) = \left(1, \frac{\pi}{2} \right)$
			$$ \left( f^{-1} \right)'(0,1) = \left( f'\left(1, \frac{\pi}{2} \right) \right)^{-1} = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}^{-1} = \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} $$
		\item $D = \R^{3}$, $f(x, y, z) = \left( yz, xz, xy \right)$,  $f'(x,y,Z) = \begin{pmatrix} 0 & z & y \\ z & 0 & x \\ y & x & 0 \end{pmatrix}$
			$$  (x_{0}, y_{0}, t_{0}) \coloneqq (1,1,1), \quad \det f'(1,1,1) = \det \begin{pmatrix} 0 & 1 &1 \\ 1 & 0 &1 \\ 1 & 1 & 0 \end{pmatrix} = 2. $$
			 Nach \ref{19.6:satz} existiert eine offene Umgebung $U$ von $(1,1,1)$, so dass $f$ auf $U$ injektiv ist. Es ist $f(1,1,1) = (1,1,1)$, also
			$$ \left( f^{-1} \right)'(1,1,1) = \left( f'(1,1,1) \right)^{-1} = \dotsc = \frac{1}{2} \begin{pmatrix} -1 & 1 & 1 \\ 1 & -1 & 1 \\ 1 & 1 & -1 \end{pmatrix}. $$
	\end{enumerate}	
\end{beispiele}


\chapter{Integration im \texorpdfstring{$\R^{n}$}{Rn}}

Alle Sätze i.d. $\S$en geben wir ohne Beweis an! 

\bigskip

\index{kompaktes Intervall}
Sind $[a_{1}, b_{1}], [a_{2}, b_{2}], \dotsc, [a_{n}, b_{n}]$ kompakte Intervalle in $\R$ (also $a_{j} \leq b_{j} ~(j = 1, \dotsc n)$), so hei{\ss}t
	$$ I \coloneqq [a_{1}, b_{1}] \times [a_{2}, b_{2}] \times \dotsc \times [a_{n}, b_{n}] $$
ein \textbf{kompaktes Intervall im $\R^{n}$}. 
	
\bigskip

% todo Bild Seite 40
$|I| \coloneqq (b_{1} - a_{1}) (b_{2} - a_{2}) \cdots (b_{n} - a_{n})$ Inhalt von $I$ (Volumen von $I$). ($|I| = 0 \iff \exists j \in \{1, \dotsc, n \}: a_{j} = b_{j}$). 

\bigskip

\index{Zerlegung}
Zu jedem $[a_{j}, b_{j}]$ sei eine Zerlegung $Z_{j}$ von $[a_{j}, b_{j}]$ gegeben. Dann hei{\ss}t 
	$$ Z \coloneqq Z_{1} \times Z_{2} \times \dotsc Z_{n} $$
eine \textbf{Zerlegung von $I$}.

\bigskip

% todo Bild Seite 40
\index{Teilintervall}
Ein Teilintervall $\tilde{I}$ von $I$ bezüglich $Z$ hat die Form
	$$ T_{1} \times T_{2} \times \dotsc \times T_{m}, $$
wobei $T_{j}$ ein Teilintervall bezüglich $Z_{j}$ ist.

\bigskip

Seien $I_{1}, \dotsc, I_{m}$ die Teilintervalle bzgl. $Z$. Dann:
	$$ I = I_{1} \cup I_{2} \cup \dotsc \cup I_{m}, \quad |I| = |I_{1}| + \dotsc + |I_{m}| $$

\index{Untersumme} \index{Obersumme}
\begin{definition}
	Sei $I$ wie oben und $f \colon I \rightarrow \R$ sei beschränkt. Sei $Z$ eine Zerlegung von $I$ mit den Teilintervallen $I_{1}, \dotsc, I_{m}$. 
	
	\bigskip
	
	$m_{j} \coloneqq \inf f(I_{j})$, $M_{j} \coloneqq \sup f(I_{j}) ~(j = 1, \dotsc, n)$.
	\begin{align*}
		s_{f}(Z) & \coloneqq \sum_{j=1}^{m} m_{j} |I_{j}| \textbf{ Untersumme} \text{ von } f  \text{ bzgl. } Z. \\
		S_{f}(Z) & \coloneqq \sum_{j=1}^{m} M_{j} |I_{j}| \textbf{ Obersumme} \text{ von } f  \text{ bzgl. } Z.
	\end{align*}
\end{definition}


\begin{satz} \label{20.1:satz}
	$I$ und $f$ seien wie oben und $Z$ und $\tilde{Z}$ seien Zerlegungen von $I$.
	\begin{enumerate}
		\item Ist $Z \subseteq \tilde{Z} \Rightarrow s_{f}(Z) \leq s_{f}(\tilde{Z})$, $S_{f}(Z) \geq S_{f}(\tilde{Z})$
		\item $\big( \inf f(I) \big) \left| I \right| \leq s_{f}(Z) \leq S_{f}(\tilde{Z}) \leq \big( \sup f(I) \big) \left|I \right|$
	\end{enumerate}
\end{satz}

\index{integrierbar} \index{Integral}
\begin{definition}
	$I$ und $f$ seien wie oben.
	\begin{align*}
	\lowdashint_{I} f dx & \coloneqq \lowdashint_{I} f(x) dx \coloneqq \sup \left\{ s_{f}(Z) \colon Z \text{ Zerlegung von } I \right\} \\
		\highdashint_{I} f dx & \coloneqq \highdashint_{I} f(x) dx \coloneqq \sup \left\{ s_{f}(Z) \colon Z \text{ Zerlegung von } I \right\}
	\end{align*}
	Aus \ref{20.1:satz}: $\lowdashint_{I} f dx \leq \highdashint_{I} f dx$. $f$ hei{\ss}t \textbf{integrierbar über $I$} (ib) $\iff \lowdashint_{I} f dx = \highdashint_{I} f dx$. In diesem Fall hei{\ss}t
		$$ \int_{I} f dx \coloneqq \int_{I} f(x) dx \coloneqq \lowdashint_{I} f dx $$
	das \textbf{Integral von $f$ über $I$} man schreibt:
		$$ f \in R(I). $$
\end{definition}


\begin{satz} \label{20.2:satz}
	$I$ sei ein kompaktes Intervall im $\R^{m}$, $f, g  \colon I \rightarrow \R$ seien beschränkt und es seien $\alpha, \beta \in \R$.
	\begin{enumerate}
		\item Sind $f, g \in R(I)$, so auch $\alpha f + \beta g$, $f g$ und $|f|$. Weiter:
			$$ \int_{I} (\alpha f + \beta g) dx = \alpha \int_{I} f dx + \beta \int_{I} g dx $$
			und
			$$ \left| \int_{I} f(x) dx \right| \leq \int_{I} |f(x)| dx. $$
		\item Gilt $f, g \in R(I)$ und $f \leq g$ auf $I$, so ist $\int_{I} f dx \leq \int_{I} g dx$.
		\item Sind $f, g \in R(I)$ und gilt für ein $\alpha > 0$ dass $|g(x)| \geq \alpha ~(x \in I)$, so ist $\frac{f}{g} \in R(I)$.
		\item $C(I, \R) \subseteq R(I)$
	\end{enumerate}
\end{satz}


\begin{unnamedtheorem}[Satz von Fubini] \label{20.3:satz}
	Seien $p, q \in \N$, $n = p + q$ (also $\R^{n} = \R^{p} \times \R^{q}$). $I_{1}$ sei ein kompaktes Intervall im $\R^{p}$,  $I_{2}$ sei ein kompaktes Intervall im $\R^{q}$, es sei $I \coloneqq I_{1} \times I_{2} \subseteq \R^{n}$ und $f \in R(I)$.
	
	\bigskip
	
	% todo Bild Seite 42
	Punkte in $I$ bezeichnen wir mit $(x, y)$, wobei $x \in I_{1}$ und $y \in I_{2}$. 

	\begin{itemize}
		\item Für jedes feste $y \ I_{2}$ sei die Funktion $x \mapsto f(x, y)$ integrierbar über $I_{1}$ und es sei $g(y) \coloneqq \int_{I_{1}} f(x,y) dx$. Dann: $g \in R(I_{2})$ und
			$$ \int_{I} f(x, y) d(x,y) = \int_{I_{2}} g(y) dy = \int_{I_{2}} \left( \int_{I_{1}} f(x,y) dx \right) dy $$
		\item Für jedes feste $x \ I_{1}$ sei die Funktion $y \mapsto f(x, y)$ integrierbar über $I_{2}$ und es sei $g(x) \coloneqq \int_{I_{2}} f(x,y) dy$. Dann: $g \in R(I_{1})$ und
			$$ \int_{I} f(x, y) d(x,y) = \int_{I_{1}} g(x) dx = \int_{I_{1}} \left( \int_{I_{2}} f(x,y) dy \right) dx $$
	\end{itemize}	
\end{unnamedtheorem}

\begin{folgerung} \label{20.4:folg}
	Sei $I = [a_{1}, b_{1}] \times [a_{2}, b_{2}] \times \dotsc \times [a_{n}, b_{n}]$ und $f \in C(I)$. Dann:
	\begin{align*}
		\int_{I} f(x) dx & = \int_{I} f(x_{1}, \dotsc, x_{n}) d(x_{1}, \dotsc, x_{n}) \\
			& = \int_{a_{1}}^{b_{1}} \left( \dotsc \int_{a_{n-1}}^{b_{n-1}} \left( \int_{a_{n}}^{b_{n}} f(x_{1}, \dotsc, x_{n}) dx_{n} \right) dx_{n-1} \dotsc \right) dx_{1}
	\end{align*}
	wobei die Reihenfolge der Integrationen beliebig vertauscht werden darf.
\end{folgerung}

\begin{beispiele} ~\
	\begin{enumerate}
		\item $I = \left[0, \frac{\pi}{2}\right] \times \left[0, \frac{\pi}{2}\right]$
			\begin{align*}
				\int_{I} \sin(x+y) d(x, y) & = \int_{0}^{\frac{\pi}{2}} \left( \int_{0}^{\frac{\pi}{2}} \sin(x + y) dy \right) dx \\
				&= \int_{0}^{\frac{\pi}{2}} \left[ - \cos(x+y)\right]_{y=0}^{y = \frac{\pi}{2}} dx \\
				& = \int_{0}^{\frac{\pi}{2}} \left( - \cos\left(x+\frac{\pi}{2}\right) + \cos(x) \right) dx \\
				& = \left[ - \sin\left( x + \frac{\pi}{2} \right) + \sin x \right]_{0}^{\frac{\pi}{2}} \\
				& = - \sin (\pi) + \sin \left( \frac{\pi}{2} \right) - \left( -\sin \left( \frac{\pi}{2} \right) + \sin 0 \right) = 1 + 1 = 2
			\end{align*}
		\item $I = [0, 2] \times [0, 1] \times [0, 1]$
			\begin{align*}
				\int_{I} \left( x^{2} z + y x z \right) d(x,y,z) & = \int_{0}^{1} \left( \int_{0}^{2} \left( \int_{0}^{1} \left( x^{2} z + yxz \right) dz \right) dx \right) dy \\
				& = \int_{0}^{1} \left( \int_{0}^{2} \left[ \frac{1}{2} x^{2} z^{2} + \frac{1}{2} y x z^{2} \right]_{z=0}^{z=1} dx \right) dy \\
				& = \int_{0}^{1} \left( \int_{0}^{2} \left( \frac{1}{2} x^{2} + \frac{1}{2} y x \right) dy \right) dx \\		
				& = \int_{0}^{1} \left[ \frac{1}{2} x^{2} y + \frac{1}{4} y^{2} x \right]_{y=0}^{y=2} dx \\		
				& = \int_{0}^{1} \left( x^{2} + x \right) dx \\	
				& = \frac{1}{3} x^{3} + \frac{1}{2} x^{2} \Big|_{0}^{1} = \frac{1}{3} + \frac{1}{2} = \frac{2}{6} + \frac{3}{6} = \frac{5}{6}
			\end{align*}
		\item Sei $I = [a_{1}, b_{1}] \times [a_{2}, b_{2}] \subseteq \R^{2}$, $f \in C[a_{1}, b_{1}]$ und $g \in C[a_{2}, b_{2}]$.
			\begin{align*}
				\int_{I} f(x) g(y) d(x, y) & = \int_{a_{1}}^{b_{1}} \left( \int_{a_{2}}^{b_{2}} f(x) g(y) dy \right) \\
				& = \int_{a_{1}}^{b_{1}} f(x) \left( \int_{a_{2}}^{b_{2}} g(y) dy \right) dx \\
				& = \left( \int_{a_{1}}^{b_{1}} f(x) dx \right) \left( \int_{a_{2}}^{b_{2}} g(y) dy \right)
			\end{align*}
	\end{enumerate}	
\end{beispiele}

Sei $B \subseteq \R^{n}$ \textbf{beschränkt}. Wie kann man $B$ einen Inhalt zuordnen?
$$ c_{B}(x) \coloneqq \begin{cases} 1, & x \in B \\ 0, & x \notin B \end{cases} \text{ charakteristische Funktion von } B $$
Wähle ein kompaktes Intervall $I$ mit $B \subseteq I$.

\bigskip

% todo Bild Seite 45
Sei $Z$ eine Zerlegung von $I$ mit den Teilintervallen $I_{1}, \dotsc, I_{m}$
$$ \inf c_{B}(I_{j}) = \begin{cases} 1, & \text{ falls } I_{j} \subseteq B \\ 0, & \text{ falls } I_{j} \not\subseteq B \end{cases} $$
Damit folgt: \index{Inhalt} \index{Inhalt!innerer} \index{Inhalt!äußerer} \index{messbar}
\begin{itemize} 
	\item $s_{c_{B}}(Z) = \sum_{j : I_{j} \subseteq B} |I_{j}|$
		$$ \sup c_{B}(I_{j}) = \begin{cases} 1, & \text{falls } I_{j} \cap B \neq \emptyset \\ 0, & \text{falls } I_{j} \cap B = \emptyset \end{cases} $$
	\item $S_{c_{B}}(Z) = \sum_{j: I_{j} \cap B \neq 0} |I_{j}|$
		\begin{align*}
			\underline{v}(B) & \coloneqq \lowdashint_{I} c_{B}(x) dx \quad \textbf{innerer Inhalt} \text{ von } B \\
			\overline{v}(B) & \coloneqq \highdashint_{I} c_{B}(x) dx \quad \textbf{äußerer Inhalt} \text{ von } B \\
		\end{align*}
	\item $B$ hei{\ss}t \textbf{messbar} (mb) $:\iff \underline{b}(B) = \overline{b}(B) \iff c_{B} \in R(I)$. In diesem Fall:
		$$ |B| \coloneqq \int_{I} c_{B}(x) dx \text{ Inhalt von } B. $$
\end{itemize}
Diese Definitionen sind unabhängig von der Wahl von $I$!

\begin{beispiel*}
	Sei $I$ ein beliebiges kompaktes Intervall im $\R^{n}$.
	\begin{enumerate}
		\item $B = \emptyset$. Dann $c_{B}(x) = 0 ~\forall x \in I$. Also ist $s_{c_{B}}(Z) = S_{c_{B}}(Z) = 0$ für jede Zerlegung $Z$. Somit ist $\emptyset$ messbar und $|\emptyset| = 0$.
		\item Sei $B \subseteq \R^{n}$ ein kompaktes Intervall. Wähle $I = B$. Mit obigen Bezeichnungen:
			$$ s_{c_{B}}(Z) = \underbrace{\sum_{j=1}^{m} |I_{j}|}_{= |I|} = S_{c_{B}}(Z) \text{ für jede Zerlegung } Z. $$
			Also ist $B$ messbar und $|B| = |I|$ (= frühere Definition des Inhalts von $I$).
		\item $(n=1)$ $B \coloneqq [0, 1] \cap \Q$ ($I = [0, 1]$)
			$$ c_{B}(x) = \begin{cases} 1, & x \in [0, 1] \cap \Q \\ 0, & \text{sonst}. \end{cases} $$
			$\xRightarrow[]{HM I} c_{B} \notin R(I)$. $B$ ist also nicht messbar.
	\end{enumerate}
\end{beispiel*}

\index{integrierbar} \index{Integral}
\begin{definition}
	Sei $B \subseteq \R^{n}$ messbar und $f \colon B \rightarrow \R$ beschränkt.
		$$ f_{B}(x) \coloneqq \begin{cases} f(x), & x \in B \\ 0, & x \notin B \end{cases} $$
	Wähle ein kompaktes Intervall $I$ mit $B \subseteq I$, also $f_{B} = f \cdot c_{B}$ auf $I$.
	
	\bigskip
	
	$f$ hei{\ss}t \textbf{über $B$ integrierbar} $:\iff f_{B} \in R(I)$. In diesem Fall schreiben wir: $f \in R(B)$ und
		$$ \int_{B} f dx \coloneqq \int_{B} f(x) dx \coloneqq_{I} f_{B}(x) dx $$
	hei{\ss}t \textbf{Integral von $f$ über $B$}. 
\end{definition}

Diese Definitionen sind unabhängig von der Wahl von $I$. Es gilt also für eine beschränkte Menge $B \subseteq \R^{n}$:
	$$ B \text{ ist messbar } \iff c_{B} \in R(B) $$
In diesem Fall: $|B| = \int_{B} 1 dx \eqqcolon \int_{B} dx$.

\begin{satz} \label{20.5:satz}
	Seien $A, B \subseteq \R^{n}$ messbar und $\alpha, \beta \in \R$.
	\begin{enumerate}
		\item Ist $f \in C(B, \R)$ beschränkt, so ist $g \in R(B)$. \label{20.5.a:satz}
		\item Seien $f, g \in R(B)$. Dann: \label{20.5.b:satz}
			\begin{enumerate}
				\item $\alpha f + \beta g \in R(B)$, $fg, |f| \in R(B)$ 
					\begin{description}
						\item $\int_{B} (\alpha f + \beta g ) dx = \alpha \int_{B} f dx + \beta \int_{B} g dx$,
						\item $\left| \int_{B} f dx \right| \leq \int_{B} |f| dx$
					\end{description}
				\item Ist $f \subseteq g$ auf $B$, so ist $\int_{B} f dx \leq \int_{B} g dx$.
				\item Existiert ein $\gamma > 0$ mit $|g(x)| \geq \gamma ~(x \in B)$, so ist $\frac{f}{g} \in R(B)$.
			\end{enumerate}
		\item \begin{enumerate} \label{20.5.c:satz}
				\item $A \cup B$, $A \neg B$ und $A \setminus B$ sind messbar 
				\item aus $A \subseteq B$ folgt $|A| \leq |B|$
				\item $f \in R(A \cup B) \iff f \in R(A) \cap R(B)$. In diesem Fall:
					$$ \int_{A \cup B} f dx = \int_{A} f dx + \int_{B} f dx - \int_{A \cap B} f dx $$
					Insbesondere: $|A \cup B| = |A| + |B| - |A \cap B|$
				\item Seien $f, g \in R(B)$ und $g \leq f$ auf $B$. \label{20.5.c.4:satz}
					$$ M_{f,g} \coloneqq \left\{ (x, y) \in \R^{n+1}: x \in B, g(x) \leq y \leq f(x) \right\}. $$
					Dann ist $M_{f,g}$ messbar (im $\R^{n+1}$) und $|M_{f,g}| = \int_{B} \left( f - g \right) dx$.  % todo Bild Seite 47
					Ist $g = 0$, so ist 
					$$\left|M_{f,0}\right| = \int_{B} f(x) dx. $$ % todo Bild Seite 48 
			  \end{enumerate}
	\end{enumerate}
\end{satz}


\begin{beispiele} ~\
	\begin{enumerate} % todo Bild Seite 48
		\item $K \coloneqq \left\{ (x, y) \in \R^{2}: x^{2} + y^{2} \leq r^{2} \right\} ~(r > 0)$; $B \coloneqq [-r, r] \subseteq \R$,
			 $B$ ist messbar; Für $x \in B$ sei
			 $$ f(x) \coloneqq \sqrt{r^{2} - x^{}}, \quad g(x) \coloneqq -\sqrt{r^{2} - x^{2}} $$
			 Damit: $K = M_{f,g}$, $f, g \in R(B)$.
			 $$ g(x) \leq \gamma \leq f(x) \iff -\sqrt{r^{2} - x^{2}} \leq \gamma \leq \sqrt{r^{2} - x^{2}} $$ 
			 $$ \iff |\gamma| \leq \sqrt{r^{2} - x^{2}} \iff \gamma^{2} \leq r^{2} - x^{2} $$
			 Also ist $K$ messbar und
			 $$ |K| = \int_{B} \left( f - g \right) dx = \int_{-r}^{r} 2 \sqrt{r^{2} - x^{2}} dx \overset{HMI}{=} \pi r^{2} $$
		\item $K \coloneqq \left\{ (x, y, z) \colon ~ 0 \leq x \leq 1, 0 \leq y \leq 1, z \leq 1 - y^{2}, z \geq 0 \right\}$. $B \coloneqq [0,1] \times [0,1]$ ist messbar. Für $(x, y) \in B$ sei
			$$ f(x, y) \coloneqq 1 - y^{2}. $$
			Dann: $K = M_{f, 0}$, $f, 0 \in R(B)$. Also ist $K$ messbar und 
			\begin{align*}
				|K|  & = \int_{B} f(x, y) d(x, y) = \int_{0}^{1} \left( \int_{0}^{1} \left( 1 - y^{2} \right) dy \right) dx \\
					 & = \int_{0}^{1} \left[ y - \frac{1}{3} y^{3} \right]_{y=0}^{y=1} dx \\
					 & = \int_{0}^{1} \left( 1 - \frac{1}{3} \right) dx = \frac{2}{3}
			\end{align*} % todo Bild Seite 48
	\end{enumerate}	
\end{beispiele}


\begin{unnamedtheorem}[Prinzip von Cavalieri] \label{20.6:satz}
	Es sei $B \subseteq \R^{n+1}$ messbar. Für Punkte im $\R^{n+1}$ schreiben wir $(x,z)$ mit $x \in \R^{n}$ und $z \in \R$. Es seien $a, b \in \R$ so dass $a \leq z \leq b ~\forall (x, z) \in B$.
	
	\bigskip
	
	% todo Bild Seite 49	
	Für $Z \in [a, b]$ sei 
		$$ Q(z) \coloneqq \{ x \in \R^{n} \colon (x, z) \in B \}. $$
	Es sei für alle $z \in [a, b]$ $Q(z)$ messbar. Dann ist $z \mapsto |Q(z)|$ integrierbar über $[a, b]$ und
	$$ |B| = \int_{a}^{b} |Q(z)| dz. $$
\end{unnamedtheorem}


\begin{beispiele} ~\ \index{Rotationskörper}
	\begin{enumerate}
		\item $B \coloneqq \{ (x, y, z) \in \R^{3} \coloneqq x^{2} + y^{2} + z^{2} \leq r^{2} \}$ $(r > 0)$ Kugel um $(0, 0, 0)$ mit Radius $r$. Hier: $a = -r$, $b = r$. Für $z \in [-r, r]$ ist
			$$ Q(z) \coloneqq \left\{ (x, y) \in \R^{2} \colon x^{2} + y^{2} \leq r^{2} - z^{2} \right\} $$
			die Kreisscheibe um $(0, 0)$ mit Radius $\sqrt{r^{2} - z^{2}}$. $|Q(z)| = \pi \left( r^{2} - z^{2} \right)$. Dann:
			$$ |B| = \int_{-r}^{r} \pi \left( r^{2} - z^{2} \right) dz = \frac{4}{3} \pi r^{3}. $$ % todo Bild Seite 49
		\item $B = \left\{ (x, y, z) \in \R^{3} \colon x^{2} + y^{1} \leq 4 - z, z \in [b, 4] \right\}$ Rotationsparaboloid. $a = 0$, $b = 4$; Für $z \in [0, 4]$:
			$$ Q(z) \coloneqq \left\{ (x, y) \in \R^{2} \colon x^{2} + y^{2} \leq 4 - z \right\} $$
			$|Q(z)| = \pi \left( 4 - z\right) \Rightarrow |B| = \int_{0}^{3} \pi (4 - z) dz = 8 \pi$  \textbf{Rotationskörper}. % todo Bild Seite 50
	\end{enumerate}	
\end{beispiele}

\index{Normalbereich}
\begin{definition}
	Seien $a, b \in \R$, $a < b$, $f,g \in C[a, b]$ und $f \leq g$ auf $[a, b]$.
	$$ B \coloneqq \left\{ (x, y) \in \R^{2} \colon x \in [a, b], f(x) \leq y \leq g(x) \right\} $$
	\textbf{Normalbereich bzgl. der $x$-Achse}. $B$ ist messbar ($\ref{20.5.c:satz}  (iv)$)! Sei $h \in C(B, \R)$. Wir berechnen $\int_{B} h(x, y) d(x, y)$.
	$$ m \coloneqq \min f\left( [a, b] \right), ~ M \coloneqq \max f \left( [a, b] \right), ~ I \coloneqq [a, b] \times [m, M]. $$
	Dann:
	\begin{align*}
		\int_{B} h(x, y) d(x, y) & ~ = \int_{I} h_{B}(x, y) d(x, y) \\
		& \overset{Fubini}{=} \int_{a}^{b} \left( \int_{m}^{M} h_{B}(x, y) dy \right) dx \\
		& ~ = \int_{a}^{b} \left( \int_{f(x)}^{g(x)} h(x, y) dy \right) dx
	\end{align*} % todo Bild Seite 49
\end{definition}

\index{Rotationskörper}
\begin{unnamedtheorem*}[Rotationskörper]
	Sei $a < b$ und $f \in R[a, b]$ und $f \geq 0$ auf $[a, b]$. % todo Bild Seite 50
	
	\bigskip
	
	Der Graph von $f$ rotiert um die $x$-Achse $\rightarrow$ \textbf{Rotationskörper}.
	$$ B = \left\{ (x,y,z) \in \R^{3}: y^{2} + z^{2} \leq f(x)^{2} \right\} $$
	Also: $|Q(x)| = \pi f(x)^{2}$. Somit: $|B| = \pi \int_{a}^{b} f(x)^{2} dx$.
\end{unnamedtheorem*}


\begin{beispiel*}
	$a = 0$, $b = 4$; $f(x) = \sqrt{3 - x}$ (s. Bsp. b)
	$$ |B| = \pi \int_{0}^{4} (4 - x) dx = 8 \pi $$	
	% todo Bild Seite 50
\end{beispiel*}

\index{Normalbereich bzgl. der $y$-Achse}
\begin{definition}
	$a, b, f$ und $g$ seien wie oben.
	$$ B \coloneqq \left\{ (x, y) \in \R^{2} \colon y \in [a, b], f(x) \leq x \leq g(y) \right\} $$
	\textbf{Normalbereich bzgl. der $y$-Achse}. Wie oben: für $h \in C(B, \R)$:
	$$ \int_{B} h(x, y) d(x, y) = \int_{a}^{b} \left( \int_{f(y)}^{g(y)} h(x, y) dx \right) dy $$ % todo Bild Seite 51
\end{definition}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $B = \left\{ (x, y) \in \R^{2} \colon x \in [0, 1], \sqrt{x} \leq y \leq 2 - x \right\}$ Normalbereich bzgl. der $x$-Achse
			\begin{align*} % todo Bild Seite 51
				\int_{B} (x + y) d(x, y) & = \int_{0}^{1} \left( \int_{\sqrt{x}}^{2-x} (x+y) dy \right) dx \\
				& = \int_{0}^{1} \left[ xy + \frac{1}{2} y^{2} \right]_{\sqrt{x}}^{2-x} dx \\
				& = \int_{0}^{1} \left( x ( 2 - x) + \frac{1}{2} \left( 2 - x \right)^{2} - x \sqrt{x} - \frac{1}{2} x \right) dx \\
				& = \dotsc = \frac{71}{60}.
			\end{align*} 
		\item $B = \left\{ (x, y) \in \R^{2} \colon y \in [0, 1], 0 \leq x \leq y^{2} \right\}$ Normalbereich bzgl. der $y$-Achse. $f(y) = 0$, $g(y) = y^{2}$.
			$$ \int_{B} xy d(x, y) = \int_{0}^{1} \left( \int_{0}^{y^{2}} xy dx \right) dy = \int_{0}^{1} \left[ \frac{1}{2} x^{2} y \right]_{0}^{y^{2}} dy = \int_{0}^{1} \frac{1}{2} y^{5} dy = \frac{1}{12} $$ % todo Bild Seite 51
			$B$ ist auch Normalbereich bzgl. der $x$-Achse! % todo Bild Seite 52
			$$ \int_{B} xy d(x, y) = \int_{0}^{1} \left( \int_{\sqrt{x}}^{1} xy dy \right) dx = \int_{0}^{1} \left[ \frac{1}{2} x y^{2} \right]_{y=\sqrt{x}}^{y=1} dx = \int_{0}^{1} \left( \frac{1}{2} x - \frac{1}{2} x^{2} \right) dx = \frac{1}{12}. $$
	\end{enumerate}	
\end{beispiele}


Sei $A \subseteq \R^{2}$ kompakt und messbar; $f, g \colon A \rightarrow \R$ seien stetig und es sei $f \leq g$ auf $A$.
	$$ B \coloneqq \left\{ (x,y,z) \in \R^{3} \colon (x,y) \in A, f(x,y) \leq z \leq g(x,y) \right\} $$
Dann ist $B$ messbar. Sei $h \in C(B, \R)$: % todo Bild Seite 52
	$$ \int_{B} h(x,y,z) d(x,y,z) \overset{Fubini}{=} \int_{A} \left( \int_{f(x,y)}^{g(x,y)} h(x,y,z) dz \right) d(x,y) $$


\begin{beispiel*} Sei $f(x,y) = 0$, $g(x,y) = 1 - (x+y)$. Sei
	\begin{align*}
		A & = \left\{ (x,y) \in \R^{2} \colon x \geq 0, y \geq 0, x + y \leq 1 \right\}, \\
		B & = \left\{ (x,y,z) \in \R^{3} \colon x,y,z \geq 0, x + y + z \leq 1 \right\}.
	\end{align*}  % todo Bild Seite 52
	\begin{align*}
		\int_{B} 2 xyz d(x,y,z) & = \int_{A} \left( \int_{0}^{1 - (x+y)} 2xyz dz \right) d(x,y) \\
		& = \int_{A} \left[ xyz^{2} \right]_{z=0}^{z=1-(x+y)} d(x,y) \\
		& = \int_{A} xy \left( 1 - (x+y)\right)^{2} d(x,y) = \int_{0}^{1} \left( \int_{0}^{1-x} xy \left( 1 - (x+y)\right)^{2} dy \right) dx \\
		& = \dotsc 
	\end{align*} 
\end{beispiel*}


\begin{bemerkung}
	Sind $f \in R[a,b]$ und $g \in R[c,d]$, so gilt mit $I \coloneqq [a,b] \times [c,d]$:
	\begin{align*}
		\int_{I} f(x) g(y) d(x,y) & = \int_{a}^{b} \left( \int_{c}^{d} f(x) g(y) dy \right) dx \\
		& = \int_{a}^{b} f(x) \left( \int_{c}^{d} g(y) dy \right) dx \\
		& = \left( \int_{a}^{b} f(x) dx \right) \left( \int_{c}^{d} g(y) dy \right) 
	\end{align*} 	
\end{bemerkung}


\begin{beispiel*}
	Sei $c = a$ und $d = b$ und $I = [a, b] \times [a, b]$.
	$$ \int_{I} e^{-(x^{2} + y^{2})} d(x,y) = \int_{I} e^{-x^{2}} e^{-y^{2}} d(x,y) = \left( \int_{a}^{b} e^{-x^{2}} dx \right)^{2}. $$
\end{beispiel*}

\index{Substitutionsregel}
\begin{unnamedtheorem}[Substitutionsregel] \label{20.7:satz}
	Sei $G \subseteq \R^{n}$ offen, $g \colon G \rightarrow \R^{n}$ injektiv und stetig differenzierbar. Es sei $\forall z \in G$: $\det g'(z) \neq 0$. Es sei $B \subseteq G$ kompakt und messbar, $A \coloneqq g(B)$ und $f \in C(A, \R)$. % todo Bild Seite 54
	
	\bigskip
	
	Dann ist $A$ kompakt und messbar und
	$$ \int_{A} f(x) dx = \int_{B} f\left( g(x) \right) \left| \det g'(z) \right| dz $$
\end{unnamedtheorem}

\index{Polarkoordinaten}
\begin{unnamedtheorem}[Polarkoordinaten (n=2)] \label{20.8:satz} $x = r \cos \varphi$, $y = r \sin \varphi$ ($r = \|(x,y)\| = \left(x^{2} + y^{2} \right)^{\frac{1}{2}}$) % todo Bild Seite 54
	$$ g(r, \varphi) \coloneqq (r \cos \varphi, r \sin \varphi), ~ \det g'(r, \varphi) = r $$
	Ist $f \in C(A, \R)$, so gilt:
	\begin{align*}
		\int_{A} f(x,y) d(x,y) & ~= \int_{B} f(r\cos \varphi, r \sin \varphi) \cdot \underbrace{r}_{!} d(r, \varphi) \\
	& \overset{Fubini}{=} \int_{\varphi_{1}}^{\varphi_{2}} \left( \int_{R_{1}}^{R_{2}} f(r \cos \varphi, r \sin \varphi) r dr \right) d\varphi 
	\end{align*} 
\end{unnamedtheorem}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $A = \left\{ (x,y) \in \R^{2} \colon 1 \leq x^{2} + y^{2} \leq 4 \right\}$. Hier: $R_{1} = 1$, $R_{2} = 2$, $\varphi_{1} = 0$, $\varphi_{2} = 2\pi$. Also: 
			$$ B = [1, 2] \times [0, 2\pi] $$
			Bemerkung: $g$ ist nicht injektiv auf $B$.
			\begin{align*}
				\int_{A} x \sqrt{x^{2} + y^{2}} d(x, y) & = \int_{B} r \cos \varphi r \cdot r d(r, \varphi) \\
				& = \int_{0}^{2\pi} \left( \int_{1}^{2} r^{3} \cos \varphi dr \right) d\varphi \\
				& = \int_{0}^{2\pi} \left[ \frac{1}{4} r^{4} \cos \varphi \right]_{r=1}^{r=2} d\varphi \\
				& = \int_{0}^{2\pi} \left( 4 \cos \varphi - \frac{1}{4} \cos \varphi \right) d\varphi \\
				&= \frac{15}{4} \int_{0}^{2\pi} \cos \varphi d\varphi = 0
			\end{align*}
		\item Für $R > 0$: $A_{R} \coloneqq \left\{ (x,y) \in \R^{2} \colon x \geq 0, y \geq 0, x^{2} + y^{2} \leq R^{2} \right\}$. Hier; $R_{1} = 0, R_{2} = R$, $\varphi_{1} = 0, \varphi_{2} = \frac{\pi}{2}$. Also $B = [0, R] \times \left[ 0, \frac{\pi}{2} \right]$, Bem.: $\det g'(0, \varphi) = 0$.
			\begin{align*}
				\int_{A_{R}} e^{-(x^{2} + y^{2})} d(x,y) & = \int_{B} e^{-r^{2}} r dr \\
				& = \int_{0}^{\frac{\pi}{2}} \left( \int_{0}^{R} e^{-r^{2}} r dr \right) d\varphi \\
				& = \frac{\pi}{2} \left[ -\frac{1}{2} e^{-r^{2}} \right]_{0}^{R} \\
				& = \frac{\pi}{2} \left(-\frac{1}{2} e^{-R^{2}} + \frac{1}{2} \right) = \underbrace{\frac{\pi}{4} \left( 1 - e^{-R^{2}} \right)}_{\eqqcolon \alpha(R)}
			\end{align*}
			Sei
			$$Q(R) \coloneqq [0, R] \times [0, R], ~ \beta(R) \coloneqq \int_{Q_{R}} e^{-(x^{2} + y^{2})} d(x, y). $$
			Es ist $A_{R} \subseteq Q_{R}$ und $e^{-(x^{2} + y^{2})} \geq 0$, also $\alpha(R) \leq \beta(R)$. Es ist
			$$ \beta(R) = \int_{0}^{R} \left( \int_{0}^{R} e^{-x^{2}} e^{-y^{2}} dy \right) dx = \left( \int_{0}^{R} e^{-x^{2}} dx \right)^{2}. $$
			$\rho \coloneqq \sqrt{2} R$. Dann: $\Q_{R} \subseteq A_{\rho}$. Somit: $\beta(R) \leq \alpha(\rho) = \alpha \left( \sqrt{2} R \right)$. Fazit $\forall R > 0$: 
			$$ \alpha(R) \leq \beta(R) \leq \alpha\left( \sqrt{2} R \right). $$
			$\xRightarrow[]{R \rightarrow \infty} \frac{\pi}{4} = \lim_{R \rightarrow \infty} \beta(R)$. Fazit:
			$$ \int_{0}^{\infty} e^{-x^{2}} dx \text{ ist konvergent und } \int_{0}^{\infty} e^{-x^{2}} dx = \frac{\sqrt{\pi}}{2}. $$
	\end{enumerate}
\end{beispiele}

\index{Zylinderkoordinaten}
\begin{unnamedtheorem}[Zylinderkoordinaten (n = 3)] \label{20.9:satz}
	$$ \begin{rcases} y = r \cos \varphi \\ y = r \sin \varphi \\ z = z \end{rcases} \quad g(r,\varphi, z ) \coloneqq (r \cos \varphi, r \sin \varphi, z), ~ \det g'(r, \varphi, z ) r. $$
	$A, B \subseteq \R$ seien wie in \ref{20.7:satz} und $f \in C(A, \R)$:
		$$ \int_{A} f(x,y,z) d(x,y,z) = \int_{B} f(r \cos \varphi, r \sin \varphi, z) \cdot r d(r, \varphi, z) $$
\end{unnamedtheorem}


\begin{beispiele} ~\
	\begin{enumerate}
		\item Seien $R, h > 0$; $A \coloneqq \left\{ (x,y,z) \in \R^{3} \colon x^{2} + y^{2} \leq R^{2}, 0 \leq z \leq h \right\}$. $B = [0, R] \times [0, 2\pi] \times [0, h]$
		\begin{align*} % todo Bild Seite 57
			|A| & = \int_{A} 1 d(x,y,z) = \int_{B} r d(r,\varphi, z) \\
				& = \int_{0}^{h} \left( \int_{0}^{2\pi} \left( \int_{0}^{R} r dr \right) d\varphi \right) dz = 2 \pi h \left[ \frac{1}{2} r^{2} \right]_{0}^{R} = \pi R^{2} h.
		\end{align*} 
		\item $A = \left\{ (x,y,z) \in \R^{3} \colon x^{2} + y^{2} \leq 1, 0 \leq y \leq x, z \in [0,1] \right\}$, $B = [0, 1] \times [0, \frac{\pi}{4}] \times [0,1]$.
			\begin{align*} % todo Bild Seite 57
				\int_{A} \left( x^{2} + y^{2} + z \right) d(x,y,z) & = \int_{B} \left( r^{2} + z \right) r d(r, \varphi, z) \\
					& = \int_{0}^{\frac{\pi}{4}} \left( \int_{0}^{1} \left( \int_{0}^{1} \left( r^{3} + zr \right) dr \right) dz \right) d\varphi \\
					& = \frac{\pi}{4} \int_{0}^{1} \left[ \frac{1}{4} r^{4} + \frac{1}{2} z r^{2} \right]_{0}^{1} dz \\
					& = \frac{\pi}{4} \int_{0}^{1} \left( \frac{1}{4} + \frac{1}{2} z \right) dz = \frac{\pi}{8}
			\end{align*}
		\item $A \coloneqq \left\{ (x,y,z) \in \R^{3} \colon 0 \leq z \leq 1, x^{2} + y^{2} \leq \sqrt{z} \right\}$.
			$$ \int_{A} \left( 4 x^{2} z + 4 y^{2} z \right) d(x,y,z) = \int_{B} 4 r^{2} z r d(r,\varphi, z), $$
			wobei $B = \left\{ (r, \varphi, z) \colon 0 \leq z \leq 1, 0 \leq r^{2} \leq \sqrt[4]{z},0 \leq \varphi \leq 2\pi  \right\}$. Also:
			\begin{align*}
				\int_{A} \left( 4x^{2} z + 4 y^{2} z \right) d(x,y,z) & = \int_{0}^{1} \left( \int_{0}^{\sqrt[4]{z}}  \left( \int_{0}^{2\pi} 4 r^{2} z d\varphi \right) dr \right) dz \\
				& = 2\pi \int_{0}^{1} \left[ r^{4} z \right]_{r=0}^{r=\sqrt[4]{z}} dz \\
				& = 2\pi \int_{0}^{1} z^{2} dz = \frac{2\pi}{3} 
			\end{align*} 
			Bemerkung: $B = \big\{ (r,\varphi, z) \colon (z, \varphi) \in [0,1] \times [0, 2\pi], \underbrace{0}_{f(z,\varphi)} \leq r \leq \underbrace{\sqrt[4]{z}}_{g(z,\varphi)} \big\}$. % todo Bild Seite 58
	\end{enumerate}
\end{beispiele}


\begin{unnamedtheorem}[Kugelkoordinaten (n=3)] \label{20.10:satz}
	Für $\varphi = [0, 2\pi]$, $\vartheta \in \left[-\frac{\pi}{2}, \frac{\pi}{2} \right]$:
	$$ r = \|(x,y,z)\| = \sqrt{x^{2} + y^{2} + z^{2}}, ~ x = r \cos \varphi \cos \vartheta, ~ y = r \sin \varphi \cos \vartheta, ~ z = r \sin \vartheta $$
	$g(r, \varphi, \vartheta) \coloneqq (r, \cos \varphi \cos \vartheta, r \sin \varphi \cos \vartheta, r \sin \vartheta)$, $|\det g'(r, \varphi, \vartheta)| = r^{2} \cos \vartheta$. Sind $A, B \subseteq \R^{3}$ wie in \ref{20.6:satz} (also $A = g(B)$), so gilt für $f \in C(A, \R)$:
	$$ \int_{A} f(x,y,z) d(x,y,z) = \int_{B} f(g(r,\varphi, \vartheta)) \cdot r^{2} \cos \vartheta d(r, \varphi, \vartheta). $$
\end{unnamedtheorem}


\begin{beispiel*}
	Sei $B = \underbrace{\Big[0, 1\Big]}_{r} \times \underbrace{\left[ 0, \frac{\pi}{2}\right]}_{\varphi} \times \underbrace{\left[ 0, \frac{\pi}{2} \right]}_{\vartheta}$ und  
	$$A = \left\{ (x,y,z) \in \R^{3} \colon x,y,z \geq 0, x^{2} + y^{2} + z^{2} \leq 1 \right\}. $$ 
	Dann:
	\begin{align*}
		\int_{A} x \sqrt{x^{2} + y^{2} + z^{2}} d(x,y,z) & = \int_{B} r \cos \varphi \cos \vartheta r r^{2} \cos \vartheta d(r,\varphi, \vartheta) \\
			& = \int_{B} r^{4} \cos^{2} \vartheta \cos \varphi d(r,\varphi, \vartheta) \\
			& = \int_{0}^{1} \left( \int_{0}^{\frac{\pi}{2}} \left( \int_{0}^{\frac{\pi}{2}} r^{4} \cos^{2} \vartheta \cos \varphi d\varphi \right) d \vartheta \right) d r \\
			& = \int_{0}^{1} \left( \int_{0}^{\frac{\pi}{2}} r^{4} \cos^{2} \vartheta d\vartheta \right) dr \\
			& = \frac{1}{5} \int_{0}^{\frac{\pi}{3}} \cos^{2} \vartheta d\theta = \frac{\pi}{20}.
	\end{align*}
\end{beispiel*}


\chapter{Spezielle Differentialgleichungen 1. Ordnung}

\index{Differentialgleichung} \index{Differentialgleichung!1. Ordnung} \index{Anfangswertproblem} \index{Differentialgleichung!Lösung}  \index{Anfangswertproblem!Lösung}
\begin{definition}
	Es sei $\emptyset \neq D \subseteq \R^{3}$ und $f \colon D \rightarrow \R$ eine Funktion. Die Gleichung
	\begin{equation*}
		f(x, y, y') = 0 \tag*{$(*)$}
	\end{equation*}
	hei{\ss}t eine \textbf{Differentialgleichung (Dgl.) 1. Ordnung}. Sind $x_{0}, y_{0} \in \R$, so hei{\ss}t
	$$ (A) ~ \begin{cases} ~ f(x,y,y') = 0 \\ ~ y(x_{0}) = y_{0} \end{cases} $$
	ein \textbf{Anfangswertproblem} (AWP). 
	
	\bigskip
	
	Ist $I \subseteq \R$ ein Intervall und $y \colon I \rightarrow \R$ eine Funktion, so hei{\ss}t $y$ eine \textbf{Lösung von $(*)$ auf $I$} $:\iff y$ ist auf $I$ differenzierbar, $(x y(x), y'(x)) \in D$ und $\forall x \in I$: $f(x,y(x), y'(x)) = 0$.
	
	\bigskip
	
	Ist $y$ eine Lösung von $(*)$ auf $I$, ist $x_{0} \in I$ und $y(x_{0}) = y_{0}$, so hei{\ss}t $y$ eine \textbf{Lösung des Anfangswertproblems} (A).
\end{definition}


\begin{beispiel*} ~\
	\begin{enumerate}
		\item $D = \R^{3}$, $f(x,y,z) xy - z$; also $f(x,y(x), y'(x)) = 0 \iff y'(x) = x y(x)$. Dann ist 
			$$ y(x) e^{\frac{1}{2} x^{2}} $$
			eine Lösung der Differentialgleichung $y'(x) = x y(x)$ auf $\R$.
		\item $D = \R^{3}$, $f(x,y,z) \coloneqq ^{2} + 1 - z$; also: 
			$$ f(x,y,y') = 0 \iff y' = 1 + y^{2}. $$
			Dann ist $y(x) = \tan x$ eine Lösung der Differentialgleichung $y' = 1 + y^{2}$ auf $\left( -\frac{\pi}{2}, \frac{\pi}{2}\right)$. $y(x) = \tan x$ ist Lösung des Anfangswertproblems
			$$ \begin{cases} y' = 1 + y^{2} \\ y(0) = 0 \end{cases} $$
	\end{enumerate}	
\end{beispiel*}

\index{Differentialgleichung!getrennte Variablen} 
\subsubsection*{Differentialgleichungen mit getrennten Variablen}

\begin{satz}[ohne Beweis] \label{21.1:satz}
	$I_{1}, U_{2} \subseteq \R$ seien Intervalle, es seien $f \in C(I_{1})$ und $g \in C(I_{2})$ und es gelte $\forall y \in I_{2}$: $g(y) \neq 0$. Die Differentialgleichung
	\begin{equation*}
		y' = f(x) g(y) \tag*{$(*)$}
	\end{equation*}
	hei{\ss}t \textbf{Differentialgleichung mit getrennten Veränderlichen}. Die Lösungen von $(*)$ erhält man, indem man die Gleichung
	$$ \int \frac{dy}{g(y)} = \int f(x) dx + c $$
	nach $y$ auflöst (Stammfunktionen $H$ bzw. $F$ von $\frac{1}{g}$ bzw. $f$: $y(x) = H^{-1}(F(x)) ~(x \in I)$; $y'(x) = \frac{1}{H'(H^{-1}(F(x)))} f(x) = g(y(x)) f(x)$).
	
	\bigskip
	
	\textbf{Formal}: $y' = f(x) g(y) \longrightarrow \frac{dy}{dx} = f(x) g(y) \longrightarrow \frac{dy}{g(y)} = f(x) dx$ (Trennung der Veränderlichen) $\longrightarrow \int \frac{dy}{g(y)} = \int f(x) dx + c$.
\end{satz}


\begin{beispiele}
	In den folgenden Beispielen bestimme man zunächst die allgemeine Lösung der Differentialgleichung und dann die Lösung des Anfangswertproblems.
	\begin{enumerate}
		\item $AWP ~ \begin{cases} ~ y' = 1 + y^{3} \\ ~ y(0) = 1, \end{cases} \frac{dy}{dx} = 1 + y^{2} \Rightarrow \frac{dy}{1 + y^{2}} = dx$
			$$ \Longrightarrow \int \frac{1}{1 + y^{2}} dy = \int dx + c \Longrightarrow \arctan(y) = x + c $$
			$\Rightarrow y = \tan(x+c)$. \enquote{Allgemeine Lösung}:
			$$ y(x) = \tan ( x + c ). $$
			Wir betrachten die Lösungen für $(x+c) < \frac{\pi}{2}$. Lösungen des Anfangswertproblems: $c = \frac{\pi}{4} \Rightarrow 1 = y(0) = \tan c$. Also ist für $\left| x + \frac{\pi}{4} \right| < \frac{\pi}{2}$
			$$ y(x) = \tan \left( x + \frac{\pi}{4} \right), $$
			also für $x \in \left( - \frac{3}{4} \pi, \frac{\pi}{4} \right)$.
		\item $AWP ~ \begin{cases} ~ y' = - \frac{x}{y} \\ ~ y(0) = 2, \end{cases} \frac{dy}{dx} = \frac{x}{y} \Rightarrow y dy = - x dx$
			$$ \Longrightarrow \int y dy = - \int x dx + \tilde{c} \Longrightarrow  \frac{1}{2} y^{2} = - \frac{1}{2} x^{2} + \tilde{c} \Longrightarrow \underbrace{y^{2} = - x^{2} + c}_{\Rightarrow c \geq 0}, \quad (c = 2 \tilde{c}) $$
			$\Rightarrow y = \pm \sqrt{ c - x^{2} }$. Allgemeine Lösung: 
			$$ y(x) = \pm \sqrt{ c - x^{2} } \text{ für } x \in \left( -\sqrt{c}, \sqrt{c} \right). $$
			Lösung des Anfangswertproblems: $ 2 = y(0) = \pm \sqrt{c} \Rightarrow 2 = \sqrt{c} \Rightarrow c = 4$. Lösung des Anfangswertproblems für $x \in (-2, 2)$:
			$$ y(x) = \sqrt{4 - x^{2}}. $$
		\item $AWP ~ \begin{cases} y' = e^{y} \sin x \\ y(0) = 0, \end{cases} \frac{dy}{dx} = e^{y} \sin x \Rightarrow \frac{dy}{e^{y}} = \sin x dx$
			$$ \Longrightarrow \int \frac{dy}{e^{y}} = \int \sin x dx + c \Longrightarrow - e^{-y} = -\cos x + c \Rightarrow e^{-y} = \cos x - c $$
			$\Rightarrow - y = \log \left( \cos x - c \right)$. Allgemeine Lösung für $x$ mit $\cos > c$: 
			$$ y(x) = - \log (\cos x - c). $$ 
			Allgemeine Lösung des Anfangswertproblems: $0 = y(0) = - \log(1-c) \iff 1 - c = 1 \iff c = 0$ für $x \in \left( -\frac{\pi}{2}, \frac{\pi}{2} \right)$:
			$$ y(x) = - \log (\cos x). $$
		\item $AWP ~ \begin{cases} ~ y' = \frac{1}{xy} \\ ~ y(1) = -1, \end{cases} \frac{dy}{dx} = \frac{1}{xy} \Rightarrow y dy = \frac{1}{x} dx$
			$$ \Longrightarrow \int y dy = \int \frac{1}{x} dx + \tilde{c} \Longrightarrow \frac{1}{2} y^{2} = \ln |x| + \tilde{c} $$
			$\Rightarrow y^{2} = \ln x^{2} + c$ $(c = 2 \tilde{c})$. Allgemeine Lösung:
			$$ y(x) = \pm \sqrt{\ln x^{2} + c}. $$
			Lösung des Anfangswertproblems: $-1 = y(1) = \pm \sqrt{c} \Rightarrow -1 = -\sqrt{c} \Rightarrow c = 1$:
			$$ y(x) = - \sqrt{\ln x^{2} + 1} $$
			$(\ln x^{2} + 1 > 0 \iff \ln x^{2} > -1 \iff x^{2} > \frac{1}{e} \iff x > \frac{1}{\sqrt{e}}$ oder $x < \frac{1}{\sqrt{e}})$. Lösung des Anfangswertproblems für $x \in \left( \frac{1}{\sqrt{e}}, \infty \right)$
			 $$ y(x) = - \sqrt{\ln x^{2} + 1}. $$
	\end{enumerate}	
\end{beispiele}

Bei Anfangswertproblemen mit getrennten Veränderlichen kann auch mit bestimmten Integralen gerechnet werden. Nochmals Beispiel b): 
$$ \begin{cases} ~ y'(x) = -\frac{x}{y(x)} \\ ~ y(0) = 2 \end{cases} $$
Mit $y(0) = 2$ gilt:
\begin{align*}
	\int_{0}^{x} y'(t) y(t) dt = \int_{0}^{x} - t dt & \iff \int_{0}^{x} \frac{d}{dt} \left[ \frac{1}{2} \left( y(t) \right)^{2} \right] dt = -\frac{1}{2} x^{2} \\
	& \iff \frac{1}{2} \left( y(x) \right)^{2} - \frac{1}{2} \big( \underbrace{y(0)}_{=2} \big)^{2} = - \frac{1}{2} x^{2} \\
	& \iff \frac{1}{2} \left( y(x) \right)^{2} = 2 - \frac{1}{2} x^{2} \\
	& \iff \left( y(x) \right)^{2} = 4 - x^{2} \iff y(x) = \sqrt{4 - x^{2}} \quad (x \in (-2, 2)).
\end{align*}

\index{Differentialgleichung!lineare} \index{Störfunktion} \index{homogen} \index{inhomogen} \index{Differentialgleichung!homogene} \index{Differentialgleichung!inhomogene}
\subsubsection*{Lineare Differentialgleichungen}
Sei $I \subseteq \R$ ein Intervall, $\alpha, s \colon I \rightarrow \R$ stetig. Die Differentialgleichung
	\begin{equation*}
		y' = \alpha(x) y + s(x) \tag*{(2)}
	\end{equation*}
hei{\ss}t eine \textbf{lineare Differentialgleichung}. $s$ hei{\ss}t \textbf{Störfunktion}. Die Differentialgleichung
	\begin{equation*}
		y' = \alpha(x) y \tag*{(3)}
	\end{equation*}
	hei{\ss}t die zu (2) gehörige \textbf{homogene Gleichung} (Ist $s \neq 0$, so hei{\ss}t die Gleichung (2) inhomogen).

\begin{satz} \label{21.2:satz}
	Sei $\beta$ eine Stammfunktion von $\alpha$ auf $I$.
	\begin{enumerate}
		\item Sei $y \colon I \rightarrow \R$ differenzierbar. Dann gilt:
			\begin{enumerate}
				\item $y$ ist eine Lösung von (3) auf $I$ $\iff \exists c \in \R : y(x) = c e^{\beta(x)}$.
				\item Sei $y_{p}$ eine spezielle Lösung von (2) auf $I$. Dann: $y$ ist eine Lösung von (2) auf $I \iff \exists c \in \R : y(x) = y_{p}(x) + c e^{\beta(x)}$.
			\end{enumerate}
		\item Variation der Konstanten: Der Ansatz
			$$ y_{p}(x) = c(x) e^{\beta(x)} $$
			mit einer noch unbekannten Funktion $c$ führt auf eine spezielle Lösung von (2) auf $I$ (siehe Beweis!).
		\item Sei $x_{0} \in I$. Dann hat das Anfangswertproblem
			$$ \begin{cases} ~y' = \alpha(x) y + s(x) \\ ~y(x_{0}) = y_{0} \end{cases} $$
			auf $I$ genau eine Lösung.
	\end{enumerate}
	
	\begin{proof} ~\
		\begin{enumerate}
			\item \begin{enumerate}
					\item a Ist $c \in \R$ und $y(x) = c e^{\beta(x)}$, so gilt für $x \in I$:
						$$ y'(x) = c \beta'(x) e^{\beta(x)} = \alpha(x) c e^{\beta(x)} = \alpha(x) y(x). $$
						Ist umgekehrt $y \colon I \rightarrow \R$ eine Lösung von (3), so gilt für $\phi(x) \coloneqq e^{-\beta(x)} y(x)$ und $x \in I$:
						\begin{align*}
							\phi'(x) & = - \beta'(x) e^{-\beta(x)} y(x) + e^{-\beta(x)} y'(x) \\
							& = - \alpha(x) e^{-\beta(x)} y(x) + e^{-\beta(x)} \alpha(x) y(x) = 0. 
						\end{align*} 
						$\Rightarrow \exists c \in \R \forall x \in I: \phi(x) = c$, also $x \in I$: 
						$$ y(x) = c e^{\beta(x)}. $$
					\item Ist $y(x) = y_{p}(x9 + \underbrace{c e^{\beta(x)}}_{\eqqcolon y_{h}(x)}$ ($x \in I$), so gilt:
						\begin{align*}
							y'(x) & = y_{p}'(x) + y_{h}'(x) \\
								  & = \alpha(x) y_{p}(x) + s(x) + \alpha(x) y_{h}(x) \\
								  & = \alpha(x) \left( y_{p}(x) + y_{h}(x) \right) + s(x) = \alpha(x) y(x) + s(x). 
						\end{align*} 
						Ist umgekehrt $y$ eine Lösung von (2) auf $I$ so gilt für $y_{h}(x) \coloneqq y(x) - y_{p}(x)$:
						\begin{align*}
							y_{h}'(x) & = y'(x) - y_{p}'(x) \\
								& = \left(\alpha(x) y(x) + s(x) \right) - \left( \alpha(x) y_{p}(x) + s(x) \right) \\
								& = \alpha(x) \left( y(x) - y_{p}(x) \right) = \alpha(x) y_{h}(x). 
						\end{align*} 
						Also ist $y_{h}(x)$ eine Lösung von (3), also von der Form $y_{h}(x) = c e^{\beta(x)}$. Damit ist
						$$ y(x) = y_{p}(x) + y_{h}(x) = y_{p} + c e^{\beta(x)}. $$
				\end{enumerate}
			\item $y_{p}'(x) = c'(x) e^{\beta(x)} + c(x) \beta'(x) e^{\beta(x)} = \left( c'(x) + c(x) \alpha(x) \right) e^{\beta(x)}$. ~\\
				$y_{p}$ ist Lösung von (2) auf $I$
				\begin{align*}
					& \iff \left( c'(x) + c(x) \alpha(x) \right) e^{\beta(x)} = \alpha(x) c(x) e^{\beta(x)} + s(x) \\
					& \iff c'(x) e^{\beta(x)} = s(x) \iff c'(x) = s(x) e^{-\beta(x)}.
				\end{align*} 
				Wähle eine Stammfunktion von $c'$. Hieraus ergibt sich $y_{p}$.
			\item Allgemeine Lösung von (2): $y(x) = y_{p}(x) + c e^{\beta(x)}$.
				$$ y_{0} = y(x_{0}) = c e^{\beta(x_{0})} + y_{p}(x_{0}) \iff c = \left( y_{0} - y_{p}(x_{0}) \right) e^{-\beta(x_{0})}. $$
		\end{enumerate}
	\end{proof}
\end{satz}
	

\begin{beispiele} ~\
	\begin{enumerate}
		\item $(*)$ $y' = (\sin x) y + \sin x$. Hier: $\alpha(x) = \sin x, s(x) = \sin x, \beta(x) = - \cos x$, $I = \R$.
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung der homogenen Gleichung für $c \in \R$: $y(x) = c e^{-\cos x}$
				\item Ansatz für eine spezielle Lösung von $(*)$: $ y_{p}(x) = c(x) e^{-\cos x }$.
					\begin{align*}
						y_{p}'(x) & = c'(x) e^{-\cos x} + c(x) \sin x e^{- \cos x} \\
						& \overset{!}{=} \left( \sin x \right) y_{p}(x) + \sin x \\
						& = \left( \sin x \right) c(x) e^{-\cos x} + \sin x.
					\end{align*}
					$\Rightarrow c'(x) e^{-\cos x} = \sin x \Rightarrow c'(x) = \sin x e^{\cos x} \Rightarrow c(x) = - e^{\cos x} \Rightarrow y_{p}(x) = -1$.
				\item Allgemeine Lösung von $(*)$ für $c \in \R$: $y(x) = c e^{-\cos x} - 1$.
			\end{enumerate}
		\item Löse das Anfangswertproblem $\begin{cases} ~ y' = \left( \sin x \right) y + \sin x \\ ~ y(0) = 3 \end{cases}$
		
			\bigskip
		
			Allgemeine Lösung der Differentialgleichung: 
						$$ y(x) = c e^{- \cos x } - 1. $$
					$3 = y(0) = c e^{-1} - 1 \Rightarrow c e^{-1} = 4 \Rightarrow c = 4e$. Lösung des Anfangswertproblems für $x \in \R$:
					$$ y(x) = 4 e^{1-\cos x} - 1. $$
		\item $(*)$ $y' = 2 xy + x$. Hier: $\alpha(x) 2x$, $s(x) = x$, $I = \R$, $\beta(x) = x^{2}$.
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung der homogenen Gleichung für $c \in \R$: $y(x) = c e^{x^{2}}$.
				\item Ansatz für eine spezielle Lösung von $(*)$: $y_{p}(x) = c(x) e^{x^{2}}$.
					$$ y_{p}'(x) = c'(x) e^{x^{2}} + c(x) 2x e^{x^{2}} \overset{!}{=} 2 x y_{p}(x) + x = 2x c(x) e^{x^{2}} + x $$
					$\Rightarrow c'(x) e^{x^{2}} = x \Rightarrow c'(x) = x e^{-x^{2}} \Rightarrow c(x) = - \frac{1}{2} e^{-x^{2}} \Rightarrow y_{p}(x) = -\frac{1}{2}$.
				\item Allgemeine Lösung von $(*)$ für $c \in \R$: $y(x) = c e^{x^{2}} - \frac{1}{2}$.
			\end{enumerate}
		\item Lösung des Anfangswertproblems: $\begin{cases} ~y' = 2xy + x \\ y(1) = 0. \end{cases}$ 
		
			\bigskip
		
			Allgemeine Lösung der Differentialgleichung: $y(x) = c e^{x^{2}} - \frac{1}{2}$.
			$$ 0 = y(1) = c e - \frac{1}{2} \Rightarrow c = \frac{1}{2} e^{-1} \Rightarrow y(x) = \frac{1}{2} e^{x^{2} - 1} - \frac{1}{2} $$
		\item $(*)$ $y' = 3y + e^{x}$. Hier: $\alpha(x) = 3, s(x) = e^{x}$, $I = \R$, $\beta(x) = 3x$.
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung der homogenen Gleichung für $c \in \R$: $y(x) = c e^{3x}$.
				\item Ansatz für eine spezielle Lösung von $(*)$: $y_{p}(x) = c(x) e^{3x}$.
					$$ y_{p}'(x) = c'(x) e^{3x} + c(x) 3 e^{3x} \overset{!}{=} 3y_{p}(x) + e^{x} = 3 c(x) e^{3x} + e^{3} $$
					$\Rightarrow c'(x) e^{3x} = e^{x} \Rightarrow c'(x) = e^{-2x} \Rightarrow c(x) = -\frac{1}{2} e^{-2x} \Rightarrow y_{p}(x) =-\frac{1}{2} e^{x}$.
				\item Allgemeine Lösung von $(*)$: $y(x) = c e^{3x} - \frac{1}{2} e^{x}$.
			\end{enumerate}
		\item Löse das Anfangswertproblem $\begin{cases} ~y' = 3y + e^{x} \\ ~y(\ln z) = 0 \end{cases}$ 
		
			\bigskip
			
			Allgemeine Lösung der Differentialgleichung: $y(x) = c e^{3x} - \frac{1}{2} e^{x}$.
			$$ 0 = y(\ln z) = c e^{3 \ln 2} = c e^{\ln 8} - \frac{1}{2} e^{\ln 2} = c 8 - \frac{1}{2} 2 = 8c - 1 $$
			$\Rightarrow c = \frac{1}{8}$. Lösung des Anfangswertproblems. $y(x) = \frac{1}{8} e^{3x} - \frac{1}{2} e^{x}$.
		\item $(*)$ $y' = - \frac{1}{x} y + x$; Hier: $\alpha(x) = - \frac{1}{x}, s(x) = x, I = (0, \infty), \beta(x) = -\ln x$.
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung der homogenen Gleichung für $c \in \R$: $y(x) = c e^{-\ln x} = \frac{c}{x}$.
				\item Ansatz für eine spezielle Lösung von $(*)$: $y_{p}(x) = \frac{c(x)}{x}$.
					$$ y_{p}'(x) = c'(x) \frac{1}{x} - c(x) \frac{1}{x^{2}} \overset{!}{=} - \frac{1}{x} y_{p}(x) + x = - \frac{1}{x^{2}} c(x) + x $$
					$\Rightarrow c'(x) \frac{1}{x} = x \Rightarrow c'(x) = x^{2} \Rightarrow c(x) = \frac{1}{3} x^{3} \Rightarrow y_{p}(x) = \frac{1}{3} x^{2}$.
				\item Allgemeine Lösung von $(*)$: $y(x) = \frac{c}{x} + \frac{1}{3} x^{2}$.
			\end{enumerate}
		\item Löse das Anfangswertproblem $\begin{cases} ~y' = - \frac{1}{x} y + x \\ ~y(1) = - 1 \end{cases}$ 

		$$ - 1 = y(1) = \frac{c}{1} + \frac{1}{3} \Longrightarrow c = -\frac{4}{3} $$
		Lösung des Anfangswertproblems für $x \in (0, \infty)$: $y(x) = -\frac{4}{3x} + \frac{1}{3} x^{2}$.
	\end{enumerate}
\end{beispiele}	
	
\index{Bernoullische Differentialgleichung} \index{Riccalische Differentialgleichung}
\subsubsection*{Bernoulli- und Riccali-Differentialgleichungen}

Es sei $I \subseteq \R$ ein Intervall, $g, h \in C(I, \R)$ und $\alpha \in \R$. Die Differentialgleichung
	\begin{equation*}
		y'(x) + g(x) y(x) + h(x) \left( y(x) \right)^{\alpha} = 0 \tag*{$(*)$}
	\end{equation*}
hei{\ss}t \textbf{Bernoullische Differentialgleichung}. Im Fall $\alpha = 0$ erhält man eine lineare Differentialgleichung (inhomogen, falls $h \not\equiv 0$). Im Fall $\alpha = 1$ erhält man eine homogene lineare Differentialgleichung.

\bigskip

Nun sei $\alpha \in \R \setminus \{ 0, 1 \}$. Wir betrachten die Transformation $z(x) = \left( y(x) \right)^{1-\alpha}$:
	\begin{align*}
		z'(x) & = (1-\alpha) \left( y(x) \right)^{-\alpha} \cdot y'(x) \\ 
			  & = (1-\alpha) \left( y(x) \right)^{-\alpha} \left( -g(x)y(x) - h(x) \left( y(x) \right)^{\alpha} \right) \\
			  & = - (1-\alpha) g(x) \left( y(x) \right)^{1-\alpha} - (1 - \alpha) h(x) \\
			  & = - (1-\alpha) g(x) z(x) - (1-\alpha) h(x). 
	\end{align*} 
Dies ist eine lineare Differentialgleichung für $z$. Sei $z$ eine Lösung dieser Gleichung auf $I$. Setze 	$y(x) \coloneqq z(x)^{\frac{1}{1 -\alpha}}$ für $x$ aus einem Intervall $I_{1} \subseteq I$, für das $\left( z(x) \right)^{\frac{1}{1 - \alpha}}$ eine differenzierbare Funktion liefert. Dann ist $y$ eine Lösung von $(*)$ auf $I_{1}$. 

\bigskip

\begin{beispiel*}
	Betrachte auf $I = (-1, \infty)$: $y'(x) + \frac{y(x)}{1 + x} + (1+x) y^{4}(x) = 0$ ~\\
	$z(x) \coloneqq \left( y(x) \right)^{1-4} = \frac{1}{\left( y(x) \right)^{3}}$.
		$$ z'(x) = -\frac{3}{\left( y(x) \right)^{4}} \cdot y'(x) = \frac{3}{\left( y(x) \right)^{4}} \left( \frac{y(x)}{1 + x} + (1+x) \left( y(x) \right)^{4} \right) = \frac{3}{1+x} z(x) + 3(1+x). $$
	Eine Lösung dieser linearen Differentialgleichung auf $I$ ist z.B. für $x \in (-1, \infty)$:
		$$ z(x) = (1+x)^{2} (2x - 1). $$
	Damit ist 
		$$ y(x) = \left( z(x) \right)^{-\frac{1}{3}} = \frac{1}{\sqrt[3]{(1+x)^{2} (2x - 1)}} $$
	eine Lösung der Bernoulli-Differentialgleichung auf $\left( -1, \frac{1}{2}\right)$. 
\end{beispiel*}

Nun seien $g,h,k \in C(I, \R)$. Die Differentialgleichung
\begin{equation*}
	y'(x) + g(x) y(x) + h(x) \left( y(x) \right)^{2} = k(x) \tag*{$(**)$}
\end{equation*}
hei{\ss}t \textbf{Riccalische Differentialgleichung}.  Sind $y_{1}, y_{2}$ Lösungen von $(**)$ auf $I_{1} \subseteq I$, so gilt für $u \coloneqq y_{1} - y_{2}$:
	\begin{align*}
		u'(x) & = \left[ -g(x) y_{1}(x) - h(x) \left( y_{1}(x) \right)^{2} + k(x) \right] - \left[ -g(x) y_{2}(x) - h(x) \left( y_{2}(x) \right)^{2} + k(x) \right] \\
			& = -g(x) u(x) - h(x) \left( (y_{1}(x))^{2} - (y_{2}(x))^{2} \right) \\
			& = -g(x) u(x) - h(x) u(x) \left( y_{1}(x) + y_{2}(x) \right) \\
			& = -g(x) u(x) - h(x) u(x) \left( u(x) + 2y_{2}(x) \right)	 \\	
			& = - \left( g(x) + 2h(x) y_{2}(x) \right) u(x) - h(x) \left( u(x) \right)^{2}.
	\end{align*}
Fazit: Ist eine Lösung $y_{2}$ von $(**)$ bekannt (z.B. durch \enquote{erraten}), so liefern Lösungen $u \not\equiv 0$ obiger Bernoulli Differentialgleichung für $u$ weitere Lösungen von $(**)$ der Form $y(x) = y_{2}(x) + u(x)$.
 

\chapter{Lineare Systeme mit konstanten Koeffizienten}


I.d. $\S$en sei $I \subseteq \R$ ein Intervall und $n \in \N$.

\textbf{Erinnerung}: $y = (y_{1}, \dotsc, y_{n})^{T} \colon I \rightarrow \R^{n}$ ist auf $I$ differenzierbar $\iff y_{1}, \dotsc, y_{n}$ sind auf $I$ differenzierbar. In diesem Fall:
	$$ y' = \left( y_{1}', \dotsc, y_{n}' \right)^{T}. $$


\begin{definition}
	Sei $g = (g_{1}, \dotsc, g_{n}) \colon [a, b] \rightarrow \R$ eine Funktion mit $g_{j} \in R[a, b]$ $(j = 1, \dotsc, n)$.
	$$ \int_{a}^{b} g(t) dt \coloneqq \left( \int_{a}^{b} g_{1}(t), \dotsc, \int_{a}^{b} g_{n}(t) dt \right)^{T} ~ \left( \in \R^{n} \right) $$
\end{definition}
	
\index{lineare Differentialgleichungssystem}	 \index{lineare Differentialgleichungssystem!homogen} \index{lineare Differentialgleichungssystem!inhomogen}	\index{homogen} \index{inhomogen}
Im Folgenden sei $A = (a_{jk})$ eine reelle $n \times n$-Matrix und $b_{j} \colon I \rightarrow \R$ stetig ($j = 1, \dotsc, n$). Wir betrachten das \textbf{lineare Differentialgleichungssystem}.

	\begin{align*}
		y_{1}' & = a_{11} y_{1} + a_{12} y_{2} + \dotsc + a_{1n} y_{n} \neq b_{1}(x) \\
		y_{2}' & = a_{21} y_{1} + a_{22} y_{2} + \dotsc + a_{2n} y_{n} \neq b_{2}(x) \\
		\vdots & \hspace{3.1cm} \vdots \hspace{2.8cm} \vdots \\		
		y_{1}' & = a_{n1} y_{1} + a_{n2} y_{2} + \dotsc + a_{nn} y_{n} \neq b_{n}(x) \\
	\end{align*}
Mit $y \coloneqq \left( y_{1}, \dotsc, y_{n} \right)^{T}$ und $b \coloneqq \left( b_{1}, \dotsc, b_{n} \right)^{T}$ schreibt sich dieses System in der Form:
\begin{equation*}
	y' = A y + b(x) \tag*{(1)}
\end{equation*}
Das System
\begin{equation*}
	y' = A y  \tag*{(2)}
\end{equation*}
hei{\ss}t das zu (1) gehörende \textbf{homogene System} ((1) hei{\ss}t inhomogen, falls $b \neq 0$).

Gesucht sind jetzt also vektorwertige Funktionen die (1) bzw. (2) erfüllen.

\index{Fundamentalsystem}
\begin{satz}[ohne Beweis] ~\ \label{22.1:satz}
	\begin{enumerate}
		\item Die Lösungen von (2) sind auf ganz $\R$ definiert. Sei 
			$$ V \coloneqq \left\{ y \colon\R \rightarrow \R^{n} : y \text{ ist eine Lösung von (2)} \right\}. $$
			Dann ist $C$ ein reeller Vektorraum und $\dim V = n$. Jede Basis von $V$ hei{\ss}t eine \textbf{Fundamentalsystem} $(FS)$ von (2).
		\item Ist $y_{p}$ eine spezielle Lösung von (1) auf $I$, so gilt $y$:
			$$ y \text{ ist eine Lösung von (1) auf } I \iff \exists y_{h} \in V \colon y(x) = y_{p} + y_{h}(x) ~(x \in I) $$
		\item Ist $x_{0} \in I$ und $y_{0} \in \R^{n}$, so hat das Anfangswertproblem
			$$ \begin{cases} ~ y' = Ay + b(x) \\ ~ y(x_{0}) = y_{0} \end{cases} $$
			auf $I$ genau eine Lösung.
	\end{enumerate}
\end{satz}


Sei $\lambda \in \R$ eine Eigenwert von $A$ und $v \in \R^{n}$ der zugehörige Eigenvektor, also $Av = \lambda v$. Dann gilt mit $y(x) \coloneqq e^{\lambda x} v$:
	$$ y'(x) = \lambda e^{\lambda x} v = e^{\lambda x} Av = A \left( e^{\lambda x} v \right) = A \left( y(x) \right). $$

\textbf{Wir betrachten zunächst (2)}: Sei $p(\lambda) \coloneqq \det \left( A - \lambda I \right)$. $A$ reell $\Rightarrow p$ hat reelle Koeffizienten. Übung: ist $\lambda_{0} \in \C$ und $p(\lambda_{0}) = 0$, so ist auch $p(\overline{\lambda_{0}}) = 0$. 

\bigskip

Beachte: für $\lambda_{0} \in \C$: $\operatorname{kern} \left( A - \lambda_{0} I \right) \subseteq \operatorname{kern} \left( A - \lambda_{0} I \right) \subseteq \dotsc$

\bigskip

\textbf{Lösungsmethode für (2)}: (ohne Beweis) 
\begin{enumerate}[label=\arabic*.]
	\item Bestimme die verschiedenen Eigenwerte $\lambda_{1}, \dotsc \lambda_{r}$ von $A$ ($r \leq n$) und deren Vielfachheit $k_{1}, \dotsc, k_{r}$, also
		$$ p(\lambda) = \left( -1 \right)^{n} \left( \lambda - \lambda_{1} \right)^{k_{1}} \cdot \dotsc \cdot \left( \lambda - \lambda_{r} \right)^{k_{r}}. $$
		Ordne diese wie folgt an:
		$$ \lambda_{1}, \dotsc, \lambda_{m} \in \R, ~\lambda_{m+1}, \dotsc, \lambda_{r} \in \C \setminus \R $$
		mit $\lambda_{m+1} = \mu_{1}, \dotsc, \lambda_{m+s} = \mu_{s}$ und $\lambda_{m+s+1} = \overline{\mu_{1}}, \dotsc, \lambda_{r} = \overline{\mu_{s}}$.
		$$ M \coloneqq \left\{ \lambda_{1}, \dotsc, \lambda_{m}, \lambda_{m+1}, \dotsc, \lambda_{m+s} \right\} $$
		($\lambda_{m+s+1}, \dotsc, \lambda_{r}$ bleiben unberücksichtigt!)
	\item Für jedes $\lambda_{j} \in M$ bestimme man eine Basis von $V_{j} \coloneqq \operatorname{kern} \left( A - \lambda_{j} I \right)^{k_{j}}$ wie folgt: Bestimme eine Basis von $\operatorname{kern}\left( A - \lambda_{j} I \right)$, ergänze diese zu einer Basis von 
		$$ \operatorname{kern} \left( A - \lambda_{j} I \right)^{2}, \dotsc $$
	\item Sei $\lambda_{j} \in M$ und $v$ ein Basisvektor von $V_{j}$.
		$$ y(x) \coloneqq e^{\lambda_{j} x } \left( v + \frac{x}{1!} \left( A - \lambda_{j} I \right) v + \dotsc + \frac{x}{(k_{j} - 1)!} \left( A - \lambda_{j} I \right)^{k_{j} - 1} v \right) $$
		Fall 1: $\lambda_{j} \in \R$. Dann ist $y(x) \in \R^{n}$ und $y$ eine Lösung von (2) auf $\R$. ~\\
		Fall 2: $\lambda_{j} \in \C \setminus \R$, Dann ist $y(x) \in \C^{n}$. Zerlege $y(x)$ komponentenweise in Real- und Imaginärteil:
			$$ y(x) =\underbrace{y^{(1)}(x)}_{ \in \R^{n}} + i \underbrace{y^{(2)}(x)}_{\in \R^{n}} $$
			Dann sind $y^{(y)}, y^{(2)}$ linear unabhängige Lösungen von (2) auf $\R$.
	\item Führt man 3. für jedes $\lambda_{j} \in M$ und jeden Basisvektor von $V_{j}$ durch, so erhält man ein Fundamentalsystem von (2) [...] bez. die lineare Hülle.
\end{enumerate}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $(*)$ $y' = \underbrace{\begin{pmatrix} 1 & -4 \\ 1 & 1 \end{pmatrix}}_{= A} y$, ($n = 2$). $\det \left( A - \lambda I \right) = \underbrace{\left( \lambda - (1+2i) \right) \left( \lambda - (1.2i) \right)}_{= (1-\lambda)^{2} + 4}$ ~\\
			$\lambda_{1} = 1 + 2i$, $k_{1} = 1$, $\lambda_{2} = \overline{\lambda_{1}}$, $k_{2} = 1$. $M = \{ 1 + 2i \}$, $\operatorname{kern}(A-\lambda_{1}I) = \left[ \begin{pmatrix}
				2i \\ i \end{pmatrix} \right]$
			\begin{align*}
				y(x) & \coloneqq e^{(1+2i)x} \begin{pmatrix} 2i \\ 1 \end{pmatrix} = e^{x} \left( \cos 2x + i \sin 2x \right) \begin{pmatrix} 2i \\ i \end{pmatrix} \\
				& = \underbrace{e^{x} \begin{pmatrix} -2 \sin 2x \\ \cos 2x \end{pmatrix}}_{\eqqcolon y^{(1)}(x)} + i e^{x} \underbrace{e^{x} \begin{pmatrix} 2 \cos 2x \\ \sin 2x \end{pmatrix}}_{\eqqcolon y^{(2)}(x)} 
			\end{align*}
			Fundamentalsystem für $(*)$: $y^{(1)}, y^{(2)}$. ~\\
			Allgemeine Lösung von $(*)$: $y(x) = c_{1} y^{(1)}(x) + c_{2} y^{(2)}(x)$ $(c_{1}, c_{2} \in \R)$.
		\item $(*)$ $y' = \underbrace{\begin{pmatrix} 0 & 1 & -1 \\ -2 & 3 & -1 \\ -1 & 1 & 1 \end{pmatrix}}_{= A} y$. $\det \left( A - \lambda I \right) = (\lambda - 2)  \left( \lambda - 1\right)^{2}$. Also
			 $$ \lambda_{1} = 2, k_{1} = 1, \lambda_{2} = 1, k_{2} = 2, $$
			$\lambda_{1} = 2$: $\operatorname{kern}(A - 2I) = \left[ \begin{pmatrix} 0 \\ 1 \\ 1  \end{pmatrix} \right]$
			$$ y^{(1)}(x) \coloneqq e^{2x} \begin{pmatrix} 0 \\ 1 \\ 1\end{pmatrix} \text{ ist eine Lösung von } (*) $$
			$\lambda_{2} = 1$: $\operatorname{kern}(A - I) = \left[ \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} \right] \subseteq \left[ \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix},  \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \right] = \operatorname{kern}(A - I)^{2}$
			$$ y^{(2)}(x) \coloneqq e^{x} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} \text{ ist eine Lösung von } (*) $$
			$$ y^{(3)}(x) \coloneqq e^{x} \left( \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} + x(A - I) \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \right) = e^{x} \left( \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} + x \begin{pmatrix} -1 \\ -1 \\ 0 \end{pmatrix} \right) = e^{x} \begin{pmatrix} -x \\ -x \\ 1 \end{pmatrix}  $$
			Fundamentalsystem von $(*)$: $y^{(1)}, y^{(2)}, y^{(3)}$.
		\item Sei $A$ wie in Beispiel b). Löse das Anfangswertproblem
			$$ \begin{cases} ~ y' = Ay \\ ~y(0) = (1, 0, 1)^{T}  \end{cases} $$
			Allgemeine Lösung von $y' = Ay$:
			$$ y(x) = c_{1} e^{2x} \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} + c_{2} e^{x} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} + c_{3} e^{x} \begin{pmatrix} -x \\ -x \\ 1 \end{pmatrix} $$
			$(1,0,1)^{T} = y(0) = c_{1} \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} + c_{2} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} + c_{3} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}$
			$$ \overset{\text{(LGS)}}{\iff} \begin{pmatrix} 0 & 1 & 0 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \end{pmatrix} \begin{pmatrix} c_{1} \\ c_{2} \\ c_{3} \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 1 \end{pmatrix} \iff \left( c_{1}, c_{2}, c_{3} \right)^{T} = (-1, 1, 2)^{T} $$
			Lösung des Anfangswertproblems: $y(x) = -e^{2x} \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} + e^{x} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} + 2 e^{x} \begin{pmatrix} -x \\ -x \\ 1 \end{pmatrix}$.
	\end{enumerate} 
\end{beispiele}

\index{Fundamentalmatrix}
Wir betrachten das \textbf{inhomogene System}.
\begin{equation*}
	y' = A y + b(x) \tag*{(1)}
\end{equation*}
Sei $y^{(1)}, y^{(2)}, \dotsc, y^{(n)}$ ein Fundamentalsystem von (2) $y' = Ay$. Setze
$$ Y(x) \coloneqq \left( y^{(1)}(x), \dotsc, y^{(n)}(x) \right). $$
$Y(x)$ ist eine $n \times n$-Matrix (\textbf{Fundamentalmatrix} (FS)) mit $j$-ter Spalte $y^{(j)}(x)$.

\begin{satz}[ohne Beweis] \label{22.2:satz}
	Für alle $x \in \R$ gilt: $\det Y(x) \neq 0$ 
\end{satz}

Für eine spezielle Lösung $y_{p}$ von (1) gehe wie folgt vor:

\begin{itemize}
	\item Ansatz: $y_{p}(x) = Y(x) c(x)$ mit einer noch unbekannten Funktion $c$. 
\end{itemize}
Dann gilt (ohne Beweis):
\begin{itemize}
	\item $y_{p}$ ist eine Lösung von (1) $\iff c'(x) = Y^{-1}(x) b(x)$. Wähle eine Stammfunktion 
		$$ c = \int Y^{-1}(x) b(x) dx $$
		 und dann $y_{p}$.
\end{itemize}


\begin{beispiel*}
	$(*)$ $y' = \underbrace{\begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}}_{\eqqcolon A} y + \underbrace{\begin{pmatrix} e^{x} \\ e^{-x} \end{pmatrix}}_{\eqqcolon b(x)}$.
	
	\begin{enumerate}[label=\arabic*.]
		\item Allgemeine Lösung von $y' = A y$: $\det (A - \lambda I) = (1 - \lambda) (1 - \lambda)$
			$$ A \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}, ~ A \begin{pmatrix} 0 \\ 1 \end{pmatrix} = - \begin{pmatrix} 0 \\ 1 \end{pmatrix} $$
			Fundamentalsystem der homogenen Gleichung: 
			$$ y^{(1)}(x) = e^{x} \begin{pmatrix} 1 \\ 0 \end{pmatrix}, ~ y^{(2)}(x) = e^{-x} \begin{pmatrix} 0 \\ 1 \end{pmatrix} $$
			Also: $Y(x) = \begin{pmatrix} e^{x} & 0 \\ 0 & e^{-x} \end{pmatrix}$.
		\item Spezielle Lösung von $(*)$: $Y^{-1}(x) = \begin{pmatrix} e^{-x} & 0 \\ 0 & e^{x} \end{pmatrix}$
			$$ Y^{-1}(x) b(x) = \begin{pmatrix} 1 \\ 1 \end{pmatrix} = c'(x) \Longrightarrow c(x) = \begin{pmatrix} x \\ x \end{pmatrix}  $$
			$\Rightarrow y_{p}(x) = \begin{pmatrix} e^{x} & 0 \\ 0 & e^{-x} \end{pmatrix} \begin{pmatrix} x \\ x \end{pmatrix} = \begin{pmatrix} x e^{x} \\ x e^{-x} \end{pmatrix}$
		\item Allgemeine Lösung von $(*)$ für $c_{1}, c_{2} \in \R$:
			\begin{align*}
				y(x) & = c_{1} \begin{pmatrix} e^{x} \\ 0 \end{pmatrix}  + c_{2} \begin{pmatrix} 0 \\ e^{-x} \end{pmatrix}  + \begin{pmatrix} x e^{x} \\ x e^{-x} \end{pmatrix}  \\
				& = \begin{pmatrix} c_{1} e^{x} + x e^{x} \\ c_{2} e^{-x} + x e^{-x} \end{pmatrix} 
			\end{align*}
	\end{enumerate}
\end{beispiel*}


\chapter{Lineare Differentialgleichung \texorpdfstring{$n$}{n}-ter Ordnung\onlyattoc{\protect\\~} mit konstanten Koeffizienten}

\index{Differentialgleichung!lineare!$n$-ter Ordnung} \index{Differentialgleichung!lineare} \index{Differentialgleichung!homogen} \index{Differentialgleichung!inhomogen} \index{homogen} \index{inhomogen}

I.d. $\S$en sei $n \in \N$, $I \subseteq \R$ ein Intervall, $b \colon I \rightarrow \R$ stetig und $a_{0}, a_{1}, \dotsc, a_{n-1} \in \R$.

\bigskip

Ist $y \colon I \rightarrow \R$ $n$-mal differenzierbar auf $I$, so setze
	$$ L y \coloneqq y^{(n)} + a_{n-1} y^{(n-1)} + \dotsc + a_{1} y' + a_{0} y $$
Die Differentialgleichung  
\begin{equation*}
	\left( L y \right) (x) = b(x) \tag*{(1)}
\end{equation*}
hei{\ss}t \textbf{lineare Differentialgleichung $n$-ter Ordnung mit konstanten Koeffizienten}. Die Gleichung
\begin{equation*}
	Ly = 0 \tag*{(*)}
\end{equation*}
hei{\ss}t die zu (1) gehörige \textbf{homogene Gleichung} ((1) hei{\ss}t \textbf{inhomogen}, falls $b \not\equiv 0$).

\index{Fundamentalsystem}
\begin{satz}[ohne Beweis] ~\ \label{23.1:satz}
	\begin{enumerate}
		\item Die Lösungen von (1) existieren auf $\R$.
		\item $V \coloneqq \big\{ y \colon \R \rightarrow \R \colon y$ ist $n$-mal differenzierbar und $y$ ist eine Lösung von (2) $\big\}$. Dann ist $v$ ein reeller Vektorraum und $\dim V = n$. Jede Basis von $V$ hei{\ss}t ein \textbf{Fundamentalsystem} von (2).
		\item Ist $y_{p}$ eine spezielle Lösung von (1) auf $I$, so gilt:
			$$ y \text{ ist eine Lösung von (1) auf } I \iff \exists y_{h} \in V ~\forall x \in I: y(x) = y_{p}(x) + y_{h}(x) $$
		\item Sei $x_{0} \in I$ und seien $\eta_{0}, \dotsc \eta_{n-1} \in \R$. Dann hat das Anfangswertproblem
			$$ \begin{cases} ~Ly = b(x) \\ ~y(x_{0}) = \eta_{0}, y'(x_{0}) = \eta_{1}, \dotsc, y^{(n-1)}(x_{0}) = \eta_{n-1} \end{cases} $$
			auf $I$ genau eine Lösung.
	\end{enumerate}	
\end{satz}

\index{charakteristisches Polynom}
\textbf{Lösungsmethode für (2)}: $y^{(n)} + a_{n-1}y^{(n-1)} + \dotsc + a_{1} y' + a_{0} y = 0$.
	$$ p(\lambda) \coloneqq \lambda^{n} + a_{n-1} \lambda^{n-1} + \dotsc a_{1} \lambda + a_{0} $$
hei{\ss}t \textbf{charakteristisches Polynom für (2)}.

\bigskip

Wie in \S22 sei $p(\lambda) = \left( \lambda - \lambda_{1} \right)^{k_{1}} \left( \lambda - \lambda_{2} \right)^{k_{2}} \cdot \dotsc \cdot \left( \lambda - \lambda_{r} \right)^{k_{r}}$, ($\lambda_{i} \neq \lambda_{j}$ für $i \neq j$).
\begin{enumerate}[label=\arabic*.]
	\item Mit $\lambda_{1}, \dotsc, \lambda_{m} \in \R$ und $\lambda_{m+1} = \mu_{1} , \dotsc, \lambda_{m+s} = \mu_{s} \in \C \setminus \R$ und $\lambda_{m+s+1} = \overline{\mu_{1}}, \dotsc, \lambda_{r} = \overline{\mu_{s}}$. Sei $M \coloneqq \left\{ \lambda_{1}, \dotsc, \lambda_{m}, \lambda_{m+1}, \dotsc, \lambda_{m+s} \right\}$. 
	\item Sei $\overline{\lambda_{j}} \in M$. 
	
		\bigskip
		
		Fall 1: $\lambda_{j} \in \R$. Dann sind
		 	$$ e^{\lambda_{j} x}, ~x e^{\lambda_{j} x}, \dotsc, ~x^{k_{j} - 1} e^{\lambda_{j} x} $$
		$k_{j}$ linear unabhängige Lösungen von (2).
		 	
		\bigskip
		 	
		Fall 2: $\lambda_{j} \in \C \setminus \R$. $\lambda_{j} = \alpha + i \beta$ ($\alpha, \beta \in \R, \beta \neq 0$). Dann sind
		\begin{align*}
			& e^{\alpha x} \cos \beta x, ~ x e^{\alpha x} \cos \beta x,  \dotsc, ~x^{k_{j} - 1} e^{\alpha x} \cos \beta x, \\
			& e^{\alpha x} \sin \beta x, ~ x e^{\alpha x} \sin \beta x,  \dotsc, ~x^{k_{j} - 1} e^{\alpha x} \sin \beta x
		\end{align*}
		$2k_{j}$ linear unabhängige Lösungen von (2).
	\item Führet man 2. für jedes $\lambda_{j} \in M$ durch, so erhält man ein Fundamentalsystem von (2).
\end{enumerate}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $(*)$ $y^{(5)} + 4 y^{(4)} + 2y''' - 4y'' + 8 y' + 16y = 0$
			\begin{align*}
				p(\lambda) & = \lambda^{5} + 4 \lambda^{4} + 2 \lambda^{3} - 4 \lambda^{2} + 8 \lambda + 16 \\
				& = \left( \lambda + 2 \right)^{3} \left( \lambda - (1+i) \right) \left( \lambda - (1-i) \right)
			\end{align*}
			Also: $\lambda_{1} = -2$, $k_{1} = 3$, $\lambda_{2} = 1 + i$, $k_{2} = 1$ ($\lambda_{3} = \overline{\lambda_{2}}$), also $M = \{ -2 , 1+i \}$. 
			
			\bigskip
			
			Fundamentalsystem von $(*)$: $e^{-2x}$, $x e^{-2x}$, $x^{2} e^{-2x}$, $e^{x} \cos x$, $e^{x} \sin x$. Allgemeine Lösung von $(*)$ für $c_{1}, \dotsc, c_{5} \in \R$:
			\begin{align*}
				y(x) & = c_{1} e^{-2x} + c_{2} x e^{-2x} + c_{3} x^{2} e^{-2x} + c_{3} e^{x} \cos x + c_{5} e^{x} \sin x \\
					& = e^{-2x} \left( c_{1} + c_{2} x + c_{3} x^{2} \right) + e^{x} \left( c_{4} \cos x + c_{5} \sin x \right).
			\end{align*}
		\item $(*)$ $y'' + 3 y' + 2y = 0$
			$$ p(\lambda) = \lambda^{2} + 3\lambda + 2 = (\lambda + 1) ( \lambda + 2). $$
			$\lambda_{1} = -1$, $k_{1} = 1$, $\lambda_{2} = -2$, $k_{2} = 1$. $M = \{1, 2\}$.
			
			\bigskip
			
			Fundamentalsystem von $(*)$: $e^{-x}$, $e^{-2x}$. Allgemeine Lösung von $(*)$ für $c_{1}, c_{2} \in \R$:
			$$ y(x) = c_{1} e^{-x} + c_{2} e^{-2x} $$
		\item Löse das Anfangswertproblem
			$$ \begin{cases} ~y'' + 3y' + 2y = 0 \\ ~ y(0) = 1, y'(0) = 1 \end{cases} $$
			Allgemeine Lösung der Differentialgleichung: $y(x) = c_{1} e^{-x} + c_{2} e^{-2x}$.
			$$ 1 = c_{1} + c_{2} = y(0) \Rightarrow c_{2} = 1 - c_{1} $$
			$y'(x) = - c_{1} e^{-x} - 2 c_{2} e^{-2x}$.
			$$ 1 = y'(0) = -c_{1} - 2 c_{2} = -c_{1} - 2(1-c_{1}) = -c_{1} - 2 + 2c_{1} = c_{1} - 2 $$
			$\Rightarrow c_{1} = 3 \Rightarrow c_{2} = -2$. Lösung des Anfangswertproblems:
			$$ y(x) = 3 e^{-x} - 2 e^{-2x}. $$ 
		\item $(*)$ $y''' - 3y'' = 0$. Charakteristische Polynom:
			$$ p(\lambda) = \lambda^{3} - 3\lambda^{2} = \lambda^{2} \left( \lambda - 3\right). $$
			$\lambda_{1} = 0$, $k_{1} = 2$, $\lambda_{2} = 3$, $k_{2} = 1$.
			
			\bigskip
			
			Fundamentalsystem von $(*)$: $e^{0x}$, $x e^{0x}$, $e^{3x}$, also $1, x, e^{3x}$. Allgemeine Lösung von $(*)$ für $c_{1}, c_{2}, c_{3} \in \R$:
			$$	y(x) = c_{1} + c_{2} x + c_{3} e^{3x}.  $$
			Zur \textbf{inhomogenen Gleichung}
			\begin{equation*}
				L y = b(x) \tag*{(1)}
			\end{equation*}
			Seien $\gamma, \delta \in \R$, $m \in \N_{0}$ und $q$ ein Polynom vom Grad $m$. $b$ habe die Gestalt
			$$ b(x) = q(x) e^{\gamma x } \cos \left( \delta x \right) ~ \text{ oder } ~ b(x) = q(x) e^{\gamma x} \sin \left( \delta x \right) $$
			Sei $p$ das charakteristische Polynom von 
			\begin{equation*}
				Ly = 0 \tag*{(2)}
			\end{equation*}
			Fall 1: $p \left( \gamma + i \delta\right) \neq 0$, wähle Ansatz:
			$$ y_{p}(x) \coloneqq \left( \hat{q}(x) \cos\left( \delta x \right) + \tilde{q}(x) \sin \left( \delta x \right) \right) e^{\gamma x}. $$
			Fall 2: $\gamma + i \delta$ ist eine $\nu$-fache Nullstelle von $p$. Wähle Ansatz
			$$ y_{p}(x) \coloneqq x^{\nu} \left( \hat{q}(x) \cos\left( \delta x \right) + \tilde{q}(x) \sin \left( \delta x \right) \right) e^{\gamma x}. $$
			In beiden Fällen sind $\hat{q}$ und $\tilde{q}$ Polynome vom Grade $m$. In beiden Fällen führt $y_{p}$ zu einer speziellen Lösung von (1).
	\end{enumerate}
\end{beispiele}


\begin{beispiele} ~\
	\begin{enumerate}
		\item $(*)$ $y''' - y' = x - 1$, ($b(x) = x - 1$).
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung von $y''' - y' = 0$
					$$ p(\lambda) = \lambda^{3} - \lambda = \lambda \left(\lambda^{2} - 1\right) = \lambda (\lambda - 1) (\lambda + 1) $$
					Fundamentalsystem: $1$, $e^{x}$, $e^{-x}$.
				\item $b(x) = x - 1$. Also: $\gamma = \delta = 0$, $q(x) = x - 1$, $m = 1$. $p(\gamma + i\delta) = p(0) = 0$, $\nu =1$. Ansatz:
					$$ y_{p}(x) = x (ax + b) = ax^{2} + b^x. $$
					$y_{p}'(x) = 2ax + b$; $y_{p}''' = 0$. Dann:
					$$ x - 1 \overset{!}{=} y_{p}''' - y_{p}' = -2ax - b \iff -2a = 1, b = 1 $$
					$\Rightarrow y_{p}(x) = -\frac{1}{2} x^{2} + 1$.
				\item Allgemeine Lösung von $(*)$: $y(x) = c_{1} + c_{2} e^{x} + c_{3} e^{-x} - \frac{1}{2} x^{2} + 1$.
			\end{enumerate}
		\item  $(*)$ $y'' + 4y' ) \cos 2x$
			\begin{enumerate}[label=\arabic*.]
				\item Allgemeine Lösung von $y'' + 4y' = 0$.
					$$ p(\lambda) = \lambda^{2} + 4\lambda = \lambda ( \lambda + 4), $$
					Fundamentalsystem: $1$, $e^{-4x}$.
				\item $b(x) = \cos 2x$, also $\gamma = 0$, $\delta = 2$, $q(x) = 1$, $m = 0$. $p(\gamma + i\delta) = p(2i) \neq 0$. Ansatz:
					$$ y_{p}(x) = a\cos(2x) + b \left( \sin 2x \right). $$
					Damit:
					\begin{align*}
						y_{p}'(x) & = -2a \sin (2x) + 2b\cos(2x), \\
						y_{p}''(x) & = -4a \cos(2x) - 4b \sin(2x). 
					\end{align*}
					Einsetzen in die Differentialgleichung liefert:
					$$ \cos(2x) \overset{!}{=} y_{p}''(x) + 4y_{p}'(x) = \left(8b - 4a \right) \cos(2x) - \left(4b+8a\right) \sin(2x) $$
					$\iff 8b - 4a = 1$, $4b + 8a = 0 \iff a = -\frac{1}{20}, b = \frac{1}{10}$. Daraus folgt:
						$$ y_{p}(x) = \frac{1}{10} \sin (2x) - \frac{1}{20} \cos(2x). $$
					Allgemeine Lösung von $(*)$:
					$$ y(x) = c_{1} + c_{2} e^{-4x} + \frac{1}{10} \left( \sin(2x= - \frac{1}{2} \cos (2x) \right). $$
			\end{enumerate}
	\end{enumerate}
\end{beispiele}


\chapter{Die Fouriertransformation}

\index{stückweise} \index{stückweise!stetig} \index{stückweise!glatt}
\begin{definition} ~\
	\begin{enumerate}
		\item $g \colon [a, b] \rightarrow \R$ hei{\ss}t \textbf{auf [a, b] stückweise stetig} $:\iff \exists t_{0}, t_{1}, \dotsc, t_{m} \in [a, b]:$
			$$ a = t_{0} < t_{1} < \dotsc < t_{m} = b, ~g \in C\left( (t_{j-1}, t_{j}) \right) \quad (j = 1, \dotsc, m)  $$
			und es existiert die folgenden einseitigen Grenzwerte:
			$$ g(a+), ~ g(b-), ~ g(t_{j}+), ~g(t_{j}-) \quad (j = 1, \dotsc, m-1) $$ % todo Bild Seite 82
		\item $g \colon [a, b] \rightarrow \R$ hei{\ss}t \textbf{auf $[a, b]$ stückweise glatt} $:\iff \exists t_{0}, \dotsc, t_{m} \in [a, b]:$
			$$ t_{0} = a < t_{1} < \dotsc < t_{m} = b, ~g \in C^{1}\left( (t_{j-1}, t_{j}) \right) \quad (j = 1, \dotsc, m) $$
			und es existieren die folgenden einseitigen Grenzwerte:
			$$ g(t_{j}+), ~ g(t_{j}-), ~g'(t_{j}+), ~g'(t_{j}-) \quad (j =1, \dotsc, m-1) $$
			$$ g(a+), ~g'(a+), ~g'(b-), ~g(b-) $$
		\item $g \colon \R \rightarrow \R$ hei{\ss}t \textbf{auf $\R$ stückweise stetig} bzw. \textbf{glatt} $:\iff g$ ist auf jedem Intervall $[a, b]$ stückweise stetig bzw. glatt.
		\item Sei $g \colon \R \rightarrow \R$ stückweise glatt und $x_{0} \in \R$. Dann existieren $g'(x_{0}+)$ und $g'(x_{0}-)$. Setze
			\begin{equation*}
				g'(x_{0}) \coloneqq \frac{1}{2} \left( g'(x_{0}+) + g'(x_{0}-) \right)  \tag*{$(*)$}
			\end{equation*}
			Beachte: Ist $g$ in $x_{0}$ differenzierbar, so stimmt $(*)$ mit der üblichen Ableitung über ein.
	\end{enumerate}
\end{definition}


\begin{beispiel*}
	$g(x) = |x|$; $g'(0+) = 1$, $g'(0-) = -1$, also $g'(0) = 0$.	
\end{beispiel*}

\index{differenzierbar} \index{stückweise} \index{stückweise!stetig} \index{stückweise!glatt}
\begin{definition}
	Sei $I \subseteq \R$ ein Intervall, $f \colon I \rightarrow \C$ eine Funktion, $u(x) \coloneqq \operatorname{Re}f(x)$ und $v(x) \coloneqq \operatorname{Im}f(x)$ ($x \in I$, also $f = u + iv$).
	\begin{enumerate}
		\item $f$ hei{\ss}t auf $I$ differenzierbar $:\iff u$ und $v$ sind auf $I$ differenzierbar. In diesem Fall: $f' \coloneqq u' + i v'$.
		\item Ist $I = [a, b]$ und gilt $u, v \in R[a, b]$, so setze
			$$ \int_{a}^{b} f(x) dx = \int_{a}^{b} u(x) dx + i \int_{a}^{b} $$
		\item Ist $I = \R$, so hei{\ss}t $f$ auf $I$ stückweise stetig bzw. glatt $:\iff u,v$ sind auf $I$ stückweise stetig bzw. glatt.
	\end{enumerate}	
\end{definition}


Sei $I = [a, b]$ und $u, v \in R[a, b]$. Übung:
	$$ \left| \int_{a}^{b} f(t) dt \right| \leq \int_{a}^{b} \left| f(t) \right| dt $$
Besitzen $u$ und $v$ auf $[a, b]$ die Stammfunktionen $U$ bzw. $V$, so setze $F \coloneqq U + iV$. Dann:
	$$ F' = U' + i V' = u + iv = f $$
auf $[a, b]$ und $\int_{a}^{b} f(x) dx = F(b) - F(a)$.

\bigskip

Weitere Regeln wie Substitution, partielle Integration, etc. gelten wörtlich für $f \colon [a, b] \rightarrow \C$.


\begin{beispiel*}
	Sei $z_{0} \in \C$, $z_{0} \neq 0$ und $f(t) \coloneqq e^{z_{0} t}$. $F(t) \coloneqq \frac{1}{z_{0}} e^{z_{0} t}$. Dann: $F' = f$ auf $\R$. Für $a < b$:
	$$ \int_{a}^{b} e^{z_{0} t} dt = F(b) - F(a) = \frac{1}{z_{0}} \left( e^{z_{0}b} - e^{z_{0}a} \right). $$	
\end{beispiel*}

\index{konvergent} \index{konvergent!absolut} \index{absolut integrierbar}
\begin{definition}
	$f \colon \R \rightarrow \C$ sei eine Funktion, $u \colon \operatorname{Re}f$, $v \coloneqq \operatorname{Im}f$ und es gelte: $u, v \in R[a, b]$ für jedes Intervall $[a, b] \subseteq \R$. $\int_{-\infty}^{\infty} f(t) dt \text{ hei{\ss}t } \textbf{(absolut) konvergent}$
	$$ :\iff \int_{-\infty}^{\infty} u(t) dt \text{ und } \int_{-\infty}^{\infty} v(t) dt \text{ sind (absolut) konvergent} $$
	Im Konvergenzfall: 
	$$ \int_{-\infty}^{\infty} f(t) = \int_{-\infty}^{\infty} u(t) dt + i \int_{-\infty}^{\infty} v(t) dt. $$
	Ist $\int_{-\infty}^{\infty} f(x) dx$ absolut konvergent, so hei{\ss}t $f$ \textbf{absolut integrierbar} (aib).
\end{definition}


\begin{satz}[ohne Beweis] \label{24.1:satz}
	$f \colon \R \rightarrow \C$ sei stückweise stetig.
	\begin{enumerate}
		\item $f$ ist absolut integrierbar $\iff \int_{-\infty}^{\infty} |f(x)| dx$ ist konvergent.
		\item Ist $g \colon \R \rightarrow \C$ absolut integrierbar und $|f| \leq |g|$ auf $\R$, so ist $f$ absolut integrierbar.
	\end{enumerate}	
\end{satz}


\begin{satz}[ohne Beweis] \label{24.2.satz}
	$f \colon \R \rightarrow \C$ sei stückweise glatt, $f$ und $f'$ seien absolut integrierbar und $f$ habe höchstens endlich viele Unstetigkeitsstellen. Dann ist $f$ auf $\R$ beschränkt und	
	$$ \lim_{x \rightarrow \infty} f(x) = \lim_{x \rightarrow -\infty} f(x) = 0. $$
\end{satz}

\index{Fouriertransformation}
\begin{unnamedtheorem}[Satz und Definition] \label{24.3:satz}
	$f \colon \R \rightarrow \C$ sei stückweise stetig und absolut integrierbar. Für $s \in \R$ sei $g_{s}(t) \coloneqq f(t) e^{-ist}$ ($t \in \R$). Dann:
	\begin{enumerate}
		\item $g_{s}$ ist stückweise stetig
		\item $g_{s}$ ist absolut integrierbar
		\item Ist $\hat{f} \colon \R \rightarrow \C$ definiert durch $\hat{f}(s) = \frac{1}{2\pi} \int_{-\infty}^{\infty} f(t) e^{-ist} dt$, so gilt: 
			\begin{enumerate}
				\item $\hat{f}$ ist auf $\R$ beschränkt
				\item $\hat{f}$ ist auf $\R$ stetig.
			\end{enumerate}
	\end{enumerate}
	$\hat{f}$ hei{\ss}t die \textbf{Fouriertransformierte von $f$}. Die Zuordnung $f \mapsto \hat{f}$ hei{\ss}t \textbf{Fouriertransformation}.
	
	\begin{proof} ~\
		\begin{enumerate}
			\item Klar.
			\item $|g_{s}(t)| = |f(t)| \underbrace{\left|e^{-ist}\right|}_{= 1} = f(t)$ $\forall t \in \R \xRightarrow[]{\ref{24.1:satz}}$ Beh.
			\item \begin{enumerate}
					\item $\left| \hat{f}(s) \right| \leq \frac{1}{2\pi} \int_{-\infty}^{\infty} |f(t)| \underbrace{\left| e^{ist} \right|}_{= 1} dt = \frac{1}{2\pi} \int_{-\infty}^{\infty} |f(t)| dt ~\forall s \in \R$
					\item ohne Beweis.
				  \end{enumerate}
		\end{enumerate}
	\end{proof}
\end{unnamedtheorem}


\begin{beispiele} ~\
		\begin{enumerate}
			\item $f(t) \coloneqq \begin{cases} e^{-t}, & t \geq 0 \\ 0, & t < 0. \end{cases}~$ Klar: $f$ ist auf $\R$ stückweise stetig. Sei $\beta > 0$: % todo Bild Seite 86
			$$ \int_{0}^{\beta} f(t) dt = \int_{0}^{\beta} e^{-t} dt = e^{-t} \Big|_{0}^{\beta} = -e^{-\beta} + 1 \longrightarrow 1, \quad (\beta \rightarrow \infty) $$
			Damit ist $\int_{0}^{\infty} f(t) dt$ konvergent, somit auch $\int_{-\infty}^{\infty} f(t) dt = \infty_{0}^{\infty} f(t) dt$. $f \geq 0$ auf $\R \Rightarrow f$ ist absolut integrierbar.
			$$ \hat{f}(s) = \frac{1}{2\pi} \int_{0}^{\infty} e^{-t} e^{-ist} dt = \frac{1}{2\pi} \int_{0}^{\infty} e^{-(1+is)t} dt. $$
			Sei $\beta > 0$:
			\begin{align*}
				\int_{0}^{\beta} e^{-(1+is)t} dt & = -\frac{1}{1+is} e^{-(1+is)t} \Big|_{0}^{\beta} \\
				& = - \frac{1}{1 + is} \left( e^{-(1+is)\beta} - 1 \right) \\
				& = \frac{1}{1 + is} \left( 1 - e^{-\beta} e^{-is\beta} \right)
			\end{align*}
			$\left| e^{-\beta} e^{-is\beta} \right| = e^{-\beta} \underbrace{\left| e^{-is\beta} \right|}_{=1} = e^{-\beta} \longrightarrow 0 \quad (\beta \rightarrow \infty) \Rightarrow \int_{0}^{\infty} e^{-(1+is)t} dt = \frac{1}{1 + is}$
			$$ \Longrightarrow \hat{f}(s) = \frac{1}{2\pi} \frac{1}{1 + is} \quad (s \in \R) $$
			Analog: $\int_{-\infty}^{0} e^{t} e^{-ist} dt = \frac{1}{1 - is}$. % todo Bild Seite 86
		\item $f(t) = e^{-|t|} = \begin{cases} e^{-t} & t \geq 0 \\ e^{t}, & t < 0. \end{cases}~$ Es ist $\int_{-\infty}^{\infty} f(t) dt = 2 \int_{0}^{\infty} e^{-t} dt$ 
		
			\bigskip
		
			Beispiel a) $\Rightarrow f$ ist auf $\R$ absolut integrierbar. Klar: $f$ ist auf $\R$ stückweise stetig.
				$$ \xRightarrow[]{a)} \int_{0}^{\infty} e^{-t} e^{-ist} dt = \frac{1}{1 + is} \Rightarrow \hat{f}(s) = \frac{1}{\pi} \frac{1}{1 + s^{2}} $$
			Analog sieht man: 
				$$ \int^{0}_{-\infty} e^{t} e^{-ist} dt = \frac{1}{1 - is}. $$
			Also:
			  \begin{align*}
				\hat{f}(s) & = \frac{1}{2\pi} \left( \int^{0}_{-\infty} e^{t} e^{-ist} dt + \int_{0}^{\infty} e^{-t} e^{-ist} dt \right) \\
						& = \frac{1}{2\pi} \left( \frac{1}{1 - is} + \frac{1}{1 +is} \right)  \\ 
						& = \frac{1}{2\pi} \left( \frac{1+is + 1 - is}{1+s^{2}} \right) \\
						& = \frac{1}{\pi} \frac{1}{1 + s^{2}}
			  \end{align*}
		\item $f(t) \coloneqq \begin{cases} 1, & |t| \leq 1 \\ 0, & |t| > 1. \end{cases}$ Klar: $f$ ist stückweise stetig und absolut integrierbar. % todo Bild Seite 87a
			$$ \hat{f}(s) = \frac{1}{2\pi} \int_{-1}^{1} e^{-ist} dt $$
			Es gilt:
			\begin{itemize}
				\item $s = 0$: $\hat{f}(s) = \frac{1}{2\pi} \int_{-1}^{1} 1 dt = \frac{1}{\pi}$
				\item $s \neq 0$: $\hat{f}(s) = \frac{1}{2 \pi} \left[ - \frac{1}{is} e^{-ist} \right]_{-1}^{1}$
			 	 $$ \quad  = \frac{1}{2\pi} \left( -\frac{1}{is} \left( e^{-is} - e^{is} \right) \right)  = \frac{1}{s} \frac{1}{\pi} \underbrace{\frac{1}{2i} \left( e^{is} - e^{-is} \right)}_{= \sin(s)}  = \frac{1}{\pi} \frac{\sin(s)}{s} $$
			\end{itemize}
		\end{enumerate}
\end{beispiele}

Frage: Kann man $f$ aus $\hat{f}$ rekonstruieren?

\index{Cauchysche Hauptwert}
\subsubsection*{Der Cauchysche Hauptwert}

Das Integral $\int_{-\infty}^{\infty} f(x) dx$ war definiert als 
	$$ \lim_{\beta \rightarrow \infty} \int_{\beta}^{0} f(x) dx + \lim_{\alpha \rightarrow \infty} \int_{0}^{\infty} f(x) dx $$
und nicht als $\lim_{\alpha \rightarrow \infty} \int_{-\alpha}^{\alpha} f(x) dx.$


\begin{beispiel*}
	$\int_{-\alpha}^{\alpha} x dx = 0 ~\forall \alpha \in 0$. $\int_{-\infty}^{\infty} x dx$ ist divergent.	
\end{beispiel*}

\index{Cauchyscher Hauptwert}
\begin{definition}
	Sei $f = u + iv \colon \R \rightarrow \C$ eine Funktion mit $u, v \in R[a, b] \forall [a, b] \subseteq \R$. 
	
	\bigskip
	
	Existiert der Grenzwert $\lim_{\alpha \rightarrow \infty} \int_{-\alpha}^{\alpha} f(x) dx$, so hei{\ss}t dieser Grenzwert \textbf{Cauchyscher Hauptwert} (CH) und man schreibt
	$$ CH \text{-} \int_{-\infty}^{\infty} f(x) dx \coloneqq \lim_{\alpha \rightarrow \infty} \int_{-\alpha}^{\alpha} f(x) dx. $$
\end{definition}


Übung: Ist $\int_{-\infty}^{\infty} f(x) dx$ konvergent, so existiert $CH-\int_{-\infty}^{\infty} f(x) dx$ und 
$$ \int_{-\infty}^{\infty} f(x) dx = CH \text{-} \int_{-\infty}^{\infty} f(x) dx. $$

\begin{beispiel*}
	$\int_{-\infty}^{\infty} x dx$ divergent, $CH\text{-}\int_{-\infty}^{\infty} x dx = 0$.	
\end{beispiel*}

\begin{satz}[ohne Beweis] \label{24.4:satz}
	$f \colon \R \rightarrow \C$ sei stückweise glatt und absolut integrierbar. Dann:
	$$ CH\text{-}\int_{-\infty}^{\infty} \hat{f}(s) e^{ist} ds = \frac{1}{2} \left( f(t+) + f(t-) \right) \quad \forall t \in \R $$
	Ist also $f$ stetig auf $\R$, so gilt:
	$$ f(t) = CH\text{-}\int_{-\infty}^{\infty} \hat{f}(s) e^{ist} ds \quad \forall t \in \R $$
\end{satz}


\begin{beispiel*}
	Behauptung: $\int_{0}^{\infty} \frac{\sin x}{x} dx$ ist konvergent und $= \frac{\pi}{2}$.
	
	\begin{proof}
		$f(t) \coloneqq \begin{cases} 1, & |t| \leq 1 \\ 0, & |t| > 1. \end{cases}~$ Bekannt: $\hat{f}(s) = \frac{1}{\pi} \begin{cases} 1, & s = 0 \\ \frac{\sin s}{s}, & s \neq 0 \end{cases}$
		\begin{equation*}
			\xRightarrow[]{\ref{24.4:satz}} CH\text{-}\int_{-\infty}^{\infty} \hat{f}(s) e^{is} ds = \frac{1}{2} \left( f(1+) + f(1-) \right) = \frac{1}{2}  \tag*{(*)}
		\end{equation*}
		Für $s \neq 0$:
			\begin{align*}
				\hat{f}(s) e^{is} & = \frac{1}{\pi} \frac{\sin(s)}{s} \left( \cos(s) + i \sin(s) \right) \\
				& = \frac{1}{\pi} \left( \frac{\sin(s) \cos(s)}{s} + i \frac{|sin^{2}(s)}{s} \right)
			\end{align*}
		Sei $\alpha > 0$.
		\begin{itemize}
			\item $s \mapsto \frac{\sin^{2}(s)}{s}$ ist ungerade $\Rightarrow \int_{-\alpha}^{\alpha} \frac{\sin^{2}(s)}{s} ds = 0$
			\item $s \mapsto \frac{\sin(s) \cos(s)}{s}$ ist gerade
				$$ \Rightarrow \int_{-\alpha}^{\alpha} \frac{\sin(s) \cos(s)}{s} ds = 2 \int_{0}^{s} \underbrace{\frac{\sin(s) \cos(s)}{s}}_{\frac{1}{2} \frac{\sin(2s)}{s}} ds = \int_{0}^{\alpha} \frac{\sin(2s)}{s} ds $$
				Substituiert man $t = 2s$ gilt damit $dt = 2 ds$ und daraus folgt:
				$$ \int_{0}^{\alpha} \frac{\sin(2s)}{s} ds = 2 \int_{0}^{2 \alpha} \frac{\sin(t)}{t} \frac{1}{2} dt = \int_{0}^{2 \alpha} \frac{\sin(t)}{t} dt $$
				$$ \Longrightarrow \frac{1}{2} \overset{(*)}{=} \lim_{\alpha \rightarrow \infty} \int_{-\alpha}^{\alpha} \hat{f}(s) e^{is} ds = \frac{1}{\pi} \lim_{\alpha \rightarrow \infty} \int_{0}^{2 \alpha} \frac{\sin t}{t} dt = \frac{1}{\pi} \int_{0}^{\infty} \frac{\sin t}{t} dt $$
				$\Rightarrow$ Behauptung.
		\end{itemize}
	\end{proof}	
\end{beispiel*}

Sei $V \coloneqq \left\{ f \colon \R \rightarrow \C \colon f \text{ ist stückweise stetig und absolut integrierbar} \right\}$ Für $f \in V$ und $s \in \R$: 
$$ \hat{f}(s) = \frac{1}{2\pi} \int_{-\infty}^{\infty} f(t) e^{-ist} dt. $$


\begin{satz} ~\ \label{24.5:satz}
	\begin{enumerate}
		\item $V$ ist ein komplexer Vektorraum und es gilt für $f, g \in V$ und $\alpha, \beta \in \C$:
			$$ \widehat{\alpha f + \beta g} = \alpha \hat{f} + \beta \hat{g}. $$
		\item Sei $f \in V$, $h \in \R$ und $f_{h} \colon \R \rightarrow \C$ sei definiert durch
			$$ f_{h}(x) \coloneqq f(x + h). $$
			Dann: $f_{h} \in V$ und für $s \in \R$: $\hat{f}_{h}(s) = e^{ish} \hat{f}(s)$.
	\end{enumerate}
	
	\begin{proof}
		\begin{enumerate}
			\item Klar.
			\item $\hat{f}_{h}(s) = \frac{1}{2\pi} \int_{-\infty}^{\infty} f(t + h) e^{-ist} dt$. Sei $c > 0$, substituiert man $\tau \coloneqq t + h$ gilt damit  $d\tau = dt$ und daraus folgt:
				\begin{align*}
					\int_{0}^{c} f(t+h) e^{-ist} dt & = \int_{h}^{h+c} f(\tau) e^{-is(\tau - h)} d\tau \\
					& = e^{ish} \int_{h}^{h+c} f(\tau) e^{-is\tau} d\tau \\
					& \xrightarrow[c \rightarrow \infty]{} e^{ish} \int_{h}^{\infty} f(\tau) e^{is\tau} d\tau
				\end{align*}
				Also: 
				$$\int_{0}{\infty} f_{h}(t) e^{-ist} dt = e^{ish} \int_{h}^{\infty} f(\tau) e^{-is\tau} d\tau. $$
				Analog: $\int_{-\infty}^{0} f_{h}(t) e^{-ist} dt = e^{ish} \int_{-\infty}^{h} f(\tau) e^{-is\tau} d\tau$.
		\end{enumerate}
	\end{proof}
\end{satz}

\index{Faltung}
\begin{definition}
	$f_{1}, f_{2} \colon \R \rightarrow \C$ seien Funktionen mit $\forall t \in \R$: 
	$$ \int_{-\infty}^{\infty} f_{1}(t - x) f_{2}(x) dx $$
	konvergiert. Dann hei{\ss}t für $t \in \R$
	$$ ( f_1 \ast f_2)(t) \coloneqq \frac{1}{2\pi} \int_{-\infty}^{\infty} f_1(t-x) f_2(x) dx $$
	\textbf{Faltung} von $f_1$ und $f_2$
\end{definition}


\begin{beispiel*}
	$f_1(t) = \begin{cases} e^{-t}, & t \geq 0 \\ 0, & t < 0 \end{cases}~$, $f_2(t) = \begin{cases} 1, & |t| \leq 1 \\ 0, & |t| > 1 \end{cases}$
	
	\bigskip
	
	Für $t \in \R$:
	$$ {2 \pi \left( f_1 \ast f_2 \right) (t)}_{\eqqcolon g(t)} = \int_{-\infty}^{\infty} f_1(t-x) f_2(x) dx = \int_{-1}^{1} f_1(t-x) f_2(x) dt = \int_{-1}^{1} f_1(t-x) dx $$
	\begin{itemize}
		\item Fall 1: $t < -1$. Für $x \in [-1, 1]: t - x < 1 \Rightarrow f_1(t-x) = 0 \Rightarrow g(t) = 0$.
		\item Fall 2: $t \geq 1$. Für $x \in [-1, 1]: t - x \geq 0 \Rightarrow f_1(t-x) =be^{-(t-x)} = e^{x} e^{-t}$
			$$ \Rightarrow g(t) = \int_{-1}^{1} e^{x} e^{-t} dx = e^{-t} \left( e - \frac{1}{e} \right). $$
		\item Fall 3: $-1 \leq t <$. Nachrechnen: $g(t) = 1 - e^{-t-1}$.
	\end{itemize}
\end{beispiel*}


\begin{satz}[ohne Beweis] \label{24.6:satz}
	Es seien $f_1, f_2 \colon \R \rightarrow \R$ stetig und absolut integrierbar und $f_1$ sei beschränkt. Dann:
	\begin{enumerate}
		\item $\forall t \in \R$: $\int_{-\infty}^{\infty} f_1(t-x) f_2(x) dx$ konvergiert absolut.
		\item $f_1 \ast f_2$ ist stetig und absolut integrierbar, also $f_1 \ast f_2 \in V$ und
			$$ \left( \widehat{f_1 \ast f_2} \right) (s) = \hat{f}_1(s) \hat{f}_2(s). $$
		\item Für $t \in \R$: 
			$$ \left| \left( f_1 \ast f_2 \right) (t) \right| \leq \frac{1}{2\pi} \sup_{x \in \R} \left| f_1(x) \right| \int_{-\infty}^{\infty} \left|f_2(x) \right| dx. $$
	\end{enumerate}
\end{satz}


\begin{satz} \label{24.7:satz}
	$f \colon \R \rightarrow \C$ sei stückweise glatt, $f$ sei stetig und $f$ sei absolut integrierbar. Weiter sei $f'$ überall definiert und absolut integrierbar. Dann:
	$$ f' \in V ~\text{ und } ~ \widehat{f'}(s) = is \hat{f}(s) \quad \forall s \in \R $$
	
	\begin{proof}
		Klar: $f' \in V$. 
		\begin{itemize}
			\item Fall 1: $s=0$: $\widehat{f'}(0) = \frac{1}{2\pi} \int_{-\infty}^{\infty} f'(t) dt$. Mit $\beta > 0$:
				$$ \int_{0}^{\beta} f'(t) dt = f(\beta) - f(0) \xrightarrow[]{\ref{24.2.satz}} -f(0) \quad (\beta \rightarrow 0) $$
				D.h.: $\int_{0}^{\infty} f'(t) dt = - f(0)$. Damit: $\widehat{f'}(0) = 0 = i0 \hat{f}(0)$.
			\item Fall 2: $s\neq0$: $\widehat{f'}(s) = \frac{1}{2\pi} \int_{-\infty}^{\infty} f'(t) e^{-ist} dt$. Mit $\beta > 0$: 
				\begin{align*}
					\int_{0}^{\beta} \underbrace{f(t)}_{u} \underbrace{e^{-ist}}_{v'} dt & = - \frac{1}{is} e^{-ist} f(t) \Big|_{0}^{\beta} - \int_{0}^{\beta} f'(t) \left( - \frac{1}{is} e^{-ist} \right) dt \\
					& = -\frac{1}{is} e^{-is\beta} f(\beta) + \frac{1}{is} f(0) + \frac{1}{is} \int_{0}^{\beta} f'(t) e^{-ist} dt
				\end{align*} 
				$f(\beta) \rightarrow 0$ ($\beta \rightarrow \infty$) (wg. \ref{24.2.satz}), $\left| e^{is\beta} \right| = 1$
				$$ \xRightarrow[]{\beta \rightarrow \infty} \int_{0}^{\infty} f(t) e^{-ist} dt = \frac{1}{is} f(0) + \frac{1}{is} \int_{0}^{\infty} f'(t) e^{-ist} dt $$
				Analog: $\int_{-\infty}^{0} f(t) e^{-ist} dt = -\frac{1}{is} f(0) + \frac{1}{is} \int_{-\infty}^{0} f'(t) e^{-ist} dt$.
		\end{itemize}
	\end{proof}
\end{satz}


\begin{anwendung*}
	$f \colon \R \rightarrow \C$ sei zweimal stetig differenzierbar und $f, f', f''$ seien absolut integrierbar.
	
	\bigskip
	
	Gesucht: $u \colon \R \rightarrow \C$ stetig und absolut integrierbar mit $\forall t \in \R$:
	\begin{equation}
		\int_{-\infty}^{\infty} e^{-|t - \tau|} u(\tau) d\tau = f(t) \tag*{$(*)$}
	\end{equation}
	$g(t) \coloneqq e^{-|t|}$. Bekannt: $\hat{g}(s) = \frac{1}{\pi} \frac{1}{1+s^{2}}$. Sei $u$ eine Lösung von $(*)$, also: $f(t) = 2\pi \left( g \ast u \right) (t)$.
	$$ \Rightarrow \hat{f}(s) = 2\pi \left(\widehat{ g \ast u }\right)(s) \overset{\ref{24.6:satz}}{=} 2\pi \hat{g}(s) \hat{u}(s) = \frac{2\pi}{\pi} \frac{1}{1+s^{2}} \hat{u}(s) $$
	\begin{align*}
		\Rightarrow \hat{u}(s) & = \frac{1}{2} \left( 1 + s^{2} \right) \hat{f}(s) \\
		& = \frac{1}{2} \hat{f}(s) + \frac{1}{2} s^{2} \hat{f}(s) \\
		& = \frac{1}{2} \hat{f}(s) - \frac{1}{2} \left( is \right) \underbrace{\left( is \right) \hat{f}(s)}_{\underset{\ref{24.7:satz}}{=} \widehat{f'}(s)} \\
		& = \frac{1}{2} \hat{f}(s) - \frac{1}{2} \underbrace{is \widehat{f'}(s)}_{\underset{\ref{24.7:satz}}{=} \widehat{f''}(s)} \\
		& = \frac{1}{2} \left( \hat{f}(s) - \widehat{f''}(s) \right) = \left( \widehat{ \frac{\left( f - f'' \right)}{2}}  \right) (s) 
	\end{align*}
	$u,f,f''$ stetig $\xRightarrow[]{\ref{24.4:satz}} u(t) = \frac{1}{2} \left( f(t) - f''(t) \right)$.
\end{anwendung*}


\begin{satz}[ohne Beweis] \label{24.8:satz}
	$f \colon \R \rightarrow \C$ sei stückweise glatt, $f$ und $f'$ seien absolut integrierbar. Weiter habe $f$ genau die Unstetigkeitsstellen $x_{1}, \dotsc, x_{m} \in \R$. Dann ist für $s \in \R$:
	$$ \widehat{f'}(s) = is \hat{f}(s) - \frac{1}{2\pi} \sum_{k=1}^{m} \left( f(x_{k}+) - f(x_{k}-) \right) e^{-isx_{k}}. $$
\end{satz}

\index{bandbeschränkt}
\begin{definition}
	Sei nun $f \colon \R \rightarrow \C$ stetig und absolut integrierbar. Wenn die Fouriertransformierte $\hat{f} \colon \R \rightarrow \C$ au{\ss}erhalb eines beschränkten Intervalls $0$ ist, so hei{\ss}t $f$ \textbf{bandbeschränkt} (technisch: Die Frequenzdichte des Signals verschwindet außerhalb eines beschränkten Intervalls). 
	
	\bigskip
	
	In diesem Fall ist es möglich $f$ aus den Werten auf einem hinreichend feinen Raster $\left\{ kt : k \in \Z \right\}$ zu reproduzieren.
\end{definition}


\index{Sinuscardinalis} \index{Abtasttheorem von Shannon}
\begin{satz}[Abtasttheorem von Shannon (ohne Beweis)] \label{24.9:satz}
	$f \colon \R \rightarrow \C$ sei stetig und absolut integrierbar, und $\exists b > 0$: $\hat{f}(s) = 0$ ($s \in \R \setminus (-b, b)$). Dann gilt für jedes $T < \frac{\pi}{b}$:
	$$ f(x) = \sum_{k=-\infty}^{\infty} f(kT) \operatorname{sinc}\left( \frac{\pi}{T} (x - kT) \right) \quad (x \in \R), $$
	wobei $\operatorname{sinc}(x) \coloneqq \begin{cases} \frac{\sin x}{x}, & x \neq 0 \\ 1, & x = 0 \end{cases}$ (Sinuscardinalis).	
\end{satz}

\subsubsection*{Die Fouriertransformation im Raum der schnell fallenden Funktionen}

Ist $f \in V$, so ist $\hat{f}$ stetig und beschränkt, aber im allgemeinen nicht mehr absolut integrierbar (deswegen $CH$ in Umkehrformel). Im Raum der sogenannten schnell fallenden Funktionen herrscht diesbezüglich Symmetrie:

\index{schnell fallend} \index{Schwartz-Raum}
\begin{definition}
	Eine Funktion $f \in C^{\infty}(\R, \C)$ hei{\ss}t \textbf{schnell fallend} $:\iff \forall n, m \in \N_{0}: t \mapsto t^{m} f^{(n)}(t)$ ist beschränkt auf $\R$.
	$$ S \coloneqq \left\{ f \colon \R \rightarrow \C : f \text{ ist schnell fallend} \right\} $$
	hei{\ss}t \textbf{Schwartz-Raum}.
\end{definition}

\begin{beispiel*}
	$f(t) = p(t) e^{-t^{2}}$ ist für jedes Polynom $p$ eine schnell fallende Funktion.
\end{beispiel*}


\begin{satz} \label{24.10:satz}
	Seien $f, g \in S$. Dann gilt:
	\begin{enumerate}
		\item $\forall \alpha, \beta \in \C$: $\alpha f + \beta g \in S$ ($S$ ist also ein Vektorraum).
		\item $f \cdot g \in S$.
		\item $f^{(n)} \in S$ ($n \in \N$).
		\item $t \mapsto t^{m} f(t)$ ist in $S$.
		\item $f$ ist absolut integrierbar.
		\item $\hat{f} \in S$.
		\item $f_{h} \in S$ ($h \in \R$).
		\item $f \ast g \in S$.
	\end{enumerate}
	
	\begin{proof}
		a) - d), f) ohne Beweis
		\begin{enumerate} \setcounter{enumi}{4}
			\item $t \mapsto t^{2} f$ ist beschränkt, $t \mapsto \left(1 + t^{2}\right)f$ ist beschränkt 
				$$ \Rightarrow \left| f(t) \right| \leq \frac{M}{1 + t^{2}} \leq \frac{M}{t^{2}}, \quad (t \neq 0). $$
				Da $\int_{1}^{\infty} \frac{1}{t^{2}} dt$ konvergiert, folgt die Behauptung mit Satz \ref{24.1:satz}. % todo Handschriftliches nicht zuordenbar
		\end{enumerate}
	\end{proof}
\end{satz}


\begin{satz} \label{24.11:satz}
	Die Fouriertransformation $f \mapsto \hat{f}$ ist ein Isomorphismus von $S$ nach $S$ (also linear und bijektiv).
	
	\begin{proof}
		Sei $\mathcal{F} \colon S \rightarrow S$ definiert durch $\mathcal{F} f = \hat{f}$. $\mathcal{F}$ ist linear (klar). Betrachte $\mathcal{G} \colon S \rightarrow S$ definiert durch
			$$ \left( \mathcal{G} g \right)(t) = \int_{-\infty}^{\infty} g(s) e^{ist} ds $$
		(beachte $g$ ist absolut integrierbar). Nach Satz \ref{24.4:satz} gilt: $\mathcal{G} \left( \mathcal{F}f \right) = f$. Wegen
			$$ \left( \mathcal{G}g\right)(-t) = \int_{-\infty}^{\infty} g(s) e^{-ist} ds = 2\pi \hat{g}(t) \quad (t \in \R) $$
		ist für $s \in \R$
			\begin{align*}
				\mathcal{F} \left( \mathcal{G} g \right) (s) & = \frac{1}{2 \pi} \int_{-\infty}^{\infty} 2 \pi \hat{g}(-t) e^{-its} dt \\
					& = \int_{-\infty}^{\infty} \hat{g}(-t) e^{-its} dt \\
					& = \int_{-\infty}^{\infty} \hat{g}(t) e^{-its} dt = g(s), 
			\end{align*}
			
		also gilt $\mathcal{G} = \mathcal{F}^{-1}$.	
	\end{proof}
\end{satz}


% Skript - Ende
\appendix 

% Inhaltsverzeichnis
\renewcommand{\indexname}{Stichwortverzeichnis}
\printindex


\end{document}